Understanding Pearson product-moment correlation coefficient EPUB version of this book
Susan K. Grove, PhD, RN, ANP-BC, GNP-BC; Daisha J. Cipher, PhD

Statistics for Nursing Research, EXERCISE 13, 153-165

Statistical technique in review
Many studies are conducted to identify relationships between two or more variables. The correlational coefficient is the mathematical expression of the relationship or association studied. Two common analysis techniques used to examine relationships in healthcare studies are the Pearson product-moment correlation coefficient ( r) and the Spearman rank-order correlation coefficient ( rho ) (see the algorithm Fig. 12.1 in Exercise 12 ). The Pearson correlation coefficient is a parametric analysis technique conducted to examine bivariate correlations between continuous variables measured at the interval and ratio levels ( Gray & Grove, 2021 ; Kim et al., 2022 ). Bivariate correlation measures the extent of the relationship between two variables at a time in a study. Pearson r is calculated to determine the strength and direction of relationships in correlational studies. Therefore the purpose of correlational research is to examine relationships and not to determine cause and effect between independent and dependent variables ( Grove & Gray, 2023 ). Cause and effect are the focus of quasi-experimental and experimental studies conducted to determine the effect of an intervention on an outcome ( Kazdin, 2022 ; Shadish et al., 2002 ).

The Spearman rank-order correlation coefficient is a nonparametric analysis technique conducted to examine relationships when variables are measured at the ordinal level (see Exercise 20 ; Pett, 2016). This analysis technique is also calculated when the data collected do not meet the normality assumption of the Pearson r correlation coefficient ( Gray & Grove, 2021 ).

Types of relationships
Relationships are interpreted in terms of direction and strength. The direction of the relationship is expressed as either positive or negative. A positive or direct relationship exists when one variable increases as the other variable increases or when one variable decreases as the other decreases. The variables change in the same direction (see Exercise 11 ). For example, a moderate increase in calorie intake per day is related to an increase in weight gain. Conversely, a negative or inverse relationship exists when one variable increases as the other variable decreases. For example, an increase in minutes of exercise per day is related to a decrease in weight ( Grove & Gray, 2023 ; Heavy, 2019 ).

The strength or magnitude of a relationship is described as weak, moderate, or strong. Pearson r is never less than −1.00 or greater than +1.00, so an r value of −1.00 or +1.00 indicates the strongest possible relationship, either negative or positive, respectively. An r value of 0.00 indicates no relationship or association between two variables. To describe a relationship, the labels weak ( r < 0.30), moderate ( r = 0.30–0.50), and strong ( r > 0.50) are used in conjunction with both positive and negative values of r ( Cohen, 1988 ; Gray & Grove, 2021 ; Plichta & Kelvin, 2013 ).

The significance of r values can be determined by examining the Table of Critical Values for r for the Pearson product-moment correlation coefficient in Appendix B at the back of this text. To use this table, you need to know the level of significance or alpha for the study, which is usually set at 0.05. The degrees of freedom ( df ) for a Pearson r value is the sample size minus 2 ( N − 2). For example, if a study had r = 0.36, a sample size of 50, and alpha set at 0.05, is the r value statistically significant? The answer is yes because the r = 0.36 with a df = 48 is larger than the critical table value 0.2787 for alpha = 0.05 for a two-tailed test (see Exercise 29 for calculating and determining the significance of Pearson r correlation coefficients).

Mirror-image table of pearson r results
A mirror-image table , as the name implies, has the same labels for variables in the same order for both the x - and y -axes (see Exercise 7 for a discussion of x - and y -axes). Frequently, numbers or letters are assigned to each variable, and only the letter or number designator is used to label one of the axes. To find the r value for a pair of variables, look along the labeled or y -axis in Table 13.1 and then along the x -axis, using the number designator assigned to the variable to identify a selected relationship, and find the cell in the table with the r value. Table 13.1 is an example of a mirror-image table that displays the relationships among the variables of hours of class attended per week, hours studying per week, and final grade as a percentage. The results in the table are intended as an example of a mirror-image table and are not based on research. If you were asked to identify the r value for the relationship between hours of class attended per week and the final grade as a percentage, the answer would be r = 0.52; for between hours studying per week and final grade as a percentage, the answer would be r = 0.58. The dash (–) marks located on the diagonal line of the table represent the variable’s correlation with itself, which is always a perfect positive correlation or r = +1.00. Because the results are the same in both sides of the mirror-image table, most researchers only include half of the table in their final report ( Gray & Grove, 2021 ; Terrell, 2021 ).

View full size
TABLE 13.1

MIRROR-IMAGE PEARSON r CORRELATION TABLE

Variables	1	2	3
1.
Hours of class attended per week

–	0.34	0.52
2.
Hours studying per week

0.34	–	0.58
3.
Final grade as a percentage

0.52	0.58	–
Effect size of an r value
The Pearson r (in absolute value) is equal to the effect size ( ES ) or the strength of a relationship between two continuous variables. In Table 13.1 , the association between hours of class attended per week and hours of studying per week is r = 0.34; thus the r = ES = 0.34 for this relationship. The ES is used in power analysis to determine sample size and examine the power of study results ( Aberson, 2019 ; Cohn, 1988 ). Exercise 24 describes the elements of power analysis, and Exercise 25 includes the steps for conducting a power analysis for different statistical techniques.

The strength of the ES is the same as that for the r values, with a weak ES as <0.30, a moderate ES 0.30 to 0.50, and a strong ES >0.50. The smaller the ES , the greater the sample size needed to detect significant relationships in studies ( Aberson, 2019 ; Lohr, 2022 ). A large ES or association between two variables requires a smaller sample size to identify a significant relationship. The sample size needed for correlational studies increases as the number of variables studied increases. Correlational studies usually involve examining relationships among multiple variables, so a large sample size is important ( Cohen, 1988 ; Gray & Grove, 2021 ; Kazdin, 2022 ; Lohr, 2022 ).

Percentage of variance explained in a relationship
There is some variation in the relationship between the values of two variables for individual participants. Some of the variation in values is explained by the relationship between the two variables and is called explained variance , which is calculated by r 2 and is expressed as a percentage. To calculate the percentage of variance explained, square the r value and multiply by 100% to determine a percentage ( Cohen, 1988 ; Grove & Gray, 2023 ).

Formula: % variance explained = r 2 × 100%
Example: r = 0.58 (correlation between hours studying and final grade as a percentage) (0.58) 2 × 100% = 0.3364 × 100% = 33.64% variance explained
In this example, the hours studying per week explains 33.64% of the variance in the final course grade. However, part of the variation is the result of factors other than the relationship and is called unexplained variance . In the example provided, 100% − 33.64% (explained variance) = 66.36% (unexplained variance). Fig. 13.1 demonstrates the concepts of explained and unexplained variance in this example.

A Venn diagram shows overlap between final grade percentage and hours of study per week. The diagram is a Venn diagram with two intersected circles. The left circle is labeled final grade percentage and the right circle is labeled hours of study per week. The overlapping central area is labeled 33.64 percent variance explained. The outer non overlapping areas of both circles are labeled unexplained variance total of 66.36 percent. Two arrows point from the outer regions of both circles to a shared label at the bottom read unexplained variance 66.36 percent.
FIG. 13.1 ■
PERCENTAGES OF EXPLAINED AND UNEXPLAINED VARIANCES IN A RELATIONSHIP.

Calculating the percentage of variance explained helps researchers and nurses understand the practical implications of reported results. The stronger the r value, the greater the percentage of variance explained. For example, if r = 0.50, then 25% of the variance in one variable is explained by another variable; if r = 0.60, then 36% of the variance is explained. All Pearson r values need to be examined for clinical importance; the potential for clinical importance increases with moderate and strong relationships, where r ≥ 0.30 and yields a 9% or higher percentage of variance explained. Keep in mind that a result may be statistically significant ( p ≤ 0.05), but it may not represent a clinically important finding. For example, the correlation between hours of computer time and minutes of exercise is r = 0.195, df = 100. This r (0.195) value is greater than the critical value of r (0.1946) for alpha = 0.05 for a two-tailed Pearson correlation test (see Appendix B ). This result is statistically significant, but the percentage of variance explained is 3.80%, which has limited clinical importance. Thus the r values in a study need to be examined for statistical significance and clinical importance ( Grove & Gray, 2023 ; Terrell, 2021 ).

Research article
Source
Hartson, K. R., Gance-Cleveland, B., Amura, C. R., & Schmiege, S. (2018) . Correlates of physical activity and sedentary behaviors among overweight Hispanic school-aged children. Journal of Pediatric Nursing , 40 (1), 1–6. https://doi.org/10.1016/j.pedn.2018.01.019

Introduction
Hartson and colleagues (2018) examined the correlates of physical activity (PA) and sedentary screen time behaviors among overweight Hispanic children ages 7 to 14 years. The PA (in days/week moderate PA ≥ 60 minutes), sedentary screen time behavior (in hours/week), body mass index (BMI) percentile (%), body esteem, and self-esteem were examined for the child. Body esteem was measured with the Body Esteem Scale, which included 24 items. Self-esteem was measured with the Rosenberg Self-Esteem Scale, which was considered reliable and valid and had been used with many populations. Both of these scales were multi-item Likert scales ( Waltz et al., 2017 ). The fruit intake (in servings/day) and vegetable intake (in servings/day) were examined for both the child and parent.

Hartson et al. (2018, p. 1) concluded: “Understanding the correlates of physical activity and sedentary screen time behaviors in this underrepresented population allows nurses to better understand the connections between physical activity and other aspect of well-being in children. Further investigation is needed to determine how these relationships can be incorporated into physical activity interventions that improve the health of overweight Hispanic school-aged children.”

Relevant study results
“Methods
Study design
This was an exploratory correlation analysis of secondary data from the Mind Exercise Nutrition Do It! (MEND) 7–13 program conducted in a school district in the Western U.S.... The MEND 7– 13 program is a multi-component, community-based, family-focused health intervention developed... for overweight or obese children and their families....

Analysis
SPSS Statistical Software, version 23, was used to conduct the analysis. Missing data analysis revealed large amounts of missing data for parental PA (45% missing), parental sedentary behavior (40% missing), and parental BMI (35% missing). Therefore, these variables were excluded from further analysis. For the variables of interest, no answers were outside of the range of potential answers, and in order to maximize sample size, no outliers were excluded. Pearson’s correlations ( r ) were calculated to assess for correlations among child PA and sedentary behavior with potential child- and parent-correlates. Spearman’s correlations ( rho ) were calculated to explore correlations among PA, sedentary behavior, and potential correlates stratified by gender, due to the small sample sizes” (Harton et al. (2018, pp. 2–3).

“Results
Participant characteristics
The sample consisted of 40 child– parent dyads. The parental education of the sample was largely high school level or lower (80%), and most of the sample was from lower income households (75%). All of the children were Hispanic and of ages 7 to 14 years old. The sample of children was 50% male and 50% female. The parents were 80% mothers, 10% fathers, and 10% grandparents or other....

On average, the children participated in at least 60 min of moderate PA on 3.19 ( SD = 2.40) days per week and reported 7.09 ( SD = 6.30) hours per week of sedentary screen time behaviors. Mean fruit intakes for children (mean = 2.24, SD = 1.47) and parents (mean = 2.26, SD = 1.31) were slightly above the recommended 2 cup-equivalents per day, while the mean vegetable intakes for children (mean = 1.56, SD = 1.00) and parents (mean = 1.91, SD = 1.60) were below the recommended 2.5 cup-equivalents per day, based on recommended amounts of fruits and vegetables required for a healthy nutrient-rich pattern of eating ( U.S. Health and Human Services & U.S. Department of Agriculture, 2015 ). The mean child BMI percentile of the sample was 95.23% ( SD = 5.78), which placed the sample mean BMI in the obese category, based on the Centers for Disease Control ( CDC, 2015 ) growth reference curves. See Table 13.2 for additional baseline characteristics of the sample.

View full size
TABLE 13.2

BASELINE CHARACTERISTICS

From Hartson, K. R., Gance-Cleveland, B., Amura, C. R., & Schmiege, S. (2018). Correlates of physical activity and sedentary behaviors among overweight Hispanic school-aged children. Journal of Pediatric Nursing, 40 , 3.

n (%)	Mean	SD
Child Variable
PA (days/week moderate PA ≥60 min)	37 (92.5)	3.19	2.40
Sedentary screen time behavior (h/wk)	38 (95.0)	7.09	6.30
BMI%	40 (100.0)	95.23	5.78
Fruit intake (servings/day)	39 (97.5)	2.24	1.47
Vegetable intake (servings/day)	37 (92.5)	1.54	1.00
Body esteem	38 (95.0)	13.00	4.92
Self-esteem	39 (97.5)	21.64	5.93
Parental Variable
Fruit intake (servings/day)	39 (97.5)	2.26	1.31
Vegetable intake (servings/day)	37 (92.5)	1.91	1.60
BMI, Body mass index; PA, physical activity; SD, standard deviation.

Correlations with physical activity and sedentary behavior
Child self-esteem ( r = 0.34, p < 0.05) and parental vegetable intake ( r = 0.36, p < 0.05) had a positive association of moderate size with PA in this coed sample of overweight Hispanic school-aged children.... Interestingly, BMI percentile, sedentary screen time behaviors, and body esteem were not associated with child PA. None of the potential correlates were associated with sedentary screen time behavior, except for body esteem which was negatively associated with sedentary screen time behavior in males.... See Table 13.3 for Pearson’s correlations” ( Hartson et al., 2018 , p. 3).

View full size
TABLE 13.3

PARENT- AND CHILD-CORRELATES OF CHILD PHYSICAL ACTIVITY AND SEDENTARY BEHAVIOR (PEARSON’S CORRELATIONS, r )

From Hartson, K. R., Gance-Cleveland, B., Amura, C. R., & Schmiege, S. (2018). Correlates of physical activity and sedentary behaviors among overweight Hispanic school-aged children. Journal of Pediatric Nursing , 40 , 4.

PA	Sedentary Behavior	BMI%	Fruit intake	Veg intake	Body esteem	Self-esteem	Parent Fruit	Parent veg
PA	–								
Sedentary behavior	0.05	–							
BMI%	0.08	0.13	–						
Fruit intake	0.31	−0.08	−0.12	–					
Vegetable intake	0.05	−0.26	0.16	0.55**	–				
Body esteem	0.06	−0.04	−0.40*	0.22	−0.04	–			
Self-esteem	0.34*	0.06	−0.14	0.34*	0.12	0.44**	–		
Parent fruit intake	0.19	0.09	0.14	0.53**	0.25	0.06	0.10	–	
Parent vegetable intake	0.36*	0.05	0.15	0.60**	0.15	−0.08	0.09	0.78**	–
BMI, Body mass index; PA, physical activity.

Note: * p < 0.05, ** p < 0.01, two-tailed.

“Limitations
The sample size was small for a correlational analysis, which limited the robustness of the results; however, it allowed for the collection of data from a population that is commonly underrepresented in research, and yet, has high needs for healthcare resources.... Other limitations include that only one parent was surveyed, rather than two when available, and the use of non-validated single item measures for PA and sedentary behavior. Single item measures increased feasibility, but limited the depth of the constructs and could potentially affect the validity of the conclusions.... Also, the sedentary activity questions did not explicitly include sedentary time while texting, playing smartphone games, or using social media, all of which could increase hours of sedentary time per week. Future research will need to incorporate trends in sedentary use of technology in order to obtain accurate measures of sedentary screen time behaviors” ( Hartson et al., 2018 , pp. 4–5).

Study questions

1.
What design was used to conduct the Hartson et al. (2018) study? Did the design address the purpose of this study? Provide a rationale for your response.

2.
Identify the descriptive results for the BMI percentile in this sample. What do these results indicate clinically for these children?

3.
In the Hartson et al. (2018) study, Table 13.3 is what type of table? What values are presented in this table? What do the dashes (–) along the diagonal of this table indicate?

4.
What is the value of the Pearson r for the relationship between child PA and sedentary behavior? Is this relationship positive or negative? What is the strength of this relationship? Provide a rationale for your response.

5.
Is the relationship between child PA and self-esteem statistically significant? Provide a rationale for your response.

6.
State the null hypothesis for the relationship between child PA and self-esteem. Was the null hypothesis accepted or rejected? Provide a rationale for your response.

7.
What is the Pearson r and ES for the association between parent fruit intake and child fruit intake? Describe this relationship using words rather than numbers.

8.
What percentage of variance is explained by the relationship between the variables of parent fruit intake and child fruit intake? Show your calculations and round your answer to two decimal places.

9.
Is the relationship in Question 8 clinically important? Provide a rationale for your response.

10.
Do the results in Table 13.3 support the statement that the child BMI percentile causes reduced body esteem? Provide a rationale for your response.

Understanding simple linear regression EPUB version of this book
Susan K. Grove, PhD, RN, ANP-BC, GNP-BC; Daisha J. Cipher, PhD

Statistics for Nursing Research, EXERCISE 14, 166-177

Statistical technique in review
In nursing practice, the ability to predict future events or outcomes is extremely important in providing quality, cost-effective, safe health care ( Straus et al., 2019 ). Nurse researchers calculate and report linear regression results in their studies as a basis for making these predictions. Linear regression provides a means to estimate or predict the value of a dependent variable based on the value of one or more independent variables or predictors ( Gray & Grove, 2021 ; Kim et al., 2022 ). The regression equation is a mathematical expression of the theorized influential association between a predictor and an outcome. The link between the theoretical statement and the equation is made prior to data collection and analysis. Simple linear regression is a statistical technique conducted to determine the relationship between one predictor variable ( x ) and a dependent variable ( y ) ( Prion & Haerling, 2020 ). The assumptions for simple linear regression include normal distribution of the dependent ( y ) variable, linear relationship between x and y, and independent observations (see Exercise 30 for a detailed discussion of assumptions).

The regression line developed from simple linear regression is usually plotted on a graph, with the horizontal axis representing x (the predictor variable) and the vertical axis representing the y (the dependent or predicted variable; Fig. 14.1 ). The value represented by the letter a is referred to as the y -intercept, or the point where the regression line crosses or intercepts the y -axis. At this point on the regression line, x = 0. The value represented by the letter b is referred to as the slope, or the coefficient of x . The slope determines the direction and angle of the regression line within the graph, which expresses the extent to which y changes for every one-unit change in x . The score on variable y (dependent variable) is predicted from the study participant’s known score on variable x . The predicted score or estimate is referred to as ŷ (expressed as y -hat) ( King & Eckersley, 2019 ; Tarrell, 2021 ).

A graph shows a simple linear regression line with labeled slope and intercept. The graph shows a straight upward slope line extending diagonally from the lower left to the upper right of the plot. The point where the line intersects the vertical axis is labeled a y-intercept, and a point on the line is labeled b slope. No data points are shown on the graph.
FIG. 14.1 ■
GRAPH OF A SIMPLE LINEAR REGRESSION LINE.

Simple linear regression is an effort to explain the dynamics within a scatterplot (see Exercise 11 ) by drawing a straight line through the plotted scores or values. No single regression line can be used to predict, with complete accuracy, every y value from every x value. However, the purpose of the regression equation is to develop the line to allow the highest degree of prediction possible: the line of best fit . The procedure for developing the line of best fit is the method of least squares . If the data were perfectly correlated, all data points would fall along the straight line or line of best fit. However, not all data points fall on the line of best fit in studies, but the line of best fit provides the best equation for the values of y to be predicted by locating the intersection of points on the line for any given value of x .

The algebraic equation for the regression line of best fit is y = bx + a, where:

y = dependent variable (outcome)
x = predictor (independent variable)
b = slope of the line (beta, or what the increase in the value is along the x -axis for every unit of increase in the y value), also called the regression coefficient.
a = y -intercept (the point where the regression line intersects the x -axis), also called the regression constant.
Research reports present linear regression results in figures, tables, and/or narrative format ( American Psychological Association [APA], 2020 ). The equation or formula developed from the regression results and a figure of the line of best fit for the study data might also be included. In Fig. 14.2 , the x -axis represents gestational age in weeks and the y -axis represents birth weight in grams. As gestational age increases from 20 weeks to 34 weeks, birth weight also increases. In other words, the slope of the line is positive. This line of best fit can be used to predict the birth weight (dependent variable) for an infant based on his or her gestational age in weeks (predictor). Fig. 14.2 is an example of a line of best fit that was developed from hypothetical data. In addition, the x -axis starts at 22 weeks rather than 0, which is the usual start in a regression figure focused on gestational age. Using the equation y = bx + a , the birth weight of a baby born at 28 weeks of gestation is calculated as follows:

Equation: y = b x + a
In this example, a = 500, b = 20, and x = 28 weeks
y = 20(28) + 500 = 560 + 500 = 1060 grams
A scatterplot shows the relationship between gestational age and birth weight with a line of best fit. The scatterplot shows the horizontal axis labeled as gestational age and the vertical axis labeled as birth weight. Individual square-shaped data points are scattered across the plot, generally forming an upward trend. A straight line of best fit extends from the lower left to the upper right, pass through the middle of the clustered points. The gestational age values range from 22 to 34 and the birth weight values range from 400 to 1600.
FIG. 14.2 ■
EXAMPLE LINE OF BEST FIT FOR GESTATIONAL AGE AND BIRTH WEIGHT.

The regression line represents y for any given value of x . As you can see, some data points fall above the line and some fall below the line. If we substitute any x value in the regression equation and solve for y , we will obtain a ŷ that will be somewhat different from the actual value. The distance between the ŷ and the actual value of y is called residual , and this represents the degree of error in the regression line, as well as error of prediction. The regression line or the line of best fit for the data points is the unique line that will minimize error and yield the smallest residual ( Kim et al., 2022 ; Zar, 2010 ). The step-by-step process for calculating simple linear regression in a study is presented in Exercise 30 .

Research article
Source
Kuroki, M. (2022 ). Healthcare coverage and out-of-pocket medical expenses: Evidence from the 2017 Tax Cuts and Jobs Act and the medical expense deduction. Public Health, 205, 58–62. https://doi.org/10.1016/j.puhe.2022.01.022

Introduction
Healthcare costs in the United States (U.S.) have been rising each year, creating a burden for both insured and uninsured individuals. The deduction of medical expenses provides an important tax relief for a small percentage of taxpayers. “Taxpayers can deduct out-of-pocket health insurance premiums and a wide range of medical expenses, such as preventative care, treatment, surgeries, dental and vision care, visits to psychologists and psychiatrists, as well as prescription medications and appliances, such as glasses, contacts, false teeth, and hearing aids. In 2016, approximately 8.8 million tax returns, or 5.9% of all tax returns, were filed with a medical expense deduction, whereas the number was 10.2 million, or 6.6% of all tax returns, in 2017, which is probably due to the lower threshold for the medical expense deduction in 2017” ( Kuroki, 2022 , p. 59). This study focused on two outcomes: (1) to determine the change in state-level tax returns with medical expense deductions and (2) to examine the annual percent change in the total medical expense deduction amount at the state level. The data for this study were obtained from the Internal Revenue Service (IRS).

Relevant study results
“Results
We present graphical evidence that shows the correlations between the uninsurance rate and outcomes of interest. Fig. 14.3 plots the percentage point change in the share of tax returns with medical expense deductions during 2016–2017 against the uninsurance rate in the same period. The ordinary least squares (OLS) regression line is inserted in the figure.... The likelihood of using the medical expense deduction increased in all states in 2017, but the increase was larger in states where the uninsurance rate was higher (β = 0.06, p = 0.022), suggesting that many uninsured people benefited from the lower threshold for the medical expense deduction in 2017.

A scatterplot shows the relationship between poverty level and change in tax returns with medical deduction. The diagram is a scatterplot with the horizontal axis labeled percent uninsured among those below 400 percent of the federal poverty level and the vertical axis labeled percentage point change in tax returns with the medical deduction from 2016 to 2017. Each point is marked with a two-letter state abbreviation that represents a US state. The points are dispersed across the graph with a visible upward trend. A line of best fit rises diagonally from left to right through the center of the data. A linear equation and p-value are placed in the upper right quadrant, reads y equals 0.57 plus 0.06 x and p-value equals 0.002.
FIG. 14.3 ■
PERCENTAGE POINT CHANGE IN TAX RETURNS WITH THE MEDICAL DEDUCTION (2016–2017).

AGI, Adjusted gross income.

Kuroki, M. (2022). Healthcare coverage and out-of-pocket medical expenses: Evidence from the 2017 Tax Cuts and Jobs Act and the medical expense deduction. Public Health, 205, 61. https://doi.org/10.1016/j.puhe.2022.01.022

Similarly, Fig. 14.4 plots percent change in the total medical expense deduction amount against the uninsurance rate. In line with the finding on the share of tax returns with a medical expense deduction, the percent increase in the medical expense deduction was also larger on average in states where the uninsurance rate was higher (β = 0.9, p = 0.0003)” ( Kuroki, 2022 , p. 62).

A scatterplot shows the relationship between poverty level and change in total medical expense deduction. The diagram is a scatterplot with the horizontal axis labeled percent uninsured among those below 400 percent of the federal poverty level and the vertical axis labeled number of returns using medical deduction with A G I below 50000. Each data point represents a US state using a two-letter abbreviation. A line of best fit runs diagonally upward from left to right through the data cluster. The state abbreviations are scattered mostly in the middle and lower left regions, with a few extending higher or further right. The linear equation y equals 9.9 plus 0.9 x and the p-value equals 0.0003 are displayed in the lower right quadrant.
FIG. 14.4 ■
PERCENTAGE CHANGE IN TOTAL MEDICAL EXPENSE DEDUCTION (2016–2017).

AGI, Adjusted gross income.

Kuroki, M. (2022). Healthcare coverage and out-of-pocket medical expenses: Evidence from the 2017 Tax Cuts and Jobs Act and the medical expense deduction. Public Health, 205, 61. https://doi.org/10.1016/j.puhe.2022.01.022

“Discussion and conclusions
Given that the health insurance premiums and the costs of healthcare service have been increasing for many Americans, the effect of health insurance on out-of-pocket medical expenses is an important topic in public health.... However, the primary finding of this study is that states with higher shares of uninsured populations experienced a larger increase in the share of tax returns with a medical expense deduction, presumably because of unexpected and possibly catastrophic out-of-pocket medical expenses among the uninsured, after the threshold for the medical expense deduction was lowered in 2017. Also, the total medical expenditure deduction amounts increased more in states where the uninsurance rate was higher, consistent with the finding on the share of tax returns with a medical expense deduction” ( Kuroki, 2022 , p. 62).

Study questions

1.
What is the purpose of simple linear regression analysis and the regression equation?

2.
What is the point where the regression line meets the y -axis called? Is there more than one term for this point and what is the value of x at that point?

3.
In the formula y = bx + a , is a or b the slope? What does the slope represent in regression analysis?

4.
What are the variables on the x - and y -axes in Fig. 14.2 ? Identify which variable is the predictor variable and which is the dependent variable.

5.
What equation, developed from simple linear regression analysis, is presented in Fig. 14.2 ? Using this equation, what is the birth weight in grams ( y ) of an infant born at 30 weeks? Show your calculations.

6.
What is the predictor variable in Fig. 14.3 and what is the dependent variable?

7.
Does Fig. 14.3 have a positive or negative slope? Provide a rationale for your answer. Discuss the meaning of the slope of Fig. 14.3 .

8.
What regression equation was presented in Fig. 14.3 ? Was this equation significant? Provide a rationale for your response.

9.
What is the y -intercept in Fig. 14.3 ? Show your calculations.

10.
Calculate the percentage point change in tax returns with medical deductions ( y ) for 6% of uninsured taxpayers. Show your calculations.

Answers to study questions

1.
Simple linear regression is a statistical technique conducted to estimate or predict the values of a dependent variable based on the values of one independent or predictor variable. Regression analysis is used to calculate a line of best fit based on the relationship between the predictor variable x and the dependent variable y. The equation developed with regression analysis can be used to predict the dependent variable ( y ) values based on values of the predictor variable ( x ) ( Gray & Grove, 2021 ; Kim et al., 2022 ; Plichta & Kelvin, 2013 ).

2.
The point where the regression line meets the y -axis is called the y -intercept and is also represented by a (see Fig. 14.1 ). In regression analysis, a is also called the regression constant. At the y intercept, x = 0.

3.
In the equation y = bx + a, b is the slope of the line of best fit (see Fig. 14.1 ). The slope of the line indicates the amount of change in y for each one unit of change in x; b is also called the regression coefficient ( Gray & Grove, 2021 ; Kim et al., 2022 ).

4.
The predictor variable is gestational age, which is on the horizontal or x -axis. The dependent variable is birth weight in grams, which is on the vertical or y -axis.

5.
The equation developed by simple linear regression in Fig. 14.2 was y = 20 x + 500, where a = 500 and b = 20. The calculation of the birth weight for the gestational age of 30 weeks is: y = 20(30) + 500 = 600 + 500 = 1100 grams.

6.
In Fig. 14.3 , the predictor variable is the percent uninsured by state (2016–2017 average), which is on the x -axis. The dependent variable is the percentage point change in tax returns with medical deductions (2016–2017), represented on the y -axis.

7.
Fig. 14.3 has a positive slope. The slope is represented by b in the equation on Fig. 14.3 and is a positive value ( b = 0.06). In addition, the line of best fit extends from the lower left corner to the upper right corner, indicating a positive slope ( Kim et al., 2022 ; Prion & Haerling, 2020 ). The line of best fit demonstrates that an increase in x (predictor) is associated with an increase in y (dependent variable). In Fig. 14.3 , as the percentage of uninsured individuals in different U.S. states increases, the percentage of tax returns with medical deductions increases.

8.
A regression equation might be expressed as y = bx + a or y = a + bx. In Fig. 14.3 , the equation is y = a + bx = 0.57 + 0.06 x . This equation was significant at p = 0.022 as indicated in Fig. 14.3 and in the narrative of the article ( Kuroki, 2022 ). The p = 0.022 is significant because it is less than the alpha = 0.05 set for this study ( Grove & Gray, 2023 ; Terrell, 2021 ).

9.
At the y -intercept, x = 0. Using the equation in Fig. 14.3 , y = 0.57 + 0.06(0) = 0.57 + 0 = 0.57 ( Gray & Grove, 2021 ; Kim et al., 2022 ).

10.
In Fig. 14.3 , the equation is y = 0.57 + 0.06( x ). If x = 6%, the equation is y = 0.57 + 0.06 (6%) = 0.57 + 0.36% = 0.93% change in tax returns with medical deductions.

EXERCISE 14
Questions f

Understanding multiple linear regression EPUB version of this book
Susan K. Grove, PhD, RN, ANP-BC, GNP-BC; Daisha J. Cipher, PhD

Statistics for Nursing Research, EXERCISE 15, 178-189

Statistical technique in review
Simple linear regression was introduced in Exercise 14 and provides a means to estimate or predict the value of one dependent variable based on the value of an independent variable. However, when studying people with a focus on evidence-based practice, researchers usually examine two or more independent variables or predictors affecting the dependent variable of interest ( Gray & Grove, 2021 ). Thus multiple linear regression, an extension of simple linear regression, is conducted when more than one independent variable or predictor is entered into the analysis to predict a dependent variable. The main advantage of a multiple linear regression model is the ability to examine the effects of several predictors on a dependent variable ( Kim et al., 2022 ; Terrell, 2021 ).

Assumptions of multiple linear regression
The assumptions of multiple linear regression are as follows:

1.
Normal distribution of the dependent variable (see Exercise 27 )

2.
Linear relationship between x and y

3.
Independent observations

4.
Interval or ratio measurement of the dependent variable; however, if the dependent variable is measured with a Likert scale, and the frequency distribution is approximately normally distributed, these data are usually considered interval-level measurements and are appropriate to serve as the outcome in a linear regression model ( Rasmussen, 1989 ; Waltz et al., 2017 ).

5.
Values for the dependent variable are homoscedastic , or equally dispersed about the line of best fit (see Exercise 14 ; Gray & Grove, 2021 ; Kim et al., 2022 ).

Multicollinearity
With multiple predictors, researchers often correlate these predictors with the dependent variable to determine which are most highly correlated with the dependent variable. Pearson r analysis is typically computed to determine correlations for interval- and ratio-level data. Scores obtained with Likert scales that are normally distributed are analyzed as interval-level data ( Grove & Gray, 2023 ; Waltz et al., 2017 ). To be effective, predictors need to have strong correlations with the dependent variable, but only weak correlations with the other predictor variables in the equation. Multicollinearity occurs when the predictors in the multiple regression equation are strongly correlated (over 0.85) with each other ( Kim et al., 2022 ). Collinearity diagnostics are conducted to determine multicollinearity (see Exercise 31 ). Multicollinearity occurs in nursing studies, but it can be minimized by careful selection of predictor variables that have minimal or no correlation with each other. The ultimate goal of multiple linear regression is to find the best prediction model that has the least number of predictors with maximum explanation of the data ( Gray & Grove, 2021 ; Terrell, 2021 ).

Multiple linear regression results
The main result from multiple regression analysis is an R 2 value. For the addition of each predictor variable to the regression formula, the change in R 2 is reported. The R 2 is used to calculate the percentage of variance that is predicted by the regression formula. In the following hypothetical example, the predictors of number of pack-years of smoking (i.e., number of packs of cigarettes smoked per day times number of years of smoking), systolic blood pressure (SBP), and body mass index (BMI) were used to predict the incidence of myocardial infarction (MI) in older adults. The R 2 = 0.387, and the percentage of variance predicted is calculated by R 2 × 100%. In this example, the percentage of the variance in the dependent variable that is explained by the predictors is calculated as 0.387 × 100% = 38.7%. This means that 38.7% of the variance in the incidence of MIs in older adults is predicted by the pack-years of smoking, SBP, and BMI. The significance of an R 2 value is tested with an analysis of variance (ANOVA; see Exercises 18 and 35 ). The statistic for ANOVA is F , and a significant F value indicates that the regression equation has significantly predicted the variation in the dependent variable and that the R 2 value is not a random variation ( Gray & Grove, 2021 ; Kim et al., 2022 ). The step-by-step process for calculating multiple linear regression is presented in Exercise 31 .

Research article
Source
Inayati, A., Lee, B., Wang, R., Chen, S., Hsu, H., Lu, C., & Head, Y. L. (2022) . Determinants of fear of falling in older adults with diabetes. Geriatric Nursing, 46, 7–12. https://doi.org/10.1016/j.gerinurse.2022.04.017

Introduction
Fear of falling (FoF) is a critical factor that contributes to falls in older adults with diabetes. FoF often causes the elderly to avoid performance of essential, nonhazardous activities, which accelerates their physical and cognitive decline. Previous research was insufficient in predicting FoF in older adults. “Consequently, this study aimed to examine the important determinants of FoF in older adults with diabetes.... This study hypothesized that demographic and illness characteristics, physical function and capability, psychosocial and cognitive factors were important determinants of FoF among older adults with diabetes” ( Inayati et al., 2022 , p. 8). These researchers conducted a secondary data analysis of a previous study by Wang et al. (2021) . Convenience sampling was used to obtain a sample of 240 elderly adults with diabetes. A power analysis was conducted that indicated 143 participants were needed for a study with an alpha = 0.05, power of 0.80, and effect size of 0.15 involving 16 independent variables for a multiple regression analysis.

The dependent variable FoF was measured with a 16-item, 4-point Likert scale. The scores range from 16 to 64 on this scale, with the higher scores indicating higher FoF. Diabetes distress was measured with an eight-item, 5-point Likert scale. Each item on the scale focused on a diabetic problem that was rated as not a problem (0 points) to a serious problem (4 points). The total scores of this scale ranged from 0 to 32 points, with higher scores indicating more severe diabetic-related problems. Handgrip was measured with a hand dynamometer, with higher values indicating greater muscle strength. The time up and go (TUG) variable was a balance test of standing, walking, turning around, and taking a seat. The more seconds taken to complete the TUG test, the worse the participant’s performance. One-leg standing was a balance test on one leg measured in seconds. Cognitive function was measured with the Mini-Mental Status Examination (MMSE) that has scores ranging from 1 to 30, with 30 being a perfect score. Sarcopenia levels were measured with a scale that assessed sluggishness, assistance with walking, rising from a chair, climbing stairs, and fall history. Each item was assessed from 0 to 2, with the total score ranging from 0 to 10. The higher scores indicate greater problems with physical function and capacity. The following study excerpts present data analyses, results, and conclusions.

Relevant study results
“Data analysis
SPSS* software version 26.0 was used for data analyses in this study. Independent t -tests and Pearson’s correlation analyses were performed to test bivariate associations among variables. Multiple linear regression analysis... was conducted to identify the significant determinants of FoF.... Variables significantly associating with FoF ( p -value < 0.10) in bivariate association analysis were simultaneously entered into multiple linear regression analysis. Variables with p -value < 0.05 were considered important determinants of FoF in multiple linear regression.

Results
... Participants included 147 women (61.41%) and 93 men (38.59%) with a mean age of 70.85 (4.24) years. The comorbidity of chronic diseases was not significantly associated with FoF; however, sex, age, education level, duration of diabetes, insulin treatment, HbA1c [hemoglobin A1c] levels, experiencing a hypoglycemia episode during the past year and fall history for the past year were significantly associated with FoF. As shown in Table 15.1 , cognitive function, handgrip strength and one-leg standing test outcomes were significantly and negatively associated with FoF, whereas sarcopenia levels, TUG test outcomes and diabetes distress were significantly and positively associated with FoF.

View full size
TABLE 15.1

DISTRIBUTION OF SARCOPENIA, COGNITIVE FUNCTION, HANDGRIP STRENGTH, TIMED UP AND GO, ONE-LEG STANDING, DIABETES DISTRESS, AND FEAR OF FALLING, AND CORRELATIONS AMONG THEM ( N = 240)

Variables	Mean ( SD )	1	2	3	4	5	6	7
1.
Sarcopenia

0.89 (1.24)	1.00	−0.148 *	−0.293 ***	0.283 ***	−0.065	0.209 ***	0.444 ***
2.
Cognitive function

27.85 (2.88)		1.00	0.185 ***	−0.388 ***	0.169 **	0.014	−0.147 *
3.
Handgrip strength

26.01 (8.59)			1.00	−0.272 ***	0.030	−0.009	−0.182 **
4.
TUG

8.66 (2.57)				1.00	−0.181 **	−0.016	0.322 ***
5.
One-leg standing

19.91(38.02)					1.00	−0.010	−0.152 *
6.
Diabetes distress

9.24 (7.57)						1.00	0.438 ***
7.
Fear of falling

23.03 (7.70)							1.00
Note: SD , standard deviation; TUG, Timed Up and Go Test.

Multiple linear regression for important determinants of FoF
The variance inflation factors ranged between 1.143 and 2.584 while tolerance scores ranged between 0.387 and 0.875, therefore no multicollinearity problems were identified among variables when conducting multiple linear regression analysis. As shown in Table 15.2 , among demographic and illness characteristics, HbA1c levels [β = 0.114, p < 0.05] were significantly and positively associated with FoF. In terms of physical function and capability factors, sarcopenia levels [β = 0.312, p < 0.001] and TUG test outcomes [β = 0.198, p < 0.01] were significantly and positively associated with FoF. In terms of psychosocial factor, diabetes distress [β = 0.333, p < 0.001] was significantly and positively associated with FoF. Regarding cognitive factors, cognitive function was not significantly associated with FoF. The multiple regression model was significant [ F (15, 224) = 11.241, p < 0.001] and accounted for 42.9% of variance in FoF. According to the partial correlation coefficients, diabetes distress, sarcopenia levels, TUG test outcomes and HbA1c levels uniquely explained 14% (0.374 2 ), 9% (0.303 2 ), 4% (0.196 2 ) and 2% (0.133 2 ) of the variance in FoF respectively” ( Inayati et al., 2022 , pp. 9–10).

View full size
TABLE 15.2

MULTIPLE LINEAR REGRESSION FOR FEAR OF FALLING ( N = 240)

Variables	B	SEB	β	Partial Correlation Coefficients
Demographics and Illness Characteristics
Age	0.106	0.109	0.058	0.064
Sex (female)	−2.310	1.210	−0.147	−0.127
Education level (junior high and below)	−1.234	0.924	−0.078	−0.089
Insulin treatment (no)	1.104	0.984	0.069	0.075
Fall history (no)	−0.506	1.142	−0.027	−0.030
Experience of hypoglycemia (no)	0.873	1.080	0.044	0.054
HbA1c level	0.574	0.374	0.114 *	0.133
Body mass index	0.018	0.108	0.009	0.011
Duration of diabetes	−8.271	0.043	0.000	0.000
Physical Function and Capability
Sarcopenia level	1.934	0.406	0.312 ***	0.303
Timed Up and Go	0.591	0.198	0.198 **	0.196
Handgrip strength	0.087	0.073	0.098	0.080
One-leg standing	−0.012	0.011	−0.060	−0.074
Psychosocial Factor
Diabetes distress	0.338	0.056	0.333 ***	0.374
Cognitive Factor				
Cognitive function	0.081	0.158	0.030	0.034
Constant	−2.634	10.886		
R 2			0.429	
F value			11.241 ***	
Note: (), reference category; B , unstandardized regression coefficients; SEB, standard error of unstandardized regression coefficients; β, standardized regression coefficients.

“Conclusions
... These findings highlighted that important determinants of FoF might differ according to the nature of the disease. Diabetes-specific psychosocial and illness characteristics factors should be considered to mitigate FoF among older adults with diabetes. As diabetes distress explained the largest variance in FoF in this study, healthcare providers should be especially aware of diabetes distress among older adults with diabetes and apply diabetes-tailored psychological interventions. Additionally, optimizing glycemic control should be emphasized to older adults with diabetes. Exercise-based interventions can improve sarcopenia and dynamic imbalance and have been demonstrated to reduce FoF among the general population of older adults” ( Inayati et al., 2022 , p. 11).

Study questions

1.
What is the purpose of multiple linear regression analysis?

2.
In the Inayati et al. (2022) study, what was the dependent variable and what was its level of measurement? Identify the predictors (independent variables) that were significantly correlated with the dependent variable in Table 15.1 .

3.
What analysis technique was conducted to determine relationships among the predictor and dependent variables in Table 15.1 ? Was this the appropriate analysis technique? Provide a rationale for your response.

4.
What is the sarcopenia level and how was it measured? What is the clinical importance of this predictor variable?

5.
Which predictor variable in Table 15.1 had the highest correlation with FoF? Provide a rationale for your response.

6.
Was the correlation value in Question 5 statistically significant? Provide a rationale for your response.

7.
On Table 15.1 , what correlation result is r = −0.152 ? Describe in words the meaning of this correlation. Was this correlation statistically significant? Provide a rationale for your response.

8.
What is multicollinearity? Why is it important to test for multicollinearity before conducting multiple linear regression? Was multicollinearity a problem in this study? Provide a rationale for your response.

9.
Based on the regression analysis results, was hemoglobin A1c (HbA1c) a significant predictor of FoF? Provide a rationale for your answer.

10.
What percentage of the variance in FoF was explained by HbA1c? Discuss the clinical importance of this result.

Answers to study questions

1.
Multiple linear regression analysis is conducted to predict an outcome or dependent variable using two or more predictor variables. This analysis is an extension of simple linear regression where more than one independent variable is entered into the analysis to develop a formula for predicting the dependent variable ( Gray & Grove, 2021 ; Kim et al., 2022 ).

2.
The dependent variable was FoF, which was measured with a 16-item, 4-point Likert scale. Likert scales produce ordinal-level data; however, if the scores are normally distributed, the data are analyzed as though at the interval level with parametric statistics. The scores from the Likert scales in this study were analyzed with parametric statistics, indicating they were normally distributed. However, Inayati et al. (2022) should have reported the normality distribution of the data in their study (see Exercise 27 ; Gray & Grove, 2021 ; Waltz et al., 2017 ). In Table 15.1 , six predictor variables—sarcopenia level (also referred to as physical function and capability), cognitive function, handgrip strength, timed up and go (TUG), one-leg standing, and diabetes distress—were significantly correlated with the dependent variable of FoF.

3.
Pearson r correlational analysis was conducted to determine the relationships of the six predictor variables with each other and with the dependent variable, FoF (see Table 15.1 ). Yes, Pearson r is the correct parametric analysis technique calculated to determine relationships between variables measured at the interval and ratio levels (see Exercise 12 ; Grove & Gray, 2023 ). Sarcopenia, diabetes distress, and FoF were measured with Likert scales and cognitive function was measured with MMSE, considered interval-level data (see the answer to Question 2; Gray & Grove, 2021 ; Waltz et al., 2017 ). The handgrip strength, TUG, and one-leg standing data were at the ratio level. Pearson r correlations are computed to determine the effective predictors for regression analysis, which are the variables strongly correlated with the dependent variable but only weakly correlated with each other ( Gray & Grove, 2021 ; Kim et al., 2022 ).

4.
Sarcopenia level is a term used to describe a person’s physical function and capability. The sarcopenia level is measured with a five-item scale that assesses sluggishness, assistance in walking, rising from a chair, climbing stairs, and fall history. The items are scored from 0 to 2, with the total score ranging from 0 to 10. The higher the score, the greater the sarcopenia level, which is associated with poor physical function and capabilities. These poor physical functions increase older adults’ FoF, and their potential to fall.

5.
The predictor sarcopenia level has the highest correlation ( r = 0.444) with the dependent variable FoF. This r value identifies a moderate (0.30–0.50), positive correlation between sarcopenia level and FoF ( Cohen, 1988 ; Grove & Gray, 2023 ). The −1 and +1 are perfect correlation values, indicating the strongest relationships possible. The strength of a relationship increases as the values move toward +1 or −1 and away from zero. In this study, the r = 0.444 is the value closest to +1 and the farthest from 0 ( Gray & Grove, 2021 ).

6.
Yes, the r = 0.444*** is statistically significant. Inayati et al. (2022) used asterisks (*) to identify the significant correlational values. As in the notes under Table 15.1 ,*** indicate that p < 0.001. The level of significance or alpha for this study was set at 0.05. The p value for the correlation of sarcopenia and FoF was < 0.001, which is less than alpha and is statistically significant ( Grove & Gray, 2023 ).

7.
The r = −0.152* is a weak, negative, significant relationship between one-leg standing time and FoF. Study participants who had longer one-leg standing time in seconds had lower FoF scores. This relationship was significant at p < 0.05, as indicated by the single asterisk (*) (see the note under Table 15.1 ). Because p < 0.05 is less than alpha = 0.05 set for this study, the result is statistically significant ( Grove & Gray, 2023 ; Terrell, 2021 ).

8.
Multicollinearity occurs when the predictors in the multiple regression equation are strongly correlated ( r ≥ 0.85) with each other ( Kim et al., 2022 ). This happens in nursing studies, but it can be minimized by careful selection of predictor variables that have limited correlation with each other. If the predictor variables have multicollinearity, this reduces the percentage of variance of the dependent variable that is explained ( Gray & Grove, 2021 ). Inayati et al. (2022, p. 9) reported: “The variance inflation factors ranged between 1.143 and 2.584 while tolerance scores ranged between 0.387 and 0.875, therefore no multicollinearity problems were identified among variables when conducting multiple linear regression analysis.”

9.
Yes, HbA1c was a significant predictor of FoF with β = 0.114* and partial correlation coefficient = 0.133. The * indicates that the value was significant at p < 0.05, which is less than alpha = 0.05, so it is statistically significant.

10.
The percentage of variance = R 2 × 100%. The percentage of variance for HbA1c = 0.133 2 × 100% = 0.0177 × 100% = 1.77%, or rounded to the next whole percent, is 2%. The HbA1c is a limited but significant predictor of FoF. The higher the HbA1c, the greater the FoF in older adults with diabetes. Inayati et al. (2022, p. 11) recommend that “optimizing glycemic control should be emphasized to older adults with diabetes” based on the link to FoF.

EXERCISE 15
Questions for additional study

Name: _____________________________________________________ Class: _______________________

Date: ___________________________________________________________________________________

Follow your instructor’s directions to submit your answers to the following questions for additional study. Your instructor may ask you to write your answers below and submit them as a hard copy for evaluation. Alternatively, your instructor may ask you to submit your answers online.

1.
What are the assumptions for multiple linear regression?

2.
Was multiple linear regression analysis the appropriate statistical technique to calculate in the Inayati et al. (2022) study? Provide a rationale for your response.

3.
On Table 15.1 , what correlation result is r = −0.016? Was this correlation value statistically significant? What does this r value indicate for multiple linear regression?

4.
What is the correlation between TUG and FoF? State in words the relationship between these variables. Was this correlational value significant? Provide a rationale for your response.

5.
What independent variables were significant predictors of FoF? Provide a rationale for your response.

6.
What was the strongest predictor of FoF in this regression model? What percent of the variance in FoF was uniquely explained by this variable? Provide a rationale for your response.

7.
Was the regression model in the Inayati et al. (2022) study significant in predicting FoF? Provide a rationale for your response.

8.
What hypothesis was stated by the researchers? Was this hypothesis accepted or rejected? Provide a rationale for your response.

9.
What percentage of the variance of FoF was explained by the regression model? Provide the calculations for obtaining this value.

10.
Discuss the clinical importance of the regression results in the Inayati et al. (2022) study.

Understanding the independent samples t -test EPUB version of this book
Susan K. Grove, PhD, RN, ANP-BC, GNP-BC; Daisha J. Cipher, PhD

Statistics for Nursing Research, EXERCISE 16, 190-201

Statistical technique in review
The independent samples t -test is a parametric statistical technique calculated to determine differences between the scores obtained from independent or unrelated samples or groups ( Grove & Gray, 2023 ). Groups are independent if the assignment of one participant to a group is unrelated to the assignment of other participants to groups (see Exercise 12 for a discussion of independent groups). For example, when study participants are randomly assigned to either an intervention or control group, the groups are unrelated or independent. Because the t -test is considered fairly easy to calculate, researchers often use it in determining differences between two groups when variables are measured at the interval or ratio level. Jones et al. (2021) examined the statistical tests conducted to analyze data from 667 doctor of nursing practice (DNP) projects. The most frequently calculated parametric analysis techniques were the paired samples t -test ( n = 140; 21%) and the independent samples t -test ( n = 86; 12.9%).

The independent samples t -test is conducted to determine differences between the means ( 
X
¯
) of two groups in a study and adjusts that difference for the variability (computed by the standard error) among the data ( Celentano & Szkla, 2018 ; Gray & Grove, 2021 ; King & Eckersley, 2019 ). When interpreting the results of t -tests, the larger the calculated t value in absolute value, the greater the difference between the two groups. The significance of a t value can be determined by comparison with the critical t values in the statistical table for the t distribution based on the degrees of freedom ( df ) for the study (see Appendix A Critical Values for Student’s t Distribution at the back of this text). The formula for df for an independent t -test is as follows:

df = (number of participants in sample A + number of participants in sample B) − 2
Example df = (50 in sample A + 52 in sample B)–2 = 102–2 = 100
In a hypothetical example, researchers conducted a study to determine the effect of a structured dietary plan on adolescents’ weight loss. The sample included 97 overweight adolescents who were randomly assigned to either an experimental group ( n = 48) or a comparison group ( n = 49). The null hypothesis was: There is no difference in weight loss between the adolescents exposed to the structured dietary plan versus those receiving standard care. The df for this example is computed as follows: (48 + 49) −2 = 95. At the end of 6 months, the groups were significantly different in weight loss with t (95) = 2.393, p < 0.05. Review the critical values for the t distribution in Appendix A and note that t (95) = 1.985, p = 0.05. The t value found in this example is larger than the value in the table, so the result is significant. The p < 0.05 also indicates significance because it is less than the alpha = 0.05 set at the start of the study ( Grove & Gray, 2023 ).

The independent samples t -test is best conducted once to examine differences between two groups in a study, because conducting multiple t -tests on study data can result in an inflated Type I error rate. A Type I error occurs when the researcher rejects the null hypothesis when it is in actuality true. Researchers need to consider other statistical analysis options for their study data rather than conducting multiple t -tests. However, if multiple t -tests are conducted, researchers can perform a Bonferroni procedure to reduce the risk of a Type I error (see Exercise 18 ).

The Bonferroni procedure is a simple calculation in which the alpha is divided by the number of t -tests conducted on different aspects of the study data. For example, if a study’s alpha was set at 0.05 and the researcher planned on conducting five t -tests on the study data, the corrected alpha would be computed as follows: 0.05 ÷ 5 = 0.01. However, it should be noted that the Bonferroni procedure has long been criticized for being too stringent, resulting in overcorrection of alpha. Bender and Lange (1999, p. 601) wrote, “The Bonferroni procedure ignores dependencies among the data and is therefore much too conservative if the number of tests is large.”

Assumptions for the independent samples t -test
The t -test for independent samples or groups includes the following assumptions:

1.
The raw scores or values in the population are normally distributed.

2.
The dependent variable(s) is(are) measured at the interval or ratio levels. A dependent variable measured with a multi-item scale that has normally distributed scores can also be analyzed as though at the interval level ( Waltz et al., 2017 ).

3.
The two groups examined for differences have equal variance, which is best achieved by a random sample and random assignment to groups.

4.
All scores or observations collected within each group are independent or unrelated to other study scores or observations ( Gray & Grove, 2021 ; Kim et al., 2022 ).

The t -test is robust, meaning the results are reliable even if one of the assumptions has been violated. However, the t -test is not robust regarding between-samples or within-samples independence or with respect to extreme violation of normality assumptions. Groups do not need to be of equal sizes but rather of equal variance. Groups are independent if the two sets of data were not taken from the same study participants and if the scores are not related ( Gray & Grove, 2021 ; Plichta & Kelvin, 2013 ). This exercise focuses on interpreting and critically appraising the t -tests results presented in research reports. Exercise 32 provides a step-by-step process for computing the independent samples t -test.

Research article
Source
Kim, H. J., & Hwang, S. Y. (2022) . Effect of website-based learning on improved monitoring and adverse drug reactions by clinical nurses. Asian Nursing Research, 16, 45–51. https://doi.org/10.1016/j.anr.2021.12.004

Introduction
Kim and Hwang (2022) conducted a quasi-experimental study to examine the effects of a website-based learning program on the voluntary monitoring and reporting of adverse drug reactions (ADRs) by clinical nurses. The dependent or outcome variables for this study were: (1) the knowledge on ADRs, measured with a 20-question objective test; (2) self-efficacy or level of confidence in ADR monitoring, measured with a 10-item Likert scale (1–4 points); ADR monitoring in practice, measured with a 10-item Likert scale (1–5 points); and medication performance ability related to ADR monitoring, measured with a six-item Likert-type 5-point scale (1–5 points). The results and conclusions from this study are presented in the following excerpt.

Relevant study results
“Methods
Study design
This study was a quasi-experimental control group pretest-posttest design with random allocation for developing website-based learning content and verifying its effectiveness on voluntary reporting of ADRs in nurses with more than 1 year of clinical experience.

Development of website-based learning contents
The website, including the learning content, was developed according to the web-based learning design model with five steps: analysis, design, development, application, and evaluation. In the analysis stage, in July 2017, 210 clinical nurses were surveyed about their preferred educational form and content for ADR reporting. Among them, 10 individual interviews were conducted to explore the reasons for the difficulty of voluntary reporting....

Setting and participants
The number of samples in this study was calculated based on the evidence of the educational effect with a large effect size in several previous studies on ADR reporting for clinical nurses. Using G*Power program 3.1.9.2, the number of samples that fit the t -test with an effect size of 0.80, significance level of 0.05 for the two-tailed test, and power of 80% was at least 26 in each group. The criteria for selection of participants were nurses working at a university hospital... and general ward nurses with clinical experience of 1 to 25 years, excluding new nurses and chief nurses. New nurses were excluded from the participants because they had little experience with drug side effects and lacked drug-related clinical judgment skills that required critical thinking. To secure the homogeneity of clinical experience among a total of 266 participants who met the criteria, 60 participants were selected through a randomization program (Microsoft Excel), divided into 5 years and less than 5 years, and assigned to an experimental group and a control group. All 60 participants agreed to participate in the study, and there were no dropouts; 30 in the experimental group and 30 in the control group were used for the final analysis” ( Kim & Hwang, 2022 , pp. 46–47).

“Data analysis
The data were analyzed using IBM SPSS Statistics Software Version 21.0 (IBM, Armonk, NY, USA). General characteristics of the participants were analyzed as real numbers, percentages, and mean and standard deviations. The prior homogeneity of the two groups was verified by the chi-square test, Fisher’s exact and t -tests, and the Kolmogorov-Smirnov test for normality, and the Levene’s test for equality of variance. To verify the effect of the intervention, the differences prior to and after the intervention were identified between the experimental group and the control group by independent t -test” ( Kim & Hwang, 2022 , pp 48–49).

“Results
Verification of the Effectiveness of the Website-Based Learning Interventions

1)
Homogeneity test of participant’s general characteristics and variables

As a result of the analysis to verify the homogeneity of the general characteristics and dependent variables of the two groups, there was no statistically significant difference, and the two groups were homogeneous ( Table 16.1 ). In this study, participants visited the website an average of 7.03 times, but mainly used learning content rather than commenting or posting, and mainly asked questions about how to use the program. This appears to be the result of the short mediation period and lack of publicity.

View full size
TABLE 16.1

GENERAL CHARACTERISTICS OF PARTICIPANTS AND HOMOGENEITY TEST FOR DEPENDENT VARIABLES ( N = 60)

Kim, H. J., & Hwang, S. Y. (2022). Effect of website-based learning on improved monitoring and adverse drug reactions by clinical nurses. Asian Nursing Research, 16, 49. https://doi.org/10.1016/j.anr.2021.12.004

Exp. ( n = 30)	Cont. ( n = 30)		
Variables	Categories	n (%) or M± SD	n (%) or M± SD	χ 2 or t	p
Gender	Men	3(10.0)	0(0.0)	3.16	.237 b
Women	27(90.0)	30(100.0)		
Age (years)		31.83 ± 6.68	30.87 ± 5.57	−0.59	.559
Education	College	6(20.0)	5(163)	0.51	.774 b
Bachelor’s	22(733)	24(80.0)		
Master’s	2(6.7)	1(3.3)		
Marital status	Married	10(33.0)	8(26.7)	0.32	.573
Single	20(67.0)	22(73.3)		
Total clinical experience (months)		99.10 ± 82.55	88.8 ± 71.81	0.54	.911
12~<36	7(23.3)	9(30.0)		
36 ≤~<60	8(26.7)	6(20.0)		
60 ≤~<120	7(23.3)	7(233)		
≥120	8(26.7)	8(261)		
Working department	Medical ward	14(46.7)	15(50.0)	0.33	.849
Surgical ward	12(40.0)	10(33.3)		
Others a	4(13.3)	5(16.7)		
Reporting experience	Yes	16(533)	21(70.0)	136	.184
No	14(46.7)	9(30.0)		
Education experience	Yes	18(60.0)	22(73.3)	−1.20	.273
No	12(40.0)	8(26.7)		
Knowledge		14.57 ± 2.42	14.00 ± 2.27	−0.94	.354
Self-efficacy		35.90 ± 431	37.27 ± 5.63	1.06	.296
Monitoring practice		32.83 ± 4.54	33.50 ± 4.29	0.58	.561
Medication performance ability		2127 ± 3.15	20.60 ± 2.46	0.91	.365
Note. Cont. = control group; Exp. = experimental group; M = mean; SD = standard deviation.

2)
Effects of website-based learning on research-dependent variables

The difference in ADR knowledge score of 2.93 ± 2.80 in the experimental group was significantly higher than the 1.20 ± 1.92 found in the control group ( t = −2.80, p = 0.007). The score difference of self-efficacy on ADR monitoring in the experimental group was 3.50 ± 4.99 points, which was significantly higher than the −0.13 ± 5.18 points of the control group ( t = −2.77, p = 0.008). The difference in scores of monitoring ADRs in the experimental group (5.07 ± 6.28) was higher than the 1.27 ± 6.19 found in the control group, and the difference was statistically significant ( t = −2.36, p = 0.022). The difference in post-pre scores of medication performance ability related to ADR monitoring in the experimental group was 1.93 ± 3.29, which was higher than the 0.53 ± 3.19 evident in the control group, but the difference was not statistically significant ( t = −1.67, p = 0.100) ( Table 16.2 )” ( Kim & Hwang, 2022 , pp. 49–50).

View full size
TABLE 16.2

COMPARISON OF VARIABLES BETWEEN THE TWO GROUPS ( N = 60)

Kim, H. J., & Hwang, S. Y. (2022). Effect of website-based learning on improved monitoring and adverse drug reactions by clinical nurses. Asian Nursing Research, 16, 49. https://doi.org/10.1016/j.anr.2021.12.004

Pre	Post	Difference		
Variables	Group	M± SD	M± SD	M± SD	t	p
Knowledge on ADR	Exp.( n = 30)	14.57 ± 2.42	17.50 ± 122	2.93 ± 2.80	−2.80	.007
Cont. ( n = 30)	14.00 ± 2.27	1520 ± 1.85	120 ± 1.92		
Self-efficacy on ADR	Exp. ( n = 30)	35.90 ± 4.30	39.40 ± 5.06	350 ± 4.99	−2.77	.008
Cont. ( n = 30)	37.27 ± 5.63	37.13 ± 6.70	−0.13 ± 5.18		
ADR monitoring practice	Exp. ( n = 30)	32.83 ± 4.54	37.90 ± 536	5.07 ± 628	−2.36	.022
Cont. ( n = 30)	33.50 ± 4.30	34.77 ± 4.91	127 ± 6.19		
Medication performance ability	Exp. ( n = 30)	21.27 ± 3.15	2320 ± 333	1.93 ± 329	−1.67	.100
Cont. ( n = 30)	20.60 ± 2.46	21.13 ± 239	053 ± 3.19		
ADR = adverse drug reaction; Cont. = control group; Exp. = experimental group; M = mean; SD = standard deviation.

“Conclusion
The website content developed in this study included video lectures, case studies about ADRs, information on individual drugs, and FAQs about ADRs. In addition, various notice board functions were used to enable two-way communication such as sharing cases and providing feedback, providing drug safety information issued monthly by the local product safety center, and posting reports related to ADRs. Nurses who learned through the website significantly increased their knowledge of ADRs, self-efficacy, and monitoring practices compared with the control group. Sharing and communication through such an open website induces clinical nurses to practice monitoring for ADRs and activates voluntary reporting, leading to a safer medication culture in hospital settings” ( Kim & Hwang, 2022 , p. 50).

Study questions

1.
What design was used in the study by Kim and Hwang (2022) ? What groups were examined for differences in this study? Were these groups independent or dependent? Provide a rationale for your response with documentation.

2.
What statistical test was conducted by the researchers to examine the effect of the website-based learning intervention in their study? Was this test appropriate for analyzing the data in this study? Provide a rationale for your response.

3.
Kim and Hwang (2022) examined the study groups for differences prior to the implementation of the website-based learning intervention. What is the meaning of these results?

4.
Were the experimental and control groups significantly different for ADR monitoring practice dependent variable preintervention? Provide a rationale for your answer.

5.
What statistics were computed to describe the ADR monitoring practices pretest and posttest? What were the results from these calculations and what did these results indicate?

6.
State the null hypothesis for the dependent variable knowledge on ADR in this study. What statistical test was conducted to test this hypothesis?

7.
Were the groups significantly different for the dependent variable knowledge on ADR? Provide a rationale for your response. Was the null hypothesis in Question 6 accepted or rejected?

8.
What can cause an increased risk for Type I errors when t -tests are conducted in a study? How might researchers reduce the increased risk for a Type I error in a study?

9.
Were the experimental and control groups significantly different for the dependent variable self-efficacy on ADR? Provide these results and discuss the meaning of them.

10.
Kim and Hwang (2022) conducted the Pearson’s chi-square test to analyze the differences in marital status and working department (see Table 16.1 ) between the experimental and control groups. Would an independent samples t -test be appropriate to analyze the data for these demographic variables in this study (review algorithm in Exercise 12 )? Provide a rationale for your answer.

Answers to study questions

1.
Kim and Hwang (2022, p. 46) conducted “a quasi-experimental control group pretest-posttest design” to determine the effectiveness of a website-based learning intervention on clinical nurses’ voluntary monitoring and reporting of ADRs. Study participants were randomly assigned to either the experimental group or control group, which indicates that the groups were independent or unrelated ( Gray & Grove, 2021 ; Shadish et al., 2002 ).

2.
Independent samples t -tests were conducted to examine the effectiveness of the website-based learning intervention on selected outcomes. The experimental group was provided the website-based content that included real cases, latest drug-related knowledge, and video lectures on ADR. The control group received a small notebook for monitoring ADRs of nurses. Yes, this analysis technique was appropriate to determine differences between the independent groups (experimental and control) created by random assignment. The knowledge variable was measured by an objective test (ratio-level data) and the other three dependent variables were measured with Likert scales (ordinal-level data). However, the data for all variables were normally distributed, so the Likert-scale data could be analyzed with t -tests ( Bandalos, 2018 ; Waltz et al., 2017 ).

3.
The experimental and control groups were examined for differences related to the demographic characteristics and the dependent variables at the beginning of the study. The independent samples t -tests and chi-square tests were nonsignificant for all the variables examined because the p values were all greater than the alpha set at 0.05 for this study (see Table 16.1 ). These nonsignificant results indicate the experimental and control groups were similar or equivalent for these variables at the beginning of the study. Therefore Kim and Hwang (2022) can conclude the significant differences found between the two groups at the end of the study were probably because of the effects of the intervention rather than sampling error or initial group differences ( Gray & Grove, 2021 ; Kim et al., 2022 ; Terrell, 2021 ).

4.
No, the experimental and control groups were not significantly different for the ADR monitoring practice variable preintervention. The t = 0.58, p = 0.561 is nonsignificant because the p value is greater than the alpha = 0.05 set prior to the study ( Grove & Gray, 2023 ).

5.
For the ADR monitoring practice variable, 
X
¯
 and standard deviations ( SD s) were computed for both the experimental and control groups preintervention and postintervention and also differences scores. For the experimental group, the preintervention descriptive statistics were ( 
X
¯
) ± SD = 32.83 ± 4.54; and those postintervention were ( 
X
¯
) ± SD = 37.90 ± 5.36, with a difference score of ( 
X
¯
) ± SD = 5.07 ± 6.28. For the control group, the preintervention descriptive statistics were ( 
X
¯
) ± SD = 33.50 ± 4.30; and those postintervention were ( 
X
¯
) ± SD = 34.77 ± 4.91, with a difference score of ( 
X
¯
) ± SD = 1.27 ± 6.19. The experimental and control groups were similar for ADR monitoring practice before the intervention, but there was a greater increase in the experimental group mean (5.07 points) after the website-based intervention than the control group (1.27 points).

6.
The null hypothesis is: There is no difference in the knowledge on ADR between the clinical nurses in the experimental group receiving the website-based intervention and the control group receiving a notebook . The independent samples t -test was conducted to examine group differences.

7.
Yes, the experimental and control groups were significantly different for knowledge on ADR because t = −2.80, p = 0.007. The p value indicates significant results because it is less than the alpha = 0.05 set for this study. The study findings are significant, so the null hypothesis in Question 6 should be rejected ( Gray & Grove, 2021 ; Terrell, 2021 ).

8.
The computation of multiple t -tests on data for dependent variables can cause an increased risk for Type I errors (see Table 16.2 ). Computing t -tests on demographic characteristics (see Table 16.1 ) does not increase the risk of a Type I error. The Bonferroni procedure can be calculated to reduce the risk of a Type I error in studies with multiple t -tests; however, many researchers consider this alpha correction to be too stringent, so it should be used with caution ( Celentano & Szklo, 2018 ).

9.
The experimental and control groups were significantly different for the dependent variable of self-efficacy on ADR, because t = −2.77, p = 0.008. The p value is less than the alpha = 0.05, so the result is statistically significant. This result means that clinical nurses exposed to the website-based learning content had significantly higher self-efficacy or confidence in adapting to the ADR monitoring task than the control group ( Grove & Gray, 2023 ; Terrell, 2021 ).

10.
No, the independent samples t -test would not have been appropriate to analyze the differences in marital status and working department between the experimental and control groups. These demographic variables were measured at the nominal level because they had exhaustive and mutually exclusive categories that could not be ranked (see Exercise 1 ; Grove & Gray, 2023 ; Waltz et al., 2017 ). Thus the chi-square test is the appropriate statistic for analyzing these demographic variables measured at the nominal level (see Exercises 1 , 12 , and 19 ).

EXERCISE 16
Questions for additional study

Name: _____________________________________________________ Class: _______________________

Date: ___________________________________________________________________________________

Follow your instructor’s directions to submit your answers to the following questions for additional study. Your instructor may ask you to write your answers below and submit them as a hard copy for evaluation. Alternatively, your instructor may ask you to submit your answers online.

1.
What does df mean? Kim and Hwang (2022) did not provide the df in their study. Why is it important to know the df for a t value? Using the df formula, calculate the df for this study.

2.
What are the 
X
¯
s and SD s for age for the experimental and control groups? What statistical analysis was conducted to determine the difference in means for age for the two groups at the beginning of the study? Was this an appropriate analysis technique? Provide a rationale for your answer.

3.
What are the t and p values for age? What do these results mean?

4.
What are the assumptions for conducting the independent samples t -test?

5.
Were the assumptions identified in Question 4 met by Kim and Hwang (2022) in their study? Provide a rationale for your response.

6.
State the null hypothesis for the ADR monitoring practice between the experimental and control groups of clinical nurses.

7.
Was the null hypothesis stated in the an

Understanding the paired samples t -test EPUB version of this book
Susan K. Grove, PhD, RN, ANP-BC, GNP-BC; Daisha J. Cipher, PhD

Statistics for Nursing Research, EXERCISE 17, 202-213

Statistical technique in review
The paired or dependent samples t -test is a parametric statistical technique conducted to determine differences between two sets of repeated measures data from one group of individuals. The scores used in the analysis might be obtained from the same study participant under different conditions, such as the one-group pretest–posttest design ( Gray & Grove, 2021 ). With this type of design, a single group of participants experiences the pretest, treatment or intervention, and posttest. Participants are referred to as serving as their own control during the pretest, which is then compared with the posttest scores after the intervention. Fig. 17.1 presents the pretest–posttest design ( Gray & Grove, 2021 ; Terrell, 2021 ).

A diagram shows the process of an experimental group with pretest, treatment and posttest steps. The diagram shows a sequence for an experimental group. The process starts with a box labeled pretest under the heading measurement of dependent variable. An arrow points to a second box labeled treatment or intervention under the heading manipulation of independent variable. Another arrow points to a third box labeled posttest under the heading measurement of dependent variable.
FIG. 17.1 ■
ONE-GROUP PRETEST–POSTTEST DESIGN.

Paired or dependent scores also result from a one-sample repeated measures design, where one group of participants are assessed two or more times and the means ( 
X
¯
s) of these assessments are compared. Paired samples t -tests can also be applied to a crossover study design, in which participants receive one kind of treatment or intervention and subsequently receive a comparison treatment ( Celentano & Szklo, 2018 ; Gliner et al., 2017 ). For example, one group of participants could be exposed to two different amounts, high and low, of aspartame, which is included in artificial sweeteners. The outcomes for each participant for each amount of aspartame are measured, resulting in paired scores.

The one-group design is considered a weak quasi-experimental design because it is difficult to determine the effects of a treatment without a comparison to a separate control group ( Gray & Grove, 2021 ; Shadish et al., 2002 ). However, the t -test is the simplest statistic to conduct when comparing two means. Jones et al. (2021) examined the statistical tests conducted in 667 doctor of nursing practice (DNP) projects and found the paired samples t -test was the most commonly conducted statistical test ( n = 140, 21%). Over time, DNP projects need to be conducted with stronger designs that produce data that can be analyzed with more powerful statistical techniques ( Gray & Grove, 2021 ).

Assumptions for the paired samples t -test
The assumptions for the paired samples t -test are as follows:

1.
The distribution of scores is normal or approximately normal.

2.
The dependent variable(s) is(are) measured at interval or ratio levels. A dependent variable measured with a multi-item scale that has normally distributed scores can also be analyzed as though at the interval level ( Waltz et al., 2017 ).

3.
Repeated measures data are collected from one group of study participants, resulting in paired scores.

4.
The differences between the paired scores are independent ( Gray & Grove, 2021 ; Kazdin, 2022 ; Shadish et al., 2002 ).

The degrees of freedom ( df ) for the paired samples t -test are calculated using the following formula: df = N −1, where the N represents the sample size ( Terrell, 2021 ). For example, if the study included a sample size of 68, the df = 68 − 1 = 67.

Another research design for which paired samples t -tests are appropriate is the case control research design ( Kazdin, 2022 ). Case control designs involve a matching procedure whereby a control participant is matched to each case, in which the cases and controls are different people but matched demographically. The study participants in the two groups could be matched for age, diagnosis, or severity of illness that might affect the study outcomes. Matching the intervention and control group for selected demographic variables controls the effect of these variables and strengthens the design ( Gray & Grove, 2021 ; Shadish et al., 2002 ).

Research article
Source
Williams, T., Kennedy-Malone, L., Thompson, J., & Monge, E. C. (2022 ). The effect of an exergame on physical activity among older adults residing in a long-term care facility: A pilot study. Geriatric Nursing, 44 , 48–53. https://doi.org/10.1016/j.gerinurse.2022.01.001

Introduction
Williams and colleagues (2022) conducted a quasi-experimental study to determine the effects of arranged residential video games on the health outcomes of older adults. The intervention included a Nintendo Wii video gaming system that was implemented for 6 weeks with long-term care (LTC) residents. The Wii system included several exergame options such as tennis, baseball, and bowling. The bowling option was selected because it had an option for multiple players and could be used by those who could stand, as well as those in a wheelchair. The outcome variables were exercise benefits, exercise barriers, self-efficacy or confidence in exercise ability, and physical activity levels. The dependent variables of exercise benefits and barriers were measured with the Exercise Benefits and Barriers Scale (EBBS). The EBBS was a 43-item Likert scale that included two subscales: one focused on benefits and the other on barriers. The responses for the EBBS items ranged from 4 (strongly agree) to 1 (strongly disagree). This scale was not developed for use in LTC facilities. The self-efficacy for exercise variable was measured with the Self-Efficacy for Exercise (SEE) scale. The SEE included 11 items that were scored from 0 (no confidence) to 10 (very confident) to assess the participants’ confidence in their ability to exercise. The Rapid Assessment of Physical Activity (RAPA) questionnaire was used to assess the participants’ level of physical activity. The RAPA included nine items with scores that ranged from 1 (rarely or never do any physical activity) to 7 (≥ 20 min per day of vigorous physical activity ≥ 3 days a week).

Williams et al. (2022) reported limitations of sample size and lack of the sample’s representation of the population. In addition, the attendance at the different sessions of the intervention was limited, with only six participants attending all 12 sessions. However, despite these limitations, the researchers encouraged directors of LTC facilities to organize exergames to improve the residents’ overall purposeful physical activity. The design, sample, and key results are presented in the following study excerpt.

Relevant study results
“Methods
Design
A pre-posttest single group quasi-experimental cross-sectional design was chosen for this pilot study to evaluate the feasibility of the intervention implementation as well as changes in outcomes following the intervention. The intervention was conducted at four long-term care facilities in central NC [North Carolina]. The Nintendo Wii was used in a physical activity intervention....

Sample
Our target population consisted of individuals capable of consenting who resided in long-term care [LTC] facilities located in two counties in central NC.... Within the LTC facility was a dedicated space secured by the facility liaison with a television in where the intervention took place.... An a priori power analysis was conducted... to determine an appropriate sample size. To detect medium to large effect size of 0.062 [probably a typographical error and should be 0.62] using a two-sided paired t -test, an alpha level of 0.05 and 80% power, this study needed at least 24 participants after accounting for 20% attrition” ( Williams et al., 2022 , p. 49).

“Data analysis
Descriptive statistics ( n, %) were conducted on participant attendance to determine feasibility of the 12-session intervention. Benefits, barriers, and self-efficacy were compared between pre- and post-intervention using paired t -tests and physical activity was examined using a Wilcoxon signed-rank test due to deviations from normality. Statistical analysis was conducted using IBM SPSS version 25 with alpha set to 0.05.

Results
Participant characteristics
Of the 29 consenting participants, one had an unexpected hospitalization and subsequently passed away; three participants dropped out and did not state reasons for the withdrawal; and one contracted a contagious illness which required isolation and did not return. The final sample size for this study was N = 24. Participants were long-stay residents of the four facilities.... The majority of the participants were female ( n = 16, 65.6%) and self-identified as Caucasian ( n = 20, 83.3%). The ages of participants ranged from 55–93, with the average age of 79.97 ( SD = 10.35). Most of the participants had lived in the LTC facility between 2–5 years (33.3%)” ( Williams et al., 2022 , p. 50).

“Perceptions of exercise benefits/barriers and self-efficacy for exercise
Paired t -test results for EBBS and SEE questionnaire mean scores are displayed in Table 17.1 . The findings revealed a nonsignificant improvement in participants’ perceptions of exercise benefits and barriers resulting from the intervention, though not statistically significant ( p s = 0.900 and 0.310, respectively). The perceptions of exercise barriers scores ranged from 22–37 at preintervention and 16–37 at postintervention. The perceptions of exercise benefits scores ranged from 31–81 at pretest and 29–79 at posttest. Mean self-efficacy for exercise scores as measured by the SEE questionnaire improved although not statistically significantly ( p = 0.200). Self-efficacy for exercise scores ranged from 0.91 to 9.1 at preintervention and from 0.0 to 9.1 at postintervention.

View full size
TABLE 17.1

PAIRED t -RESULTS FOR PERCEIVED EXERCISE BENEFITS/BARRIERS AND SELF-EFFICACY FOR EXERCISE

Source: Williams, T., Kennedy-Malone, L., & Monge, E. C. (2022). The effect of an exergame on physical activity among older adults residing in a long-term care facility: A pilot study. Geriatric Nursing, 44 , 51. https://doi.org/10.1016/j. gerinurse.2022.01.001

Outcome	Preintervention (mean ± SD )	Postintervention (mean ± SD )	t	df	Significance
EBBS benefits	52.1 ± 12.1	52.4 ± 12.0	−0.13	23	0.900
EBBS barriers	30.6 ± 3.4	29.6 ± 4.5	1.04	23	0.310
SEE self-efficacy	4.8 ± 2.1	5.3 ± 2.0	−1.31	23	0.200
SEE = Self-Efficacy for Exercise Scale; EBBS = Exercise Benefits and Barriers Scale.

Note: EBBS barriers are scored such that lower scores indicate fewer barriers.

Rapid assessment of physical activity
The highest score with an affirmative response on the RAPA questionnaire was recorded for each patient at pre- and postintervention. Preliminary analyses revealed deviations from normality for the RAPA scores (Shapiro-Wilks’ p < 0.05), therefore RAPA scores were examined using a nonparametric Wilcoxon signed rank test. The median score on the RAPA increased from 3.0,... albeit not significantly ( Z = −0.82, p = 0.410)” ( Williams et al., 2022 , p. 51).

Study questions

1.
Identify and describe the design for the Williams et al. (2022) study.

2.
What independent (intervention) and dependent (outcome) variables were included in this study?

3.
Are independent or dependent (paired) scores examined in this study? Provide a rationale for your response.

4.
What inferential statistical technique was calculated to examine differences in the participants’ EBBS benefits, EBBS barriers, and self-efficacy scores before and after the 6-week physical activity intervention? Is this technique appropriate? Provide a rationale for your response.

5.
What statistical techniques were calculated to describe the preintervention EBBS benefits subscale? Were these techniques appropriate? Provide a rationale for your response.

6.
Compare the descriptive analysis values for the preintervention and postintervention for the EBBS benefits subscale. What do these results indicate?

7.
State the null hypothesis for the EBBS benefits variable in this study.

8.
What is the t -test value for the EBBS benefits variable preintervention and postintervention? Is this result significant? Provide a rationale for your response. Was the hypothesis in Question 7 accepted or rejected?

9.
Examine the t values in Appendix A . What t value would be significant at the 0.05 level for a two-tailed t -test in a study with N = 24 participants? Discuss the meaning of these results.

10.
Was there a significant difference in the participants’ EBBS barriers variable between the preintervention and postintervention? Provide a rationale for your answer. Is this result clinically important?

Answers to study questions

1.
Williams et al. (2022, p. 49) clearly reported they used “A pre-posttest single group quasi-experimental cross-sectional design.” The study design is presented in Fig. 17.1 of this exercise. The study was identified as a pilot to examine the feasibility of implementing an exergame intervention with LTC residents and to examine its effects on the outcomes of benefits, barriers, self-efficacy, and physical activity level in four LTC facilities ( Gray & Grove, 2021 ; Shadish et al., 2002 ).

2.
The independent variable or intervention was the Nintendo Wii exergame of bowling. The dependent variables or outcomes were EBBS benefits, EBBS barriers, self-efficacy of exercise confidence, and physical activity level.

3.
Dependent scores were analyzed in this study because only one group of 24 participants was included. The dependent variables for all participants were measured as the pretest followed by the 6-week exergame intervention, and then the posttest. The pretest scores served as a control to be compared with the posttest scores, resulting in paired scores ( Gray & Grove, 2021 ; Kazdin, 2022 ; Terrell, 2021 ).

4.
Paired samples t -tests were conducted to examine differences in the participants’ EBBS benefits, EBBS barriers, and self-efficacy scores before and after the physical activity exergame intervention. Table 17.1 identifies the statistical technique as paired samples t -test. This statistical technique is appropriate because the study included one group and the participants’ scores were dependent, obtained as a pretest prior to the intervention followed by a posttest (see answer to Question 3; Gray & Grove, 2021 ; Terrell, 2021 ). The dependent variables of EBBS benefits, EBBS barriers, and self-efficacy were measured using Likert scales, resulting in ordinal-level data. However, the scores for these variables were normally distributed and were analyzed as interval-level data using the paired t -test ( Bandalos, 2018 ; Waltz et al., 2017 ).

5.
A mean and standard deviation ( SD ) were calculated to describe the EBBS benefits variable preintervention. The 
X
¯
 = 52.1 and SD = 12.1. The data from the EBBS benefits subscale was ordinal (see the answer to Question 4). However, the data were normally distributed and were analyzed as interval using 
X
¯
 and SD , which are appropriate for describing variables measured at the interval or ratio level (see Exercise 1 ; Bandalos, 2018 ; Grove & Gray, 2023 ; Waltz et al., 2017 ).

6.
The EBBS benefits variable had preintervention 
X
¯
 = 52.1 and SD = 12.1 and postintervention 
X
¯
 = 52.4 and SD = 12.0. The 
X
¯
s were essentially the same; they varied by only 0.30. These results indicate there was minimal change after the intervention. The SD s were almost the same (12.1 versus 12.0), indicating similar dispersion or spread of the EBBS benefits scores.

7.
Null hypothesis: There is no change in the EBBS benefits outcome from before and after the physical activity exergame intervention.

8.
The paired t -test result was t (23) = −0.13, p = 0.900 for the EBBS benefits variable preintervention and postintervention. This result is not statistically significant because p = 0.900 is greater than the alpha that was set at 0.05 for this study ( Grove & Gray, 2023 ). When the results from a study are not statistically significant, the null hypothesis is accepted.

9.
Identify the section of the table focused on two-tailed tests and the alpha = 0.05. The df = N − 1, which is 24 − 1 = 23 in this study (see Table 17.1 ). The t value for alpha = 0.05, or t (23) = 2.069. This critical t value (2.069) from Appendix A supports that the t -test results in Table 17.1 are nonsignificant. The study t values are less than the critical t value.

10.
The t (23) = 1.04, p = 0.310 for the EBBS barriers variable is a nonsignificant result. The p = 0.310 is greater than the alpha = 0.05 set for this study, making the result nonsignificant. The physical activity exergame intervention did not significantly change the EBBS barriers variable. The minimal change in EBBS barriers scores from preintervention to postintervention did not support the use of the exergame intervention in practice.

EXERCISE 17
Questions for additional study

Name: _____________________________________________________ Class: _______________________

Date: ___________________________________________________________________________________

Follow your instructor’s directions to submit your answers to the following questions for additional study. Your instructor may ask you to write your answers below and submit them as a hard copy for evaluation. Alternatively, your instructor may ask you to submit your answers online.

1.
What are the assumptions for conducting a paired or dependent samples t -test in a study?

2.
Which of the assumptions in Question 1 do you think were met in the Williams et al. (2022) study? Provide a rationale for your response with references.

3.
Were the scores for self-efficacy, as measured by the SEE, normally distributed for the LTC residents participating in the Wii bowling exergame? Provide a rationale for your response.

4.
What is the paired t -test value for self-efficacy for the LTC residents participating in the physical activity exergame? Is this result statistically significant? Provide a rationale for your response.

5.
State the null hypothesis for self-efficacy outcome that was assessed in this study. Was this hypothesis accepted or rejected? Provide a rationale for your response.

6.
Examine the t values in Appendix A . What t value would be significant at the 0.05 level for a one-tailed t -test in a study with 101 participants? What does this result indicate?

7.
Were the scores for physical activity, as measured by the RAPA questionnaire, normally distributed for the LTC residents participating in the Wii bowling exergame? Provide a rationale for your response.

8.
What analysis technique was conducted to examine preintervention and postintervention differences for physical activity level of LTC residents? Was physical activity significantly changed from preintervention to postintervention for the residents participating in the Wii bowling ex

Understanding analysis of variance and post hoc analyses EPUB version of this book
Susan K. Grove, PhD, RN, ANP-BC, GNP-BC; Daisha J. Cipher, PhD

Statistics for Nursing Research, EXERCISE 18, 214-225

Statistical technique in review
Analysis of variance (ANOVA) is a parametric statistical technique conducted to determine whether a statistically significant difference exists among the means of three or more groups. There are different types of ANOVAs, with the most basic being the one-way ANOVA . This analysis is conducted when a study has one independent variable and one dependent variable. The data collected for the dependent variable should be normally distributed and achieve an interval- or ratio-level of measurement ( Kim et al., 2022 ). This exercise focuses on the one-way ANOVA and introduces you to the repeated-measures ANOVA. The repeated-measures ANOVA is used to analyze data from studies where the same variable(s) is(are) repeatedly measured over time for a group or groups of study participants. The intent is to determine the change that occurs over time in the dependent variable(s) with exposure to the independent variable(s). More information about repeated-measures ANOVA and other types of ANOVA, such as multivariate ANOVA, factorial ANOVA, and analysis of covariance (ANCOVA), can be found in nursing research and statistical texts ( Gray & Grove, 2021 ; Heavy, 2019 ; Kim et al., 2022 ; Terrell, 2021 ).

The outcome of ANOVA is a numerical value for the F statistic. The calculated F -ratio from ANOVA indicates the extent to which group means differ, while considering the variability within the groups.

F = Differences between groups/Differences within groups
ANOVA is similar to the independent samples t -test because both techniques are conducted to determine group differences (see Exercise 16 ). The null hypothesis tested is: No differences exist between the means of the groups studied. The null hypothesis is rejected when the analysis yields a smaller p value, such as p = 0.022, than the alpha = 0.05 set for the study. However, t -tests are conducted to determine the difference between two groups, because conducting multiple t -tests in a study with three or more groups results in an inflated Type I error. Thus ANOVA is the accurate statistic to conduct when a study includes more than two groups ( Grove & Gray, 2023 ; Knapp, 2017 ).

Assuming the null hypothesis of no differences among the means of the groups studied is true, the probability of obtaining an F -ratio as large as the obtained value in each sample is determined by the calculated p value. If the p value is greater than the level of significance, or alpha, set for the study, then the study results are nonsignificant and the F -ratio will be less than the critical value for F in the statistical table (see Appendix C , Critical Values of F for alpha = 0.05 and alpha = 0.01 at the back of this text). With nonsignificant results, researchers will accept the null hypothesis of no significant differences among the groups’ means. However, there is always a possibility that this decision is in error, and the probability of committing this Type I error is determined by alpha. When alpha = 0.05, there are 5 chances in 100 that the results are a Type I error or concluding something is significant when it is not. When alpha = 0.01, there is 1 chance in 100 that the results are a Type I error ( Grove & Gray, 2023 ; Kim et al., 2022 ).

ANOVA assumptions and results
Conducting an ANOVA requires addressing the following assumptions:

1.
The populations from which the samples were drawn, or the random samples, are normally distributed (i.e., the dependent variable should be normally distributed).

2.
The dependent variable is measured at the interval or ratio level.

3.
The measurements or observations of the dependent variable are independent.

4.
The groups should be mutually exclusive.

5.
The groups should have equal variance, also known as homogeneity of variance ( Gray & Grove, 2021 ; Kim et al., 2022 ).

Researchers who analyze their data by conducting an ANOVA report their results in an ANOVA summary table or in the text of the research report. An example of how an ANOVA result is commonly expressed in the text of a study is as follows:

F (2,120) = 4.79, p = 0.01
where:

■
F is the statistic.

■
2 is the group degrees of freedom ( df ) calculated by k − 1, where k = number of groups in the study. In this example, k − 1 = 3 − 1 = 2.

■
120 is the error degrees of freedom ( df ) that is calculated based upon the number of participants, or N − k. In this example, 123 participants − 3 groups = 120 error df.

■
4.79 is the F -ratio or value.

■
p indicates the significance of the F -ratio in this study or p = 0.01.

The F value is calculated by computer with its p value to indicate its significance. As discussed earlier, the F value can also be compared with the critical values of F presented in Appendix C to determine significance. The critical F value with alpha = 0.05 for F (2,120) is 3.07. In this example, the calculated F value is significant because it exceeds the critical F value in the table. In examining the critical values of F at alpha = 0.01, you note that F (2,120) = 4.79.

Post hoc analyses following ANOVA
When a significant F value is obtained from the conduct of ANOVA, additional analyses are needed to determine the specific location of the differences in a study with more than two groups. Post hoc analyses were developed to determine where the differences lie, because some of the groups might be different and others might be similar. For example, a study might include three groups: an experimental group (receiving an intervention), a placebo group (receiving a pseudo or false treatment), and a comparison group (receiving standard care). The ANOVA resulted in a significant F -ratio or value, but post hoc analyses are needed to determine the exact location of the differences. With post hoc analyses, researchers might find that the experimental group is significantly different from both the placebo and comparison groups but that the placebo and comparison groups were not significantly different from each other. As discussed earlier, three t -tests could be conducted to determine differences among the groups, but that would inflate the Type I error ( Grove & Gray, 2023 ; Kim et al., 2022 ). Thus post hoc analyses were developed to detect the differences after ANOVA with a significant F value. The frequently conducted post hoc analyses include the Newman-Keuls test, the Tukey Honestly Significant Difference (HSD) test, the Scheffé test, and the Dunnett test ( Gray & Grove, 2021 ; Kim et al., 2022 ; Terrell, 2021 ).

With many post hoc analyses, the alpha level is reduced in proportion to the number of additional tests required to locate the statistically significant differences. As the alpha level is decreased, reaching the level of significance becomes increasingly more difficult. The Newman-Keuls test compares all possible pairs of means and is the most liberal of the post hoc tests discussed here. “Liberal” indicates that the alpha is not as severely decreased. The Tukey HSD test computes one value with which all means within the dataset are compared. It is considered more stringent than the Newman-Keuls test and requires approximately equal sample sizes in each group. The Scheffé test is one of the more conservative post hoc tests, but with the decrease in Type I error there is an increase in Type II error, which is concluding something is not significant when it is. The Dunnett test requires a control group, and the experimental groups are compared with the control group without a decrease in alpha. Exercise 35 provides the step-by-step process for calculating ANOVA and post hoc analyses.

Research article
Source
Meehan, C. D., & Barker, N. (2021 ). Remediation for NCLEX-RN success in high-risk nursing students. Teaching and Learning in Nursing, 16, 254–257. https://doi.org/10.1016/j.teln. 2021.02.003

Introduction
The pass rate on the National Council Licensure Exam for Registered Nurses (NCLEX-RN) is frequently used as one of the outcomes for determining the success of undergraduate nursing programs. Meehan and Barker (2021, p. 254) conducted a retrospective cohort study to determine whether a “remediation protocol would improve undergraduate baccalaureate predictor scores for passing the NCLEX-RN on the first attempt for high-risk students.” The students completed either four semesters of remediation, two semesters of remediation, or no remediation for the classes of 2016, 2017, and 2018. This study included eight groups that are identified in Table 18.1 . The eight groups included three groups of traditional students, three groups of second-degree students, and two groups of out-of-sequence students. The key results for this study are presented in the following excerpt.

View full size
TABLE 18.1

COMPREHENSIVE PREDICTOR SCORES FOR TRADITIONAL AND SECOND-DEGREE STUDENTS

Groups	Count	Sum	Average Score
A traditional (no remediation)	50	3426.8	68.536
B traditional (two semesters remediation)	45	3093.4	68.742
C traditional (four semesters remediation)	51	3750.8	73.545
X traditional (out of sequence, 0 semesters remediation)	5	311.4	62.28
Z traditional (out of sequence, one semester remediation)	11	726	66
D Second degree (no remediation)	30	2052.3	68.41
E Second degree (two semesters remediation)	32	2354.7	73.584
F Second degree (four semesters remediation)	34	2664	78.353
Relevant study results
“In this study, researchers compared student scores on the Assessment Technologies Institute’s (ATI) Comprehensive Predictor Exam. A comparison was made between senior students who participated in a formalized remediation program and those that did not. From the spring of 2016 through the spring of 2018, a total of 162 traditional undergraduate nursing students completed the Comprehensive Predictor Exam. Additionally, 96 second-degree nursing students completed the Comprehensive Predictor Exam from December 2016 through December 2018. Traditional students from cohort A had no implemented remediation program while cohort B had some remediation and cohort C completed two years of a formalized remediation program. Similarly, second-degree students in cohort D had no implemented remediation program, cohort E had some remediation, and cohort F completed four semesters of a formalized remediation program [ Table 18.1 ]. Additionally, 16 out-of-sequence students’ data were included in the results. These students had failed one or more nursing courses. Although the Comprehensive Predictor has been determined to accurately project a student’s likelihood to pass the NCLEX-RN, this study examined the effects of remediation on the Comprehensive Predictor scores in relation to remediation throughout the nursing program....

A one-way between-subjects ANOVA was conducted to compare the effect of a remediation policy on nursing students enrolled in an undergraduate program in their last semester of a baccalaureate nursing program. Remediation had a significant effect on undergraduate nursing students’ standardized testing at the p < 0.05 level for six cohorts consisting of F (7,250) = 9.04 and a p value of 0.0000000006 [ Table 18.2 ]. Post hoc comparisons using the Tukey HSD test indicated that the mean score for those that received remediation was significantly different than those that did not in similar cohorts. These results would support the integration of remediation within nursing programs to improve a student’s success on predictive NCLEX-RN practice exams.... Students who participated in the full remediation program achieved a minimal score of 73.84% and had at least a 95% likelihood of passing the NCLEX-RN on their first attempt. Students who did not participate in any remediation program did not score over 68.53%” ( Meehan & Barker, 2021 , p. 256).

View full size
TABLE 18.2

ANOVA

Source of Variation	SS	df	MS	F	p value	F crit
Between groups	3757.095	7	536.728	9.040	0.0000000006	2.046
Within groups	14842.853	250	59.371			
Total	18599.948	257				
This study indicated that the implementation of a formalized remediation program improved the predictor exam scores for students preparing for the NCLEX-RN.

Study questions

1.
Describe the type of design used by Meehan and Barker (2021) in their study.

2.
What were the independent and dependent variables included in this study?

3.
How was the dependent variable measured for this study? What level of measurement was achieved for this variable? Provide a rationale for your answer.

4.
Identify the number and types of groups that were examined for differences.

5.
What type of analysis was conducted in this study to examine group differences? Was that an appropriate analysis technique? Provide a rationale for your answer.

6.
What are the assumptions for use of ANOVA?

7.
What did the researcher set the level of significance, or alpha, at for this study? What is the potential for Type I error with this level of alpha?

8.
State the null hypothesis for the Meehan and Barker (2021) study.

9.
What were the ANOVA results for this study? Should the null hypothesis be accepted or rejected? Provide a rationale for your answer.

10.
Was group A significantly different than group C? What do these results indicate?

Answers to study questions

1.
Meehan and Barker (2021) conducted a retrospective cohort study. Retrospective means looking back in time and involves collecting data from existing records or databases for analysis. Cohorts are groups or categories of groups that are included in a study. In this study, data were exit exam scores obtained from a convenience sample of nursing students’ records in the final semester of their undergraduate program ( Gray & Grove, 2021 ).

2.
The independent variable was the remediation protocol. The dependent or outcome variable was the student scores on the ATI Comprehensive Predictor Exam.

3.
The dependent variable was measured using the ATI Comprehensive Predictor Exam. This exam is a standardized test used to predict nursing students’ performance on the NCLEX-RN exam. The data obtained with the ATI exam are at the ratio level with equal interval categories and an absolute zero (see Exercise 1 ; Grove & Gray, 2023 ).

4.
The Meehan and Barker (2022) study included eight groups that are identified in Table 18.1 . Three groups included traditional students, three groups included second-degree students, and two groups included out-of-sequence students who had failed a nursing course. The traditional and second-degree students had one of the following: no remediation, two semesters of remediation, or four semesters of remediation. The out-of-sequence students had either no remediation or one semester of remediation.

5.
Meehan and Barker (2021) reported they conducted a one-way ANOVA to determine differences among the eight groups of nursing students in their study (see Table 18.1 ). The one-way ANOVA was appropriate because the study included one independent variable (remediation) and one dependent variable (ATI exam scores). The exam scores were independent and at the ratio level of measurement. Because this study focused on examining differences among multiple groups, the ANOVA statistical technique was the most appropriate (see Fig. 12.1 ; Gray & Grove, 2021 ).

6.
The five assumptions for the ANOVA statistical technique are that there is a normal distribution of the populations from which the samples were drawn; that the dependent variable is measured at the interval or ratio level; that measurements of the dependent variable are independent; that groups should be mutually exclusive; and that groups should have equal variance or homogeneity of variance ( Gray & Grove, 2021 ; Kim et al., 2022 ).

7.
The level of significance, or alpha, for this study was set at 0.05. The potential for a Type I error is 5 chances in 100 ( Grove & Gray, 2023 ).

8.
The null hypothesis is: The groups of traditional, second-degree, and out-of-sequence nursing students who received remediation had no difference in their ATI exam scores than those who did not receive remediation.

9.
According to Table 18.2 and the study narrative, F (7,250) = 9.04, p = 0.0000000006, was calculated for the ATI exam scores for the eight groups of nursing students. This F value is statistically significant because the p value is less than the alpha = 0.05 that was set for this study. The significant result means that there was a statistically significant difference among the eight groups of nursing students’ ATI exam scores. In addition, the F (7,250) = 9.04 is greater than the critical value of F = 2.046, which indicates statistical significance (see Table 18.2 ). Therefore the null hypothesis was rejected ( Grove & Gray, 2023 ).

10.
Yes, groups A and C were significantly different. Meehan and Barker (2021, p. 256) reported that the “mean score for those that received remediation was significantly different than those that did not in similar cohorts.” Group A (no remediation) and Group C (four semesters of remediation) were cohorts of traditional students who were reported to have significantly different ATI exam scores.

EXERCISE 18
Questions for additional study

Name: _____________________________________________________ Class: _______________________

Date: ___________________________________________________________________________________

Follow your instructor’s directions to submit your answers to the following questions for additional study. Your instructor may ask you to write your answers below and submit them as a hard copy for evaluation. Alternatively, your instructor may ask you to submit your answers online.

1.
Examine the traditional groups of nursing students in the Meehan and Barker (2021) study. Which group had the highest average score on the ATI’s Comprehensive Predictive Exam: A, B, or C? Provide a rationale for your answer.

2.
Which group had the highest average score for the ATI exam? Identify the mean for this group and discuss its meaning.

3.
Were the traditional out-of-sequence students in groups X and Z adequately represented in the Meehan and Barker (2021) study? Provide a rationale for your answer.

4.
ANOVA was conducted by Meehan and Barker (2021) to examine group differences in their study. Would t -tests have also been appropriate? Provide a rationale for your answer.

5.
In Table 18.2 , Meehan and Barker (2021) reported the df for the one-way ANOVA as 7 and 250. What types of df s are these and how were they calculated?

6.
What is the purpose for conducting post hoc analysis? What type of post hoc test was conducted in the Meehan and Barker (2021) study and was it appropriate? Provide a rationale for your answer.

7.
Were adequate results reported for the calculation of the Tukey HSD test? Provide a rationale for your answer.

8.
State the null hypothesis regarding the average scores for the second-degree students in groups D and F (see Table 18.1 ). Should the null hypothesis be accepted or rejected? Provide a rationale for your answer.

9.
Hypothetically, researchers reported the following results from the one-way ANOVA in their study: F (4,60) = 3.14. Is this result significant? Provide a rationale for your answer.

10.
Are the findings from the Meehan and Barker (2021) study

Understanding the Pearson chi-square EPUB version of this book
Susan K. Grove, PhD, RN, ANP-BC, GNP-BC; Daisha J. Cipher, PhD

Statistics for Nursing Research, EXERCISE 19, 226-234

Statistical technique in review
The Pearson chi-square (χ 2 ) is an inferential statistical test calculated to examine differences among groups with variables measured at the nominal level. There are different types of chi-square tests and the Pearson chi-square is commonly reported in nursing studies. The Pearson chi-square test compares the frequencies that are observed with the frequencies that were expected. The assumptions for the chi-square test are as follows ( Daniel, 2000 ):

1.
Only one datum entry is made for each participant in the sample. Therefore, if repeated measures from the same participant are being used for analysis, such as pretests and posttests, chi-square is not an appropriate test.

2.
The variables must be categorical (i.e., nominal), either inherently, or transformed to categorical from quantitative values.

3.
For each variable, the categories are mutually exclusive and exhaustive. No cells may have an expected frequency of zero. In the actual data, the observed cell frequency may be zero. However, the Pearson chi-square test is not sensitive to small sample sizes, and other tests, such as the Fisher exact test, are more appropriate when testing very small samples ( Daniel, 2000 ; Yates, 1934 ).

The chi-square values calculated are compared with the critical values in the chi-square table (see Appendix D , Critical Values of the χ 2 Distribution). If the result is greater than or equal to the value in the table, significant differences exist. If the values are statistically significant, the null hypothesis is rejected ( Gray & Grove, 2021 ). These results indicate that the differences are probably an actual reflection of reality and not caused by random sampling error or chance.

In addition to the chi-square value, researchers often report the degrees of freedom ( df ). This statistical concept is important for calculating and determining levels of significance. The standard formula for df is sample size ( N ) minus 1, or df = N − 1; however, this formula is adjusted based on the analysis technique performed ( Pett, 2016 ). The df formula for the chi-square test varies based on the number of categories examined in the analysis. The formula for df for the two-way chi-square test is df = ( R − 1) ( C − 1), where R is the number of rows and C is the number of columns in a chi-square table. For example, in a 2 × 2 chi-square table, df = (2 − 1) (2 − 1) = 1. Therefore the df is equal to 1. Table 19.1 displays a 2 × 2 chi-square contingency table based on the findings of a study by Conlon and colleagues (2021) . In Table 19.1 , the columns represent the two nominal binary categories of the novel coronavirus of 2019 (COVID-19) test results (positive/negative); and the two rows represent the two nominal binary categories of those with and without diabetes. The df = (2 − 1) (2 − 1) = (1) (1) = 1, and the study results were as follows: χ 2 (1, N = 27,201) = 170.72, p < 0.001. It is important to note that the df can also be reported without the sample size, as in χ 2 (1) = 170.72, p < 0.001. Among those with diabetes, rates of testing positive for COVID-19 were significantly higher. Alternatively, the rates of diabetes were significantly higher among those who tested positive for COVID-19 ( Conlon et al., 2021 ).

View full size
TABLE 19.1

CONTINGENCY TABLE BASED ON THE RESULTS OF CONLON ET AL. (2021) STUDY

COVID-19 Positive ( n = 1,218)	COVID-19 Negative ( n = 25,983)
Diabetes	262	2,556
No diabetes	956	23,427
If more than two groups are being examined, chi-square does not determine where the differences lie; it only determines that a statistically significant difference exists. A post hoc chi-square analysis will determine the location of the difference. The step-by-step process for calculating the Pearson chi-square test is presented in Exercise 37 .

Research article
Source
Conlon, A., Ashur, C., Washer, L., Eagle, K. A., & Bowman, M. A. H. (2021). Impact of the influenza vaccine on COVID-19 infection rates and severity. American Journal of Infection Control, 49 (6), 694–700. https://doi.org/10.1016/j.ajic.2021.02.012

Introduction
Conlon and colleagues (2021) conducted a retrospective cohort study to assess the role of the influenza vaccine on COVID-19 susceptibility and severity. The primary study outcome was the comparison of positive and negative COVID-19 testing in those who received the influenza vaccine versus those who did not. Other study variables included baseline patient characteristics and the presence of comorbidities. Over 4.5 million unique patient charts within the Michigan Medicine healthcare system were extracted, and of those, 27,201 patients received laboratory testing for COVID-19. The study alpha was set to 0.05. The footnote under Table 19.2 states, “ P values are shown from chi-square tests for categorial variables and Wilcoxon rank sum tests for continuous variables comparing probability of positive COVID-19 test.”

View full size
TABLE 19.2

PATIENT CHARACTERISTICS AND ASSOCIATIONS WITH COVID-19

From: Conlon, A., Ashur, C., Washer, L., Eagle, K. A., & Bowman, M. A. H. (2021). Impact of the influenza vaccine on COVID-19 infection rates and severity. American Journal of Infection Control , 49 (6), 694–700. https://doi.org/10.1016/j.ajic.2021.02.012

Variable *	COVID-19 Negative ( n = 25,983)	COVID-19 Positive ( n = 1218)	Entire cohort ( n = 27,201)	P value †
Influenza vaccine, n (%)	12,472 (48.0)	525 (43.1)	12,997 (47.8)	<.001
Women, n (%)	14,512 (55.9)	649 (53.3)	15,161 (55.7)	0.08
Age, mean ( SD )	47.07 (22.21)	50.69 (18.67)	47.23 (22.07)	<.001
Age, n (%)
<35	8143 (31.3%)	276 (22.7%)	8419 (31.0%)	<.001
35–49	4532 (17.4%)	276 (22.7%)	4808 (17.7%)	
50–64	6098 (23.5%)	349 (28.7%)	6447 (23.7%)	
≥65	6597 (25.4%)	308 (25.3%)	6905 (25.4%)	
Race, n (%)				
African American	2,972 (11.4)	432 (35.5)	3,404 (12.5)	<.001
Caucasian	20,386 (78.5)	617 (50.7)	21,003 (77.2)	
Other	1,841 (7.1)	113 (9.3)	1,954 (7.2)	
Ethnicity, n (%)
Hispanic or Latino	824 (3.2)	27 (2.2)	851 (3.1)	0.08
Non-Hispanic or Latino	23,951 (92.2)	1111 (91.2)	25,062 (92.1)	
Chronic pulmonary disease, n (%)	3806 (14.6)	241 (19.8)	4047 (14.9)	<.001
Congestive heart failure, n (%)	2032 (7.8)	125 (10.3)	2157 (7.9)	0.003
Diabetes, n (%)	2556 (9.8)	262 (21.5)	2818 (10.4)	<.001
Complicated diabetes, n (%)	749 (2.9)	103 (8.5)	852 (3.1)	<.001
Uncomplicated diabetes, n (%)	1807 (7.0)	159 (13.1)	1966 (7.2)	<.001
Hypertension, n (%)	5847 (22.5)	438 (36.0)	6285 (23.1)	<.001
Complicated hypertension, n (%)	1549 (6.0)	175 (14.4)	1724 (6.3)	<.001
Uncomplicated hypertension, n (%)	4298 (16.5)	263 (21.6)	4561 (16.8)	<.001
BMI, SD	28.23 (9.10)	32.42 (12.28)	28.39 (9.28)	<.001
BMI, n (%)
<18.5	1713 (6.6%)	17 (1.4%)	1730 (6.4%)	
18.5–24.9	4856 (18.7%)	117 (9.6%)	4973 (18.3%)	
25–29.9	5097 (19.6%)	219 (18.0%)	5316 (19.5%)	
30–39.9	5014 (19.3%)	264 (21.7%)	5278 (19.4%)	
>40	1424 (5.5%)	118 (9.7%)	1542 (5.7%)	
Elixhauser Score, SD	1.54 (2.34)	2.53 (3.19)	1.59 (2.39)	<.001
Smoking Status, n (%)
Current smoker	1678 (6.5%)	40 (3.3%)	1718 (6.3%)	0.002
Former smoker	3635 (14.0%)	175 (14.4%)	3810 (14.0%)	
Tobacco use	91 (0.4%)	2 (0.2%)	93 (0.3%)	
Never smoker	6836 (26.3%)	348 (28.6%)	7184 (26.4%)	
Relevant study results
The following excerpt summarizes the Pearson chi-square results that indicate the differences between those with positive and negative COVID-19 test results on baseline demographic and clinical variables. “Higher rates of comorbid conditions were seen in patients testing positive for COVID-19, including chronic pulmonary disease (19.8% vs 14.6%, P <.001), congestive heart failure (10.3% vs 7.8%, P =.003), any diabetes (21.5% vs 9.8%, P <.001), complicated diabetes (8.5% vs 2.9%, P <.001), uncomplicated diabetes (13.1% vs 7.0%, P <.001), any hypertension (36.0% vs 22.5%, P <.001), complicated hypertension (14.4% vs 6.0%, P <.001), and uncomplicated hypertension (21.6% vs 16.5%, P <.001). Additionally, older patients and African Americans were more likely to test positive versus negative for COVID-19 (50.7 years vs 47.1 years, P <.001 and 35.5% vs 11.4%, P <.001, respectively). A comparison of baseline characteristics stratified by COVID-19 status is seen in [ Table 19.2 ].

Patients receiving an influenza vaccine tended to have more comorbidities than those in the unvaccinated group, including higher rates of chronic pulmonary disease (16.4% vs 13.4%, P <.001), congestive heart failure (9.2% vs 6.7%, P <.001), diabetes (11.1% vs 9.7%, P =.001), and hypertension (23.9% vs 22.3%, P =.01). Patients receiving an influenza vaccine also tended to be older (48.4 years vs 46.1 years, P <.001), female (61.0% vs 50.9%, P <.001), and Caucasian (80.1% vs 74.6%, P <.001)” (Conlon et al., 2021, p. 696).

It should be noted that this article represents each p value with an uppercase P because the American Journal of Infection Control displays p as uppercase. Most journals of nursing research require formatting in accordance with the American Psychological Association ( APA, 2020 ), which requires p to be lowercase.

Study questions

1.
What is the sample size for the Conlon et al. (2021) study? How many study participants (percentage) tested positive for COVID-19 and how many tested negative? Was this sample size adequate for the study?

2.
State the null hypothesis with regard to influenza vaccine (received/not received) by COVID-19 test result (positive/negative) in the Conlon et al. (2021) study.

3.
What is the p value for influenza vaccine? Was the null hypothesis accepted or rejected? Provide rationales for your answers.

4.
Does a statistically significant chi-square result provide evidence of causation between the variables? Provide a rationale for your answer.

5.
What is the p value for congestive heart failure? Is the p value statistically significant? Provide a ration-ale for your answer.

6.
Is there a statistically significant difference with regard to percentage of women by COVID-19 test result (positive/negative)? Document your answer.

7.
What is the df for smoking status? Calculate the df for the Pearson chi-square test comparing COVID-19 test result (positive/negative) by smoking status (current/former/tobacco use/never).

8.
State the null hypothesis regarding the variable smoking status by COVID-19 test result (positive/negative).

9.
Should the null hypothesis for smoking status (developed in Question 8) be accepted or rejected? Provide a rationale for your answer.

10.
Would a Pearson chi-square test be appropriate for the comparison of Elixhauser Scores by COVID-19 test result (positive/negative)? Why or why not?

Answers to study questions

1.
The sample size is n = 27,201 with n = 25,983 (95.52%) persons who tested negative for COVID-19 and n = 1,218 (4.48%) persons who tested positive for COVID-19 as indicated in Table 19.2 . This sample size is extremely large, and the majority of the statistical results were significant, indicating adequate statistical power (see Exercise 25 ).

2.
The null hypothesis is: There is no difference between persons who tested negative and positive for COVID-19 on whether they received the influenza vaccine.

3.
The p < 0.001 for influenza vaccine. Because p is less than the study alpha of 0.05, this result is significant. The specific chi-square values are not listed in Table 19.2 , which is a typical method of reporting a set of multiple chi-square tests. The null hypothesis is rejected when study results are statistically significant ( Gray & Grove, 2021 ; Pett, 2016 ). It should be noted that p values never equal zero, but they may be extremely small. Per APA format, very small p values are reported as “< 0.001.”

4.
No, a statistically significant chi-square value does not provide evidence of causation. A statistically significant chi-square value indicates that a significant difference between groups exists, but does not provide a causal link ( Grove & Gray, 2023 ; Shadish et al., 2002 ).

5.
The p = 0.003 for congestive heart failure. Because p is less than the study alpha of 0.05, this result is significant.

6.
No, there was not a statistically significant difference with regard to percentage of women by COVID-19 test result (positive/negative). Of those who tested negative for COVID-19, 55.9% were women. Of those who tested positive for COVID-19, 53.3% were women. The chi-square test was not significant because p = 0.08, which exceeds the study alpha of 0.05, indicating a nonsignificant result.

7.
The df formula is df = ( R − 1) ( C − 1). There are four R rows for smoking status: current, former, tobacco use, and never. There are two C columns, negative and positive COVID-19 test. Therefore df = (4 − 1) (2 − 1) = (3)(1) = 3.

8.
The null hypothesis: There is no difference between persons who tested negative versus those who tested positive for COVID-19 on their category of smoking status.

9.
The null hypothesis should be rejected. The p = 0.002 for smoking status and is therefore less than the study alpha of 0.05. The null hypothesis is rejected when study results are statistically significant ( Gray & Grove, 2021 ; Pett, 2016 ).

10.
No, a Pearson chi-square test is not appropriate for the comparison of Elixhauser Scores by COVID-19 test result. One of the assumptions of the Pearson chi-square test is that the data are of a nominal level of measurement. The Elixhauser Score is an ordinal variable, with higher values indicative of more medical comorbidities, and lower values indicative of fewer medical comorbidities ( Elixhauser, et al., 1998 ). According to the footnote under Table 19.2 , the Wilcoxon rank-sum test (otherwise known as the Mann-Whitney U test; see Exercises 21 and 34 ) was computed to compare Elixhauser Scores by COVID-19 test result.

EXERCISE 19
Questions for additional study

Name: _____________________________________________________ Class: _______________________

Date: ___________________________________________________________________________________

Follow your instructor’s directions to submit your answers to the following questions for additional study. Your instructor may ask you to write your answers below and submit them as a hard copy for evaluation. Alternatively, your instructor may ask you to submit your answers online.

1.
According to Table 19.2 of the Conlon et al. (2021) study, name the two variables that were not statistically significant. Document your answer.

2.
What level of measurement is appropriate for calculating the chi-square statistic? Give two examples from Table 19.2 of demographic variables measured at the level appropriate for chi-square.

3.
State the null hypothesis regarding the variable of uncomplicated hypertension by COVID-19 test result (positive/negative).

4.
Should the null hypothesis for uncomplicated hypertension (developed in Question 3) be accepted or rejected? Provide a rationale for your answer.

5.
List the percentages of persons with uncomplicated hypertension in the two COVID-19 test groups. Show the calculations for how these percentages were derived using the values listed in Table 19.2 .

6.
What is the df for race? Calculate the df for the Pearson chi-square test comparing COVID-19 test result (positive/negative) by race (African American/Caucasian/other).

7.
Is there a statistically significant difference with regard to presence of chronic pulmonary disease by COVID-19 test result (positive/negative)? Document your answer.

8.
List the percentages of persons with chronic pulmonary disease in the two COVID-19 test groups. Show the calculations for how these percentages were derived using the values listed in Table 19.2 .

9.
Compare and contrast the two different statistical analyses for the variable of age presented in Table 19.2 .

10.
A statistically significant difference is present between persons who tested negative versus positive for COVID-19 on their category of smoking status, p = 0.002. Does this result provide the location of the difference? Provide a rationale for your answer.

Understanding spearman rank-order correlation coefficient EPUB version of this book
Susan K. Grove, PhD, RN, ANP-BC, GNP-BC; Daisha J. Cipher, PhD

Statistics for Nursing Research, EXERCISE 20, 235-245

Statistical technique in review
The Spearman rank-order correlation coefficient , or Spearman rho (also written as ρ ), is a nonparametric test conducted to identify relationships or associations between two variables. The Spearman analysis technique is an adaptation of the Pearson product-moment correlation (see Exercises 13 and 29 ) and is calculated when the assumptions of the Pearson correlation analysis cannot be met. Thus the Spearman rho is computed on data that are ordinal level of measurement or variables measured at the interval or ratio levels with values that are skewed or not normally distributed ( Pett, 2016 ; Terrell, 2021 ).

Each participant included in the analysis must have a score (or value) on each of two variables x and y . The values for both variables must be ranked to conduct this analysis. The values on each variable are ranked separately ( Pett, 2016 ; Daniel, 2000 ). Calculation of Spearman rho is based on difference scores between a participant’s ranking on the first (variable x ) and second (variable y ) sets of values. The formula for difference scores is D = x − y . Because results with negative values cancel out positive values, results are squared for use in the analysis. The formula for calculation of Spearman rho is:

ρ
=
1
−
6
∑
D
2
N
3
−
N
where:

ρ = Rho , the statistic for the Spearman correlation coefficient

D = Difference between the rankings of a participant’s score or value on both variables x and y

N = Number of paired ranked scores ( Daniel, 2000 ).

The Spearman rank-order correlation coefficient values range from −1 to + 1, where a positive value indicates a positive association, and a negative value indicates a negative or inverse association. Numbers closest to + 1 or −1 indicate the strongest associations. In comparison to the Pearson correlation coefficient ( r ), the Spearman rho has a statistical power of 91%, which means the Spearman rho has a 9% smaller probability of detecting an association if one exists. If the study sample size is greater than 50 participants, the power of the Spearman rho is approximately equal to the Pearson r in detecting a relationship in a study. The strength of rho values are as follows, in absolute value: <0.30 are weak relationships, 0.30 to 0.50 are moderate relationships, and >0.50 are strong relationships. A Spearman rho of 0 indicates no relationship between the two variables; the closer the rho value is to 0, the weaker the relationship ( Pett, 2016 ; Terrell, 2021 ). The significance of rho can be determined in one of two ways: (1) by comparing the calculated value with the critical value in a Spearman rho table, or (2) by using statistical software to compute the Spearman rho , along with exact p values.

The Spearman rho is calculated using the following hypothetical example: six students’ intramuscular (IM) injection techniques were ranked by two instructors from a high score of 1 to a low score of 6. The data or rankings for this example are ordinal and presented in Table 20.1 . The purpose of this example is to examine the relationship between the two instructors’ rankings of the six students’ IM injection techniques. The null hypothesis is: There is no association between rankings of students’ IM injection technique by instructors A and B.

View full size
TABLE 20.1

ASSOCIATION BETWEEN TWO INSTRUCTORS’ RANKINGS of STUDENTS’ INTRAMUSCULAR INJECTION TECHNIQUES

Student	Instructor A Ranking	Instructor B Ranking	D	D 2
Amy	1	1	0	0
Jeff	3	2	1	1
John	5	4	1	1
Julie	2	3	−1	1
Mary	4	5	−1	1
Susie	6	6	0	0
Sum				4
Calculations:

ρ
=
1
−
6
∑
D
2
N
3
−
N
ρ
=
1
−
6
(
4
)
216
−
6
=
1
−
24
210
=
1
−
0.114
=
0.886
In this example, a strong positive correlation or association ( ρ = 0.886) was found between the two instructors’ ranking of students on IM injection techniques. This value for rho , when compared with the critical value in a Spearman correlation coefficient table ( Plichta & Kelvin, 2013 ) of 0.829 for n = 6 for a two-tailed test, is statistically significant because it is equal to the critical value. Because the rho value is statistically significant, the null hypothesis is rejected. The Spearman rho is usually calculated with a larger sample and using a statistical computer package, such as SPSS ( IBM Corporation, 2022 ), that determines the rho value and its significance ( Pett, 2016 ). Usually, a Spearman rho is calculated with data that are not rankings, and therefore the statistical software internally converts the raw data to ranks and applies the Spearman rho formula. Spearman rho values may be notated in journal articles as “ rho ,” “ r s ,” or “ ρ .”

Research article
Source
Urban, R. W., Smith, J., Wilson, S., & Cipher, D. J. (2021) . Relationships among stress, resilience, and incivility in undergraduate nursing students and faculty during the COVID-19 pandemic: Policy implications for nurse leaders. Journal of Professional Nursing, 37 (6), 1063–1070. https://doi.org/10.1016/j.profnurs.2021.08.011

Introduction
Urban and colleagues (2021) conducted a descriptive correlational study to compare associations among and differences between perceptions of incivility frequency, self-reported stress, and resilience levels in undergraduate nursing students and faculty during the COVID-19 pandemic.

An online survey was used to collect data from 710 undergraduate nursing students and faculty. The researchers measured stress and resilience using the Perceived Stress Scale-10 ( PSS-10 ) and the Resilience Scale-14 ( RS-14 ), respectively. Ratings of low-level and high-level incivility were collected with the Incivility in Nursing Education-Revised ( INE-R ). Higher values on each of these scales represent higher levels of the concept being measured. Examples of low-level incivility include expressions of boredom, apathy, or disinterest in the classroom. Examples of high-level incivility include using profanity, making rude remarks, or sending inappropriate emails and texts.

“Students were significantly more stressed and less resilient than faculty. Faculty reported significantly greater low- and high-level student and low-level faculty incivility behaviors than students. Understanding student and faculty perceptions of uncivil behavior frequency occurring at the intersection of high stress and moderate resilience levels is key to the creation of targeted interventions and policy development” ( Urban et al., 2021 , p. 1063).

Relevant study results
The statistical analyses in this study included descriptive statistics and the inferential statistics of Spearman correlation, chi-square (also written as χ 2 ) (see Exercise 19 ), and multiple linear regression (see Exercises 15 and 31 ). The level of significance, or α, was set to 0.05. “Spearman correlation coefficients were computed to assess the relationships reported by nursing faculty among the study variables (stress, resilience, and the frequency of low/high incivility behaviors in nursing students and faculty). There was a weak negative correlation between stress and resilience in faculty that approached significance ( rho = 0.293, p =.08). A weak positive correlation was found between faculty stress and increased frequency of reporting high-level faculty incivility that approached significance ( rho = 0.285, p =.08). Significant positive correlations existed for faculty between reporting higher frequency scores on low student incivility and reporting frequency scores for higher student incivility ( rho = 0.876, p <.001) and lower faculty incivility ( rho = 0.552, p <.001) but not high faculty incivility frequency scores ( rho = 0.331, p <.058). Similarly, there was a significant positive correlation among nursing faculty reporting higher frequency scores on the low and high student incivility subscales ( rho = 0.538, p <.006) and on the high faculty incivility subscales ( rho = 0.388, p <.037).” ( Urban et al., 2021 , p. 1067; see Table 20.2 ).

View full size
TABLE 20.2

RELATIONSHIPS AMONG UNDERGRADUATE NURSING STUDENT AND FACULTY SURVEY TOTAL SCORES

PSS–10	RS–14	SLLIB	SHLIB	FLLIB	FHLIB
Perceived Stress Scale (PSS–10)	Student	–	–0.567 **	0.269 **	0.119 **	0.291 **	0.219 **
Faculty	–	–0.293	0.242	0.161	0.254	0.285
Resilience Scale (RS-14)	Student		–	–0.312 **	– 0.163 **	– 0.271 **	–0.202 **
Faculty		–	– 0.059	– 0.071	– 0.129	– 0.058
INE-R Student Low-Level Incivility Behaviors (SLLIB) Subscale	Student			–	0.740 **	0.710 **	0.592 **
Faculty			–	0.876 **	0.552 **	0.331
INE-R Student High-Level Incivility Behaviors (SHLIB) Subscale	Student				–	0.611 **	0.616 **
Faculty				–	0.538 **	0.388 *
INE-R Faculty Low-Level Incivility Behaviors (FLLIB) Subscale	Student					–	0.836 **
Faculty					–	0.747 **
INE-R Faculty High-Level Incivility Behaviors (FHLIB) Subscale	Student						–
Note: Pooled r s values are reported from the imputed datasets.

Study questions

1.
Among the student respondents, what was the Spearman correlation between perceived stress ( PSS-10 ) and resilience ( RS-14 )?

2.
Describe the strength and direction of the correlation between student-perceived stress (PSS-10) and resilience ( RS-14) . Is this correlation statistically significant? Provide a rationale for your answer.

3.
What was the largest Spearman correlation value in Table 20.2 ? Provide an interpretation of the value.

4.
What correlation is reported in Table 20.2 as Spearman ρ = 0.219, p < 0.01?

5.
Describe the strength and direction of the correlation between resilience ( RS-14 ) and ratings of student low-level incivility ( SLLIB ) among the student respondents .

6.
Is there a stronger correlation between resilience ( RS-14 ) and ratings of student low-level incivility ( SLLIB ) among the student respondents, or among the faculty respondents? Provide a rationale for your answer.

7.
Describe the strength and direction of the association between perceived stress ( PSS-10 ) and student high-level incivility ( SHLIB ) among the faculty respondents. Is this correlation statistically significant? Provide a rationale for your answer.

8.
Examine the correlations between perceived stress ( PSS-10 ) and student high-level incivility ( SHLIB ) for students versus faculty. Explain why the correlation for the student respondents was significant and the correlation for the faculty respondents was not significant.

9.
How many correlations presented in Table 20.2 are statistically significant at p < 0.01? Provide a rationale for your answer.

10.
Spearman rank-order correlation coefficients were computed to examine the associations in this study. Was this analysis appropriate? Provide a rationale for your answer. What is the preferred parametric analysis for identifying relationships between variables (review Exercise 13 )?

Answers to study questions

1.
The Spearman correlation between perceived stress ( PSS-10 ) and resilience ( RS-14 ) among the student respondents was ρ = −0.567.

2.
The rho of −0.567** was a statistically significant inverse correlation, indicating that higher levels of stress were associated with lower levels of resilience among the student respondents. This correlation is statistically significant at p < 0.01, as indicated by the ** in the footnote of Table 20.2 . Like most nurse researchers, Urban and colleagues (2021) set their level of significance or alpha at 0.05. Because p < 0.01 is smaller than alpha, the relationship is statistically significant ( Pett, 2016 ). Note that the negative sign in ρ = −0.567 indicates the direction of the association, not the strength of the association ( Gray & Grove, 2021 ; Pett, 2016 ).

3.
The largest Spearman rho value in Table 20.2 is 0.876**, representing the correlation between faculty ratings of low student incivility ( SLLIB ) and faculty ratings of high student incivility ( SHLIB ). There was a strong positive association between ratings of low-level and high-level student incivility among the faculty respondents. Higher ratings of low-level incivility behaviors were associated with higher ratings of high-level incivility behaviors. Similarly, lower ratings of low-level behaviors were associated with lower ratings of high-level behaviors. This relationship was statistically significant at p = 0.01 as indicated by the ** displayed in the footnote to this table.

4.
The correlation described in Table 20.2 with ρ = 0.219, p < 0.01 is the weak, positive association between perceived stress ( PSS-10 ) and ratings of faculty high-level incivility behaviors ( FHLIB ) among the student respondents. Higher levels of perceived stress were associated with higher ratings of faculty high-level incivility, and vice versa (i.e., lower levels of perceived stress were associated with lower ratings of faculty high-level incivility).

5.
There is a negative, moderate correlation between resilience ( RS-14 ) and ratings of student low-level incivility ( SLLIB ) among the student respondents: ρ = −0.312 ( p < 0.01). Among the student respondents, higher levels of resilience were associated with lower ratings of student low-level incivility, and vice versa (i.e., lower levels of resilience were associated with higher ratings of student low-level incivility).

6.
The stronger correlation is between resilience ( RS-14 ) and ratings of student low-level incivility ( SLLIB ) among the student respondents is ρ = −0.312 ( p < 0.01), which is a moderate, negative, significant association. The association between resilience ( RS-14 ) and ratings of student low-level incivility ( SLLIB ) among the faculty respondents is ρ = −0.059, which is a weak, negative nonsignificant association that is close to 0.0. The closer the rho value is to + 1 or −1, the stronger the correlation between variables. Note that the negative sign in ρ = −0.312 indicates the direction of the association and not the strength of the association ( Gray & Grove, 2021 ; Pett, 2016 ).

7.
The correlation between perceived stress ( PSS-10 ) and student high-level incivility ( SHLIB ) for the faculty respondents was not significant, with ρ = 0.161. This correlation was not statistically significant at p < 0.05 or p < 0.01 because there are no asterisks by the rho value.

8.
The correlation between perceived stress ( PSS-10 ) and student high-level incivility ( SHLIB ) for the student respondents was significant with ρ = 0.119, p < 0.01, whereas the correlation between perceived stress ( PSS-10 ) and student high-level incivility ( SHLIB ) for the faculty respondents was not significant with ρ = 0.161. The student sample size was 675, while the faculty sample size was 35. Therefore a weak Spearman rho was statistically significant with a large N of students, but not a small N of faculty. As demonstrated in Exercise 25 , the power of any inferential statistic is substantially affected by sample size. The greater the sample size, the higher the power of the statistic ( Aberson, 2019 ; Cohen, 1988 ).

9.
A total of 19 correlations identified in Table 20.2 are statistically significant at p < 0.01, as indicated by the ** beside the rho value and described in the footnote of Table 20.2 .

10.
The researchers did not explicitly state the reason(s) why Spearman rank-order correlation coefficients were computed to examine associations in this study. It is assumed that the Spearman correlations were the appropriate choice because: (1) some of the study data were considered at the ordinal level of measurement by the researchers; and/or (2) the study data were found to be nonnormally distributed and therefore inappropriate for parametric analyses. Pearson product-moment correlation is the parametric and the preferred analysis technique to identify associations between two variables when the assumptions for this test are met, which includes the study variables being measured at the interval or ratio level (see Exercise 13 ). The Pearson r is preferred because it is more powerful in identifying significant relationships than the Spearman rho ( Gray & Grove, 2021 ; Pett, 2016 ).

EXERCISE 20
Questions for additional study

Name: _____________________________________________________ Class: _______________________

Date: ___________________________________________________________________________________

Follow your instructor’s directions to submit your answers to the following questions for additional study. Your instructor may ask you to write your answers below and submit them as a hard copy for evaluation. Alternatively, your instructor may ask you to submit your answers online.

1.
How many correlations presented in Table 20.2 are statistically significant at p < 0.05? Provide a rationale for your answer.

2.
What two variables from Table 20.2 have the strongest negative (i.e., inverse) correlation? Provide a rationale for your answer.

3.
Provide an interpretation of the correlation value listed in Question 2.

4.
What two variables from Table 20.2 have the weakest positive correlation?

5.
What do the results in Question 4 mean? Provide an interpretation of the correlation value.

6.
Is the correlation between resilience ( RS-14 ) and ratings of faculty high-level incivility ( FHLIB ) among the student respondents significant? Provide a rationale for your answer.

7.
Is there a stronger correlation between resilience ( RS-14 ) and ratings of faculty high-level incivility ( FHLIB ) among the student respondents, or among the faculty respondents? Provide a rationale for your answer.

8.
Describe the correlation between resilience ( RS-14 ) and ratings of student low-level incivility ( SLLIB ) among the faculty respondents. What is the strength of the correlation, is it positive or negative, and is it statistically significant?

9.
Using the data in Table 20.1 , calculate the Spearman rho value on the provided data, with one change: Delete Susie’s values, leaving an n of 5 rows. Show your calculations.

10.
Compare the Spearman rho value from Question 9 with the rho value from the original data (ρ = 0.886). Did the value change, and why or why not? What does this mean in terUnderstanding spearman rank-order correlation coefficient EPUB version of this book
Susan K. Grove, PhD, RN, ANP-BC, GNP-BC; Daisha J. Cipher, PhD

Statistics for Nursing Research, EXERCISE 20, 235-245

Statistical technique in review
The Spearman rank-order correlation coefficient , or Spearman rho (also written as ρ ), is a nonparametric test conducted to identify relationships or associations between two variables. The Spearman analysis technique is an adaptation of the Pearson product-moment correlation (see Exercises 13 and 29 ) and is calculated when the assumptions of the Pearson correlation analysis cannot be met. Thus the Spearman rho is computed on data that are ordinal level of measurement or variables measured at the interval or ratio levels with values that are skewed or not normally distributed ( Pett, 2016 ; Terrell, 2021 ).

Each participant included in the analysis must have a score (or value) on each of two variables x and y . The values for both variables must be ranked to conduct this analysis. The values on each variable are ranked separately ( Pett, 2016 ; Daniel, 2000 ). Calculation of Spearman rho is based on difference scores between a participant’s ranking on the first (variable x ) and second (variable y ) sets of values. The formula for difference scores is D = x − y . Because results with negative values cancel out positive values, results are squared for use in the analysis. The formula for calculation of Spearman rho is:

ρ
=
1
−
6
∑
D
2
N
3
−
N
where:

ρ = Rho , the statistic for the Spearman correlation coefficient

D = Difference between the rankings of a participant’s score or value on both variables x and y

N = Number of paired ranked scores ( Daniel, 2000 ).

The Spearman rank-order correlation coefficient values range from −1 to + 1, where a positive value indicates a positive association, and a negative value indicates a negative or inverse association. Numbers closest to + 1 or −1 indicate the strongest associations. In comparison to the Pearson correlation coefficient ( r ), the Spearman rho has a statistical power of 91%, which means the Spearman rho has a 9% smaller probability of detecting an association if one exists. If the study sample size is greater than 50 participants, the power of the Spearman rho is approximately equal to the Pearson r in detecting a relationship in a study. The strength of rho values are as follows, in absolute value: <0.30 are weak relationships, 0.30 to 0.50 are moderate relationships, and >0.50 are strong relationships. A Spearman rho of 0 indicates no relationship between the two variables; the closer the rho value is to 0, the weaker the relationship ( Pett, 2016 ; Terrell, 2021 ). The significance of rho can be determined in one of two ways: (1) by comparing the calculated value with the critical value in a Spearman rho table, or (2) by using statistical software to compute the Spearman rho , along with exact p values.

The Spearman rho is calculated using the following hypothetical example: six students’ intramuscular (IM) injection techniques were ranked by two instructors from a high score of 1 to a low score of 6. The data or rankings for this example are ordinal and presented in Table 20.1 . The purpose of this example is to examine the relationship between the two instructors’ rankings of the six students’ IM injection techniques. The null hypothesis is: There is no association between rankings of students’ IM injection technique by instructors A and B.

View full size
TABLE 20.1

ASSOCIATION BETWEEN TWO INSTRUCTORS’ RANKINGS of STUDENTS’ INTRAMUSCULAR INJECTION TECHNIQUES

Student	Instructor A Ranking	Instructor B Ranking	D	D 2
Amy	1	1	0	0
Jeff	3	2	1	1
John	5	4	1	1
Julie	2	3	−1	1
Mary	4	5	−1	1
Susie	6	6	0	0
Sum				4
Calculations:

ρ
=
1
−
6
∑
D
2
N
3
−
N
ρ
=
1
−
6
(
4
)
216
−
6
=
1
−
24
210
=
1
−
0.114
=
0.886
In this example, a strong positive correlation or association ( ρ = 0.886) was found between the two instructors’ ranking of students on IM injection techniques. This value for rho , when compared with the critical value in a Spearman correlation coefficient table ( Plichta & Kelvin, 2013 ) of 0.829 for n = 6 for a two-tailed test, is statistically significant because it is equal to the critical value. Because the rho value is statistically significant, the null hypothesis is rejected. The Spearman rho is usually calculated with a larger sample and using a statistical computer package, such as SPSS ( IBM Corporation, 2022 ), that determines the rho value and its significance ( Pett, 2016 ). Usually, a Spearman rho is calculated with data that are not rankings, and therefore the statistical software internally converts the raw data to ranks and applies the Spearman rho formula. Spearman rho values may be notated in journal articles as “ rho ,” “ r s ,” or “ ρ .”

Research article
Source
Urban, R. W., Smith, J., Wilson, S., & Cipher, D. J. (2021) . Relationships among stress, resilience, and incivility in undergraduate nursing students and faculty during the COVID-19 pandemic: Policy implications for nurse leaders. Journal of Professional Nursing, 37 (6), 1063–1070. https://doi.org/10.1016/j.profnurs.2021.08.011

Introduction
Urban and colleagues (2021) conducted a descriptive correlational study to compare associations among and differences between perceptions of incivility frequency, self-reported stress, and resilience levels in undergraduate nursing students and faculty during the COVID-19 pandemic.

An online survey was used to collect data from 710 undergraduate nursing students and faculty. The researchers measured stress and resilience using the Perceived Stress Scale-10 ( PSS-10 ) and the Resilience Scale-14 ( RS-14 ), respectively. Ratings of low-level and high-level incivility were collected with the Incivility in Nursing Education-Revised ( INE-R ). Higher values on each of these scales represent higher levels of the concept being measured. Examples of low-level incivility include expressions of boredom, apathy, or disinterest in the classroom. Examples of high-level incivility include using profanity, making rude remarks, or sending inappropriate emails and texts.

“Students were significantly more stressed and less resilient than faculty. Faculty reported significantly greater low- and high-level student and low-level faculty incivility behaviors than students. Understanding student and faculty perceptions of uncivil behavior frequency occurring at the intersection of high stress and moderate resilience levels is key to the creation of targeted interventions and policy development” ( Urban et al., 2021 , p. 1063).

Relevant study results
The statistical analyses in this study included descriptive statistics and the inferential statistics of Spearman correlation, chi-square (also written as χ 2 ) (see Exercise 19 ), and multiple linear regression (see Exercises 15 and 31 ). The level of significance, or α, was set to 0.05. “Spearman correlation coefficients were computed to assess the relationships reported by nursing faculty among the study variables (stress, resilience, and the frequency of low/high incivility behaviors in nursing students and faculty). There was a weak negative correlation between stress and resilience in faculty that approached significance ( rho = 0.293, p =.08). A weak positive correlation was found between faculty stress and increased frequency of reporting high-level faculty incivility that approached significance ( rho = 0.285, p =.08). Significant positive correlations existed for faculty between reporting higher frequency scores on low student incivility and reporting frequency scores for higher student incivility ( rho = 0.876, p <.001) and lower faculty incivility ( rho = 0.552, p <.001) but not high faculty incivility frequency scores ( rho = 0.331, p <.058). Similarly, there was a significant positive correlation among nursing faculty reporting higher frequency scores on the low and high student incivility subscales ( rho = 0.538, p <.006) and on the high faculty incivility subscales ( rho = 0.388, p <.037).” ( Urban et al., 2021 , p. 1067; see Table 20.2 ).

View full size
TABLE 20.2

RELATIONSHIPS AMONG UNDERGRADUATE NURSING STUDENT AND FACULTY SURVEY TOTAL SCORES

PSS–10	RS–14	SLLIB	SHLIB	FLLIB	FHLIB
Perceived Stress Scale (PSS–10)	Student	–	–0.567 **	0.269 **	0.119 **	0.291 **	0.219 **
Faculty	–	–0.293	0.242	0.161	0.254	0.285
Resilience Scale (RS-14)	Student		–	–0.312 **	– 0.163 **	– 0.271 **	–0.202 **
Faculty		–	– 0.059	– 0.071	– 0.129	– 0.058
INE-R Student Low-Level Incivility Behaviors (SLLIB) Subscale	Student			–	0.740 **	0.710 **	0.592 **
Faculty			–	0.876 **	0.552 **	0.331
INE-R Student High-Level Incivility Behaviors (SHLIB) Subscale	Student				–	0.611 **	0.616 **
Faculty				–	0.538 **	0.388 *
INE-R Faculty Low-Level Incivility Behaviors (FLLIB) Subscale	Student					–	0.836 **
Faculty					–	0.747 **
INE-R Faculty High-Level Incivility Behaviors (FHLIB) Subscale	Student						–
Note: Pooled r s values are reported from the imputed datasets.

Study questions

1.
Among the student respondents, what was the Spearman correlation between perceived stress ( PSS-10 ) and resilience ( RS-14 )?

2.
Describe the strength and direction of the correlation between student-perceived stress (PSS-10) and resilience ( RS-14) . Is this correlation statistically significant? Provide a rationale for your answer.

3.
What was the largest Spearman correlation value in Table 20.2 ? Provide an interpretation of the value.

4.
What correlation is reported in Table 20.2 as Spearman ρ = 0.219, p < 0.01?

5.
Describe the strength and direction of the correlation between resilience ( RS-14 ) and ratings of student low-level incivility ( SLLIB ) among the student respondents .

6.
Is there a stronger correlation between resilience ( RS-14 ) and ratings of student low-level incivility ( SLLIB ) among the student respondents, or among the faculty respondents? Provide a rationale for your answer.

7.
Describe the strength and direction of the association between perceived stress ( PSS-10 ) and student high-level incivility ( SHLIB ) among the faculty respondents. Is this correlation statistically significant? Provide a rationale for your answer.

8.
Examine the correlations between perceived stress ( PSS-10 ) and student high-level incivility ( SHLIB ) for students versus faculty. Explain why the correlation for the stUnderstanding Mann-Whitney U test EPUB version of this book
Susan K. Grove, PhD, RN, ANP-BC, GNP-BC; Daisha J. Cipher, PhD

Statistics for Nursing Research, EXERCISE 21, 246-254

Statistical technique in review
The Mann-Whitney U test is a nonparametric statistical technique conducted to detect differences between two independent samples. This statistical technique is the most powerful of the nonparametric tests, with 95% of the power of the t -test. The Mann-Whitney U test is often computed when the assumptions for the independent samples t -test cannot be satisfied, such as a dependent variable that is ordinal-level or interval/ratio whereby the distribution of values is nonnormal ( Kim et al, 2022 ; Knapp, 2017 ; Terrell, 2021 ). Exercise 12 provides an algorithm that will assist you in determining whether the Mann-Whitney U test is an appropriate statistical technique. It should be noted that the Mann-Whitney U test is also known as the Wilcoxon rank-sum test; however, this test is most commonly referred to as the Mann-Whitney U test in nursing journals. The Mann-Whitney U test/Wilcoxon rank-sum test should not be confused with the Wilcoxon signed-rank test , which is a test for paired samples and is covered in Exercise 22 .

The Mann-Whitney U test checks this null hypothesis: There is no difference between two independent samples on a selected variable. For example: There is no difference between the education intervention group and control group regarding their self-care activities following surgery. In this example, self-care activities data need to be measured at least at the ordinal level. When reporting the Mann-Whitney U test results, researchers should identify the sample size for each of the independent groups and the medians for the groups so readers will know how the sample statistics differ. For example, the education intervention group included 11 postsurgical patients (median = 16.55) and the control group included 9 postsurgical patients (median = 8.75). The medians are reported for the groups instead of means because medians are not influenced by extremely small or large values ( Kim et al., 2022 ; Plichta & Kelvin, 2013 ).

To calculate the value of U , the data of both samples are combined, and each data value is assigned a rank. The lowest value is ranked 1, the next value is ranked 2, and so forth until all values are ranked, regardless from which sample the score was obtained. The idea is that if two distributions came from the same population, the average of the ranks of values would be equal as well.

Exercise 34 provides detailed examples that include hand calculations and SPSS computations of the Mann-Whitney U test. When calculating the Mann-Whitney U test by hand, one must compute two U values, and choose the smallest of the two U values when determining significance of the result ( Daniel, 2000 ). Therefore, when reporting the Mann-Whitney U test results, researchers should identify the sample size of each of the independent groups, the value of the z statistic (converted from the smallest U value) and its associated p value, and the medians for the two groups ( Terrell, 2021 ). The z statistic for the Mann-Whitney U test represents the extent to which the two groups differ on the dependent variable. The higher the z statistic, the more likely the groups significantly differ on the values of the dependent variable ( Gray & Grove, 2021 ).

Research article
Source
Deng, Y., Lin, Y., Yang, L., Liang, Q., Fu, B., Li, H., Zhang, H., & Liu, Y. (2021) . A comparison of maternal fear of childbirth, labor pain intensity and intrapartum analgesic consumption between primiparas and multiparas: A cross-sectional study. International Journal of Nursing Science, 8 (4), 380–387. https://doi.org/10.1016/j.ijnss.2021.09.003

Introduction
Deng and colleagues (2021) conducted a cross-sectional study to describe and compare fear of childbirth, in-labor pain intensity, and pain relief between women who were primiparas (e.g., individuals who had given birth for the first time) and multiparas (i.e., individuals who had given birth more than once). Table 21.1 displays the pain relief variables for the two groups of women, with descriptive statistics and the results of the Mann-Whitney U tests.

View full size
TABLE 21.1

COMPARISON OF THE AMOUNT OF PAIN RELIEF BETWEEN PRIMIPARAS AND MULTIPARAS

From: Deng, Y., Lin, Y., Yang, L., Liang, Q., Fu, B., Li, H., Zhang, H., & Liu, Y. (2021). A comparison of maternal fear of childbirth, labor pain intensity and intrapartum analgesic consumption between primiparas and multiparas: A cross-sectional study . International Journal of Nursing Science, 8 (4), 380–387. https://doi.org/10.1016/j.ijnss.2021.09.003

Variables	Primiparas ( n = 82)	Multiparas ( n = 99)	z/ χ ²	P
Duration of labor analgesia (h)	8.00 (4.50, 10.77)	3.25 (1.93, 6.23)	6.32 a	<0.001
Patients requiring manual bolus, yes	75 (91.5)	94 (94.9)	0.88 b	0.348
Total PCEA manual boluses	12.48 (6.54, 17.42)	8.20 (3.63, 13.88)	2.80 a	0.005
PCEA successful manual boluses per hour	1.77 (0.90, 2.47)	2.68 (1.65, 3.85)	4.52 a	<0.001
Hourly analgesic consumption (mL/h)	17.24 (11.52, 21.36)	23.00 (16.00, 28.25)	4.63 a	<0.001
Average analgesic consumption (mL/h·kg)	0.26 (0.19, 0.35)	0.35 (0.24, 0.45)	3.92 a	<0.001
PCEA = Patient-controlled epidural analgesia.

Note: Data are n (%), Median P 25 , P 75 ) .

“... The clinical data of maternal and neonatal were extracted from a structured electronic medical record system. Other demographic information, such as employment and family monthly income, was collected by a questionnaire. The Numeric Rating Scale (NRS) and the Chinese version of the Childbirth Attitude Questionnaire (C-CAQ) were applied to assess maternal in-labor pain intensity and fear of childbirth. The analgesic consumption and the frequency of manual boluses as rescue analgesia were stored and collected from the analgesia pump....

This is a cross-sectional study conducted from February 2018 to August 2019 in a large academic specialized hospital. The annual number of births was approximately 30,000 in recent years, ranking first in Guangdong Province. Women undergoing spontaneous or induced labor were recruited by convenient sampling immediately after being admitted to the delivery and labor room at the onset of the labor process. The inclusion criteria were 20- to 45-year-old women with singleton cephalic term pregnancies (gestational age ≥37 weeks) without severe pregnancy complications, such as heart disease, uncontrolled hypertension, and gestational diabetes mellitus. Women who had a scarred uterus, underwent artificial insemination for the current pregnancy, had a history of a significant psychiatric disorder, could not read and write Chinese, and had any contraindication to epidural analgesia were excluded.... The disparities between primiparas and multiparas were compared with independent samples t -tests or Mann-Whitney tests for continuous variables and chi-square tests for categorical variables” ( Deng et al., 2021 , p. 382).

Relevant study results
“A total of 260 women, including 97 primiparas and 163 multiparas, were included in the final data analyses. A total of 44.2% (115/260) of the women were ≥35 years of age; of the women ≥35 years of age, more were multiparas than primiparas (57.7% vs. 21.6%, P < 0.001)...

The duration of epidural analgesia was 8.00 (4.50, 10.77) h for primiparas and 3.25 (1.93, 6.23) h for multiparas ( P < 0.001). A similar percentage of primiparas and multiparas had manual boluses as rescue analgesia (91.5% vs. 94.9%, P = 0.348). Multiparas had 2.68 (1.65, 3.85) successful manual boluses per hour, and primiparas had 1.77 (0.90, 2.47) PCEA [patient-controlled epidural analgesia] successful manual boluses per hour ( P < 0.001). To exclude the effects of weight and the duration of anesthesia, the average analgesic consumption was compared. The hourly analgesic consumption was 23.00 (16.00, 28.25) mL for multiparas and 17.24 (11.52, 21.36) mL for primiparas ( P < 0.001). The average analgesic consumption was 0.35 (0.24, 0.45) mL/(h · kg) for multiparas and 0.26 (0.19, 0.35) mL/(h · kg) for primiparas ( P < 0.001)” ( Table 21.1 ; Deng et al., 2021 , p. 384).

Study questions

1.
What is the purpose of the Mann-Whitney U statistical technique? Document your response.

2.
Mann-Whitney U is the appropriate statistical test to use in which of the following situations? Provide a rationale for your answer.

a.
Correlation or relationship between two variables is being examined in a descriptive correlational study.

b.
Interval/ratio-level data with a non-normal distribution of scores for a study variable.

c.
The difference between two dependent or paired groups is being examined in a quasi-experimental study.

d.
The data collected on study variables are at the nominal level of measurement.

3.
If hourly analgesic consumption by the primipara and multipara groups were normally distributed, what would be the appropriate statistic to address differences between the two groups? Provide a rationale for your answer.

4.
State the null hypothesis for the Deng et al. (2021) study regarding hourly analgesic consumption by the primipara and multipara groups.

5.
Was the null hypothesis in Question 4 accepted or rejected? Provide a rationale for your answer.

6.
What were the median duration (in hours) of labor analgesia for each group, as displayed in Table 21.1 ?

7.
Did the two groups significantly differ on duration (in hours) of labor analgesia? Document your answer.

8.
Did the two groups significantly differ on total PCEA manual boluses? Document your answer.

9.
Why was a Mann-Whitney U test not chosen to analyze the variable of patients requiring manual bolus? Provide a rationale for your response.

10.
What is the clinical importance of knowing the hourly analgesic consumption by the two groups of study participants? Document your response.

Answers to study questions

1.
The Mann-Whitney U test is a nonparametric statistical technique used to detect differences between two independent samples (review Exercises 12 and 34 ). If the assumptions for the independent samples t -test cannot be satisfied, such as there being a dependent variable that is ordinal-level or interval/ratio-level data with the distribution of values being non-normal, then a Mann-Whitney U test is appropriate ( Kim et al, 2022 ; Knapp, 2017 ; Terrell, 2021 ).

2.
The correct answer is: b. Interval/ratio-level data with a non-normal distribution of scores on a study variable. The Mann-Whitney U test is appropriate for analyzing interval/ratio-level data when the requirements for conducting a parametric test cannot be satisfied, such as when the collected data have a non-normal or skewed distribution. The Mann-Whitney U test is designed to determine differences between groups and does not test for relationships between variables. The Mann-Whitney U test is to be used with independent and not dependent or paired groups and is for at least ordinal-level data and not nominal-level data ( Pett, 2016 ).

3.
The independent samples t -test is the most appropriate analysis technique. If the data were normally distributed and at the interval or ratio level of measurement, a parametric statistic can be computed ( de Winter & Dodou, 2010 ). The two groups were independent because the study participants were either primiparas or multiparas ( Deng et al., 2021 ). The focus of the analysis is the difference between two groups, so the most appropriate analysis technique would be the independent samples t -test (see the algorithm in Exercise 12 and computational examples in Exercise 32 ).

4.
The null hypothesis: There is no difference between the primipara and multipara groups on hourly analgesic consumption.

5.
The null hypothesis should be rejected. The p < 0.001 for hourly analgesic consumption is less than the study alpha of 0.05 ( Table 21.1 ). The null hypothesis is rejected when study results are statistically significant ( Gray & Grove, 2021 ; Pett, 2016 ).

6.
The median duration (in hours) of labor analgesia was 8.0 for the primipara group and 3.25 for the multipara group ( Table 21.1 ).

7.
Yes, the two groups significantly differed on duration (in hours) of labor analgesia, p < 0.001. The result is significant because p is less than the study alpha of 0.05.

8.
Yes, the two groups significantly differed on total PCEA manual boluses, p = 0.005. The median number of PCEA manual boluses was 12.48 for the primipara group and 8.20 for the multipara group (see Table 21.1 ). The result is significant because p is less than the study alpha of 0.05.

9.
A Pearson chi-square test, not a Mann-Whitney U test, was chosen to analyze the variable of patients requiring manual bolus. This variable is a nominal (yes/no) variable, with yes indicating the requirement of a manual bolus, and no indicating no manual bolus. Among the women in the primipara group, 75 of 82 required a manual bolus, whereas 94 of the 99 women in the multipara group required a manual bolus. As displayed in Table 21.1 , the superscript letter b in the fourth column indicates that a chi-square test was computed.

10.
The clinical importance of knowing the hourly analgesic consumption by the two groups includes planning for both the healthcare providers and the patients. If labor occurring for the first time (primiparas) requires significantly more (and longer durations of) pain management, the facilities, providers, and patients can anticipate the necessary time, costs, and resources required. The Cochrane Library in England has a large collection of systematic reviews and evidence-based guidelines and includes several resources on pain management during labor (see http://www.cochrane.org and search for “labor analgesia”). You might document with other websites, research articles, or textbooks that focus on generations of research evidence for practice ( Melnyk & Fineout-Overholt, 2023 ).

EXERCISE 21
Questions for additional study

Name: _____________________________________________________ Class: _______________________

Date: ___________________________________________________________________________________

Follow your instructor’s directions to submit your answers to the following questions for additional study. Your instructor may ask you to write your answers below and submit them as a hard copy for evaluation. Alternatively, your instructor may ask you tUnderstanding the Wilcoxon signed-rank test EPUB version of this book
Susan K. Grove, PhD, RN, ANP-BC, GNP-BC; Daisha J. Cipher, PhD

Statistics for Nursing Research, EXERCISE 22, 255-264

Statistical technique in review
The Wilcoxon signed-rank test is a nonparametric test conducted to examine differences or changes that occur between the first and second observations, such as “pretest or posttest measures for a single sample or subjects who have been matched on certain criteria” ( Pett, 2016 , p. 111). The term “paired samples” refers to a research design that repeatedly assesses the same group of people, an approach commonly referred to as repeated measures . The Wilcoxon signed-rank test is an appropriate alternative to the paired samples t -test when the assumptions for the t -test are not met. For example, the Wilcoxon signed-rank test would be computed when the data were interval or ratio level but were not normally distributed. This nonparametric test is powerful in the sense that it not only examines the direction of the change but also the degree of the change. The Wilcoxon signed-rank test requires a calculation of a difference score for each pair of scores. The greater the amount of change, the more weight the pair is given, and when no change occurs, the pair is omitted and the sample size is decreased ( Daniel, 2000 ). This test is especially effective when the sample size is small ( Pett, 2016 ). In summary, the Wilcoxon signed-rank test is a strong statistical technique used to examine differences for related groups when the data are ordinal level or when the data are interval/ratio level but not normally distributed ( Daniel, 2000 ; Kim et al., 2022 ; Pett, 2016 ).

Research article
Source
Ding, S., Lei, Q., Wu, W., Xiao, Z., Wu, Z., Chen, M., & Chen, L. (2022) . Changes in lifestyle, mood, and disease management among community-dwelling older adults during the COVID-19 pandemic in China. Aging and Health Research, 2 (1), 100059. https://doi.org/10.1016/j.ahr.2022.100059

Introduction
Ding and colleagues (2022) conducted a telephone survey to assess the effect of the novel coronavirus of 2019 (COVID-19) on the lifestyles of older adults in China. The survey was designed to assess perceived changes in lifestyle, mood, and disease management that may have occurred because of the Chinese government’s social distancing, home isolation, and lockdown requirements.

The survey was administered to older adults aged 60 and above who lived in downtown Shanghai. The researchers asked respondents to retrospectively recall their prepandemic and during-pandemic levels of home inhabitation, sleep duration and quality, diet, water intake, housework, exercise, leisure activities, and mood; 156 respondents completed the survey.

“From April 13 to May 25, 2020, a telephone survey was conducted with each participant by research nurses. The survey questionnaire contained 2 parts: 1) basic characteristics and medical history, including gender, age, education, weight, height, smoking and drinking status, medical histories, and flu vaccination history.....; 2) current and pre-pandemic (2019/11–2019/12) status in regard to lifestyle, chronic disease management, and mood. Information on lifestyle including: a. length of homestay; b. sleep status, including sleep quality (good, fair, poor), when to sleep, when to wake up, sleep duration at night, nap duration; c. diet, including daily intake of meat (including fish and poultry), vegetables, eggs, fruits, and water....; d. exercise, including time spent on housework, walking or cycling, and other exercises per day; e. leisure activities, including time spent on playing chess, reading, and using electronic products; new hobbies; and new skills they learned during the pandemic. Chronic disease management included regular monitoring of blood pressure and glucose by older adults themselves or their caregivers; routine medication-taking; and occurrence of chronic bronchitis, asthma, or flu attack. Mood included feeling calm, nervousness, upset, fear, or irritability” ( Ding et al., 2022 , Study procedure and data collection section).

“Student t -test and Wilcoxon signed-rank-sum test were used for continuous variables depending on whether assumptions of normality and homogeneity of variance test were met or not. Paired χ ² test was used for categorical variables” ( Ding et al., 2022 , Statistical analysis section).

Relevant study results
“As shown in Table 22.1 , older adults spent significantly more time at home during the pandemic than before (median: 24.0, IQR [interquartile range]: 23.0–24.0 h/day vs. median: 22.0, IQR: 20.0–23.0 h/day, P < 0.0001). They also did significantly longer naps during the pandemic than before (median: 0.6, IQR: 0–1.0 h/day vs. median: 0.5, IQR: 0–0.6 h/day, P < 0.0001). No significant differences were observed for other sleep variables. During the pandemic, the proportions of older adults with adequate consumption of meat (49.4% vs. 53.1%, P = 0.0339), and eggs (73.7% vs. 77.6%, P = 0.0143) were significantly higher than before. No significant differences were observed in regard to adequate consumption of vegetables, fruits, and water before and during the pandemic. The participants during the pandemic were more likely to gain weight (median: 63.0, IQR: 55.0–70.0 kg [kilogram] vs. median: 62.0, IQR: 55.0–70.0 kg, P = 0.0207)” ( Ding et al., 2022 , Results section).

View full size
TABLE 22.1

SLEEP, DIET BEFORE AND DURING THE PANDEMIC

From: Ding, S., Lei, Q., Wu, W., Xiao, Z., Wu, Z., Chen, M., & Chen, L. (2022). Changes in lifestyle, mood, and disease management among community-dwelling older adults during the COVID-19 pandemic in China. Aging and Health Research, 2 (1), 100059. https://doi.org/10.1016/j.ahr.2022.100059

Before the Pandemic ( n = 156)	During the Pandemic ( n = 156)	P value
Weight, kg, median (IQR)	62.0 (55.0, 70.0)	63.0 (55.0, 70.0)	0.0207
Duration at home, hour/week, median (IQR)	22.0 (20.0, 23.0)	24.0 (23.0, 24.0)	<0.0001
Sleep quality
Good, n (%)	76 (48.7)	76 (48.7)	0.8013
Fair, n (%)	60 (38.5)	61 (39.1)	
Poor, n (%)	20 (12.8)	19 (12.2)	
Sleep duration at night, hour/day, median (IQR)	6.5 (6.0, 7.0)	6.5 (6.0, 7.0)	0.7266
Nap duration, hour/day, median (IQR)	0.5 (0, 0.6)	0.59 (0, 1.0)	<0.0001
Sufficient intake of nutrients
Meat, n (%)	77 (49.4)	83 (53.1)	0.0339
Eggs, n (%)	115 (73.7)	121 (77.6)	0.0143
Vegetables, n (%)	13 (8.3)	14 (9.0)	0.7173
Fruits, n (%)	1 (0.6)	1 (0.6)	1.0000
Water, n (%)	42 (26.9)	43 (27.6)	0.3173
IQR = interquartile range.

It should be noted that this article represents each p value with an uppercase P because the American Journal of Infection Control displays p as uppercase. Most journals of nursing research require formatting in accordance with the American Psychological Association ( APA, 2020 ) which requires p to be lowercase.

The “IQR” in the Results section refers to the interquartile range. The interquartile range of a variable consists of the two values that mark the middle 50% of the variable’s values. For example, one interquartile range for weight is listed as “IQR: 55.0–70.0 kg.” This means that 50% of the participants’ weights fell between 55.0 kilograms and 70.0 kilograms. One quarter (25%) of the participants’ weights were lower than 55.0 kilograms, and 25% were higher than 70.0 kilograms.

Study questions

1.
What was the sample size for this study? Was the sample size adequate? Provide a rationale for your response.

2.
Do the data meet criteria for “paired samples”? Provide a rationale for your answer.

3.
What are the median weights in kilograms at prepandemic and during-pandemic?

4.
What is the p value for the Wilcoxon signed-rank test for weight? Is this p value statistically significant? Provide a rationale for your answer.

5.
What scale of measurement is the variable of nap duration in Table 22.1 ?

6.
What are the median values for nap duration at prepandemic and during-pandemic?

7.
What is the p value for the Wilcoxon signed-rank test for nap duration? Is this p value statistically significant? Provide a rationale for your answer.

8.
Why do you think medians and IQR values are reported in Table 22.1 instead of means?

9.
What was the research design used in this study? Was it an appropriate design to address the study purpose?

10.
The researchers concluded that the “... COVID-19 pandemic affected the lifestyle, mood, and chronic disease management among community-dwelling older adults.” What are some alternative explanations for these changes because of the research design of the study? Document your response.

Answers to study questions

1.
The sample size was 156 respondents, as indicated by the study narrative and Table 22.1 . The researchers did not report the results of a power analysis in this article. However, there were a number of significant findings, lending support to the conclusion that the analyses were most likely adequately powered (see Exercises 24 and 25 ).

2.
Yes, the data meet criteria for “paired samples” because the prepandemic and during-pandemic study variables were collected from the same group of study participants during a single survey experience involving recollections of the respondents.

3.
The median value for the prepandemic weight was 62.0 kg, versus 63.0 kg for weight at during-pandemic.

4.
The Wilcoxon signed-rank test resulted in p = 0.0207 for the change in weight from prepandemic to during-pandemic, meaning weight was significantly greater during-pandemic compared with prepandemic weight. Statistical significance for this study was set at α = 0.05. Thus the results for the change in weight is statistically significant because p = 0.0207 is less than α = 0.05 ( Gray & Grove, 2021 ). This result is statistically significant but not really clinically important, because the weight change was only 1 kg or 2.2 lb.

5.
The variable of nap duration is defined as number of hours per day. Because number of hours has numerically equal intervals and an absolute zero point, it is considered a ratio (see Exercise 1 ).

6.
The median nap durations reported for prepandemic and during-pandemic were 0.50 and 0.59 hours per day, respectively.

7.
The Wilcoxon signed-rank test resulted in p < 0.0001 for the change in nap duration from prepandemic to during-pandemic, meaning that nap duration was significantly greater during-pandemic compared with prepandemic. Statistical significance for this study was set at α = 0.05. Thus the results for the increase in nap duration is statistically significant because p < 0.0001 is less than α = 0.05 ( Gray & Grove, 2021 ).

8.
It is likely that medians and IQR values are reported in Table 22.1 instead of means because the data did not meet the normality assumption for a paired samples t -test. When the dependent variable is not normally distributed, a nonparametric test is more appropriate (see Exercise 33 ). Moreover, a median can be more infoSelecting appropriate analysis techniques for studies EPUB version of this book
Susan K. Grove, PhD, RN, ANP-BC, GNP-BC; Daisha J. Cipher, PhD

Statistics for Nursing Research, EXERCISE 23, 265-279

Multiple factors are involved in determining the suitability of a statistical procedure for a particular study. Some of these factors are related to the nature of the study, some to the nature of the researcher, and others to the nature of statistical theory. Specific factors include the following: (1) purpose of the study; (2) study hypotheses, questions, or objectives; (3) study design; (4) level of measurement of variables in a study; (5) previous experience in statistical analysis; (6) statistical knowledge level; (7) availability of statistical consultation; (8) financial resources; and (9) access and knowledge of statistical software. Use items 1 to 4 to identify statistical procedures that meet the requirements of a particular study, and then further narrow your options through the process of elimination based on items 5 through 9.

The most important factor to examine when choosing a statistical procedure is the study hypothesis or primary research question. The hypothesis that is clearly stated indicates the statistic(s) needed to test it. An example of a clearly developed hypothesis is: There is a difference in infection occurrences between an experimental group and a control group. This statement tells the researcher that a statistic to determine differences between two groups is appropriate to address this hypothesis. This statement also informs the researcher that the dependent variable is an occurrence, which is binary (dichotomous): infected or not infected.

One approach to selecting an appropriate statistical procedure or judging the appropriateness of an analysis technique is to use an algorithm or decision tree. A statistical algorithm directs your choices by gradually narrowing your options through the decisions you make. A statistical algorithm developed by Cipher (2021) that can be helpful in selecting statistical procedures is presented in Fig. 23.1 . This is the same algorithm presented and reviewed in Exercise 12 for determining the appropriateness of the statistical tests and results presented in research reports.

A flow chart outlines the recommended statistical tests based on research question type, variable measurement, group number, and research design. The flow chart includes two main branches labeled Differences and Associations or relationships. Under Differences, the measurement of the dependent variable is divided into Nominal, Ordinal, and Interval or ratio. For Nominal variables, one group uses one sample chi square. Two independent samples use Fisher's exact test, odds ratio, or chi square. Two paired samples use McNemar's test. More than two independent samples use Pearson chi square. More than two paired samples use Cochran's Q test. For Ordinal variables, two independent samples use Mann Whitney U test. Two paired samples use Wilcoxon signed rank test. More than two independent samples use Kruskal Wallis test. More than two paired samples use Friedman test. For Interval or ratio variables, one group uses one sample t test. Two independent samples use independent samples t test. Two paired samples use paired samples t test. More than two independent samples use one way analysis of variance. More than two paired samples use repeated measures analysis of variance. Under Associations or relationships, for Nominal variables with one or more groups, the recommended statistics are phi, odds ratio, contingency coefficient, Cramer's V, and logistic regression. For Ordinal variables with one group, the recommended statistics are Spearman rank order correlation coefficient, Kendall tau, and Somers D. For Interval or ratio variables with one group, the recommended statistics are Pearson product moment correlation coefficient and simple and multiple linear regression.
FIG. 23.1 ■
STATISTICAL SELECTION ALGORITHM.

One disadvantage of a statistical algorithm is that if you make an incorrect or uninformed decision (i.e., a guess), you can be led down a path in which you might select an inappropriate statistical procedure for your study. Algorithms are often constrained by space and therefore do not include all the information needed to make an appropriate selection of a statistical procedure for a study. The following examples of questions are designed to guide the selection or evaluation of statistical procedures that are reflected in Fig. 23.1 . Each question confronts you with a decision, and the decision you make narrows the field of available statistical procedures.

1.
Is the research question/hypothesis descriptive, associational (correlational), or difference-oriented?

2.
How many variables are involved?

3.
What is the measurement scale (see Exercise 1 ) of the independent and dependent variable(s)?

4.
What is the distribution of the dependent variables (normal, non-normal)?

5.
Do the data meet the assumptions for a parametric statistic (see Exercise 1 )?

As you can see, selecting and evaluating statistical procedures requires that you make a number of judgments regarding the nature of the data and what you want to know. Knowledge of the statistical procedures and their assumptions is necessary for selecting appropriate procedures. You must weigh the advantages and disadvantages of various statistical options. Access to a statistician can be invaluable in selecting the appropriate procedures.

Statistics to address basic difference research questions and hypotheses
The following statistics address research questions or hypotheses that involve differences between groups or assessments. This list is by no means exhaustive, but it represents the most common parametric and nonparametric inferential statistics involving differences. Exercises 1 and 12 discuss the concepts of parametric versus nonparametric statistics and inferential versus descriptive statistics.

t -test for independent samples
One of the most common statistical tests chosen to investigate differences between two independent samples is the independent samples t -test, which is a parametric inferential statistic. The independent samples t -test only compares two groups at a time, and the dependent variable must be continuous and normally distributed ( Kim et al., 2022 ; Zar, 2019 ). The independent samples t -test is reviewed in Exercise 16 , and the process for conducting the independent samples t -test is in Exercise 32 .

t -test for paired samples
A paired samples t -test (also referred to as a dependent samples t -test) is a statistical procedure that compares two sets of data from one group of people (or naturally occurring pairs, such as siblings or spouses). This t -test is a parametric inferential statistical test. The dependent variable in a paired samples t -test must be continuous and normally distributed ( Zar, 2019 ). The term paired samples refers to a research design that repeatedly assesses the same group of people, an approach commonly referred to as repeated measures ( Kazdin, 2022 ). The t -test for paired samples is reviewed in Exercise 17 , and the process for conducting the paired samples t -test is in Exercise 33 .

One-way analysis of variance
The one-way analysis of variance (ANOVA) is a parametric inferential statistical procedure that compares data between two or more groups or conditions to investigate the presence of differences between those groups on some continuous, normally distributed dependent variable (see Fig. 23.1 ). There are many types of ANOVAs. The one-way ANOVA involves testing one independent variable and one dependent variable (as opposed to other types of ANOVAs, such as factorial ANOVAs, that incorporate multiple independent variables). ANOVA is reviewed in Exercise 18 , and the process for conducting ANOVA is presented in Exercise 35 .

Repeated-measures ANOVA
A repeated-measures ANOVA is a statistical procedure that compares multiple sets of data from one group of people. The dependent variable in a repeated-measures ANOVA must be continuous and normally distributed. The term repeated measures refers to a research design that repeatedly assesses the same group of people over time. Repeated measures can also refer to naturally occurring pairs, such as siblings or spouses ( Gliner et al., 2017 ).

Mann-Whitney U test
The Mann-Whitney U test is the nonparametric alternative to an independent samples t -test. Like the independent samples t -test, the Mann-Whitney U test is a statistical procedure that compares differences between two independent samples. However, the Mann-Whitney U is the preferred test over the independent samples t -test when the distribution of the dependent variable significantly deviates from normality, or the dependent variable is measured at the ordinal level and cannot be treated as an interval/ratio-scaled variable ( Gray & Grove, 2021 ; Pett, 2016 ). The Mann-Whitney U is reviewed in Exercise 21 , and Exercise 34 provides the steps for conducting this test.

Kruskal-Wallis test
The Kruskal-Wallis test is the nonparametric alternative to the one-way ANOVA. Like the one-way ANOVA, the Kruskal-Wallis test is a statistical procedure that compares differences between two or more groups. However, the Kruskal-Wallis test is the preferred test over the ANOVA when the distribution of the dependent variable significantly deviates from normality, or the dependent variable is ordinal and cannot be treated as an interval/ratio-scaled variable ( Holmes, 2018 ; Kim et al., 2022 ; Pett, 2016 ).

Friedman test
The Friedman test is the nonparametric alternative to a repeated-measures ANOVA. Like the repeated-measures ANOVA, the Friedman test is a statistical procedure that compares multiple sets of data from one group of people. However, the Friedman test is the preferred test over the repeated-measures ANOVA when the dependent variable data significantly deviate from a normal distribution, or the dependent variable is ordinal and cannot be treated as an interval/ratio-scaled variable ( Pett, 2016 ).

Wilcoxon signed-rank test
The Wilcoxon signed-rank test is the nonparametric alternative to the paired samples t -test. Like the paired samples t -test, the Wilcoxon signed-rank test is a statistical procedure that compares two sets of data from one group of people. However, the Wilcoxon signed-rank test is the preferred test over the paired samples t -test when the dependent variable data significantly deviate from a normal distribution, or the dependent variable is ordinal and cannot be treated as an interval/ratio-scaled variable ( Pett, 2016 ). The Wilcoxon signed-rank test is reviewed in Exercise 22 .

Pearson chi-square test
The Pearson chi-square test (also referred to as χ 2 ) is a nonparametric inferential statistical test that compares differences between groups on variables measured at the nominal level. The chi-square test compares the frequencies that are observed with the frequencies that are expected. When a study requires that researchers compare proportions (percentages) in one category versus another category, the chi-square test is a statistic that will reveal if the difference in proportion is statistically improbable. A one-way chi-square test is a statistic that compares different levels of one variable only. For example, a one-way chi-square test could be computed to identify differences in proportions of a nominal variable such as rural area versus metropolitan area. A two-way chi-square test is a statistic that tests whether proportions in levels of one nominal variable are significantly different from proportions of the second nominal variable. For example, a two-way chi-square test could be computed to identify differences between nurses working in rural areas and nurses working in urban/metropolitan areas on the proportions of patients screened for depression. The Pearson chi-square test is reviewed in Exercise 19 , and Exercise 37 provides the steps for conducting this test.

Statistics to address basic associational/correlational research questions and hypotheses
The following statistics address research questions or hypotheses that involve associations or correlations between variables. This list is by no means exhaustive, but it represents the most common parametric and nonparametric inferential statistics involving associations.

Pearson product-moment correlation coefficient
The Pearson product-moment correlation coefficient is a parametric inferential statistic computed between two continuous, normally distributed variables (see Fig. 23.1 ). The Pearson correlation is represented by the statistic r , and the value of the r is always between −1.00 and +1.00. A value of zero indicates absolutely no relationship between the two variables; a positive correlation indicates that higher values of x are associated with higher values of y ; and a negative, or inverse, correlation indicates that higher values of x are associated with lower values of y ( Grove & Gray, 2023 ; Kim et al., 2022 ). The Pearson r is reviewed in Exercise 13 , and Exercise 29 provides steps for conducting this analysis.

Spearman rank-order correlation coefficient
The Spearman rank-order correlation coefficient is the nonparametric alternative to the Pearson r . Like the Pearson correlation, the Spearman rank-order correlation is a statistical procedure that examines the association between two continuous variables. However, the Spearman rank-order correlation is the preferred test over the Pearson r when one or both of the variables significantly deviate from a normal distribution, or the variables are ordinal and cannot be treated as an interval/ratio-scaled variable ( Pett, 2016 ). The Spearman rank-order correlation is reviewed in Exercise 20 .

Phi/Cramer V
The phi (φ) coefficient is the nonparametric alternative to the Pearson r when the two variables being correlated are both binary (dichotomous). Like the Pearson r and Spearman rank-order correlation coefficient, the phi yields a value between −1.0 and +1.0, where a zero represents no association between the variables. The Cramer V is the nonparametric alternative to the Pearson r when the two variables being correlated are both nominal. The Cramer V yields a value between 0 and 1, where a zero represents no association between the variables and a 1 represents a perfect association between the variables ( Prett, 2016 ).

Odds ratio
When both the predictor and the dependent variables are dichotomous (variables that have only two values; binary), the odds ratio is a commonly used statistic to obtain an indication of association ( Gray & Grove, 2021 ). The odds ratio ( OR ) is defined as the ratio of the odds of an event occurring in one group to the odds of it occurring in another group. An OR of >1.0 indicates that the predictor is associated with higher odds of the outcome, and an OR of <1.0 indicates that predictor is associated with lower odds of the outcome ( Celentano & Szklo, 2018 ). OR s are commonly computed in case-control studies, when the OR can identify an association between a treatment or exposure and the odds of a specific event/outcome occurring. The larger the OR , the higher the odds that the outcome will occur with treatment/exposure.

The OR can also be computed when the dependent variable is binary (dichotomous) and the predictor is continuous and would be computed by performing logistic regression analysis. Logistic regression analysis tests a predictor (or set of predictors) with a binary dependent variable. Whether the predictor is binary or continuous, an OR of 1.0 indicates that the predictor does not affect the odds of the outcome. The further the OR value is from 1.0 (either higher than or lower than), the greater the likelihood that a real association exists between the two variables. The steps for conducting the odds ratio are presented in Exercise 38 .

Simple and multiple linear regression
Linear regression is a procedure that provides an estimate of the value of a dependent variable based on the value of an independent variable or set of independent variables, also referred to as predictors . Knowing that estimate with some degree of accuracy, we can use regression analysis to predict the value of one variable if we know the value of the other variable. The regression equation is a mathematical expression of the influence that a predictor (or set of predictors) has on a dependent variable, based on a theoretical framework. A regression equation can be generated with a dataset containing participant’s x and y values. The score on variable y (dependent variable, or outcome) is predicted from the same participant’s known score on variable x (independent variable, or predictor) ( Kim et al., 2022 ; King & Eckersley, 2019 ). Simple linear regression is reviewed in Exercise 14 , and Exercise 30 provides the steps for conducting this analysis. Multiple linear regression is reviewed in Exercise 15 , and Exercise 31 provides steps for conducting this analysis.

Applying inferential statistics to population data
Secondary data analyses of large state and national datasets can be an economically feasible and time-efficient way for nurse researchers to address important health, epidemiologic, and clinical research questions. However, data that were collected on a national level using complex sampling procedures, such as those survey data made available to researchers by the Centers for Disease Control and Prevention or the Centers for Medicare and Medicaid Services, require specific weighting procedures before computing inferential statistics. Aponte (2010) conducted a thorough review of publicly available population datasets with nurse researchers in mind and elaborated on the advantages and disadvantages of using population survey data.

When the researcher is analyzing secondary population-based datasets, much attention must be given to the quality of the data, the extent of missing data, and the manner in which the data were sampled. Analyses of secondary population data involve much data cleaning, which can include recoding, missing data imputation, and weighting for complex sampling approaches. Point and click software programs such as SPSS Statistics Base (IBM SPSS Statistics for Windows, Version 22.0. Armonk, NY: IBM Corp.) can be used by the researcher for data cleaning; however, they cannot be used to adjust the data for complex sampling. There are only a handful of statistical software programs that can address the adjustments for sampling required by population survey data ( Aday & Cornelius, 2006 ; Aponte, 2010 ). When such data are analyzed without adjusting for sampling, the results are at risk for Type I error and are generally considered invalid ( Aday & Cornelius, 2006 ). In this text, the exercises focused on calculating statistical analyses ( Exercise 29 , Exercise 30 , Exercise 31 , Exercise 32 , Exercise 33 , Exercise 34 , Exercise 35 , Exercise 36 , Exercise 37 , Exercise 38 ) involve data from samples and not data from populations.

Study questions

1.
What statistic would be appropriate for an associational research question or hypothesis involving the correlation between two normally distributed continuous variables?

2.
What statistic would be appropriate for a difference research question involving the comparison of two repeated assessments from one group of participants, where the dependent variable is measured at the interval/ratio level or is continuous and the data are normally distributed?

3.
A nurse educator is interested in the difference between traditional clinical instruction and simulated instruction in an undergraduate nursing pediatrics course. She randomizes students to receive 50 hours of either traditional clinical rotations in a pediatrics department or 50 hours of simulated instruction in pediatrics. At the end of the 50 hours, the students are assessed for clinical competency in pediatrics using a standardized instrument that yields a continuous score, where higher values represent higher levels of competency. Her research question is: Is there a difference between the traditional clinical group and the simulation group on clinical competency? What is the appropriate statistic to address the research question if the scores are normally distributed?

4.
What is the appropriate statistic to address the research question in Question 3 if the scores are NOT normally distributed?

5.
What statistic would be appropriate for a difference research question involving the comparison of two groups on a dichotomous dependent variable? Provide a rationale for your answer.

6.
A researcher surveyed a sample of college students with two measures. The first measure was an assessment of loneliness, and the second measure was an assessment of stress. The two variables are normally distributed continuous variables. Her research question is: Does loneliness predict stress levels among college students? What is the appropriate statistic to address the research question?

7.
Describing the elements of power analysis: Power, effect size, alpha, and sample size EPUB version of this book
Susan K. Grove, PhD, RN, ANP-BC, GNP-BC; Daisha J. Cipher, PhD

Statistics for Nursing Research, EXERCISE 24, 280-289

The deciding factor in determining an adequate sample size for descriptive, correlational, quasi-experimental, and experimental studies is power. Power is the probability that a statistical test will detect an effect when it actually exists. Therefore, power is the inverse of Type II error and is calculated as 1 − β. Type II error is the probability of retaining the null hypothesis when it is in fact false. When the researcher sets Type II error at the conventional value of 0.20 prior to conducting a study, this means that the power of the planned statistic has been set to 0.80. In other words, the statistic will have an 80% chance of detecting an effect if an effect actually exists.

Power analysis can address the number of participants required for a study or, conversely, the extent of the power of a statistical test. A power analysis performed prior to the study beginning to determine the required number of participants needed to identify an effect is termed an a priori power analysis . A power analysis performed after the study ends to determine the power of the statistical result is termed a post hoc power analysis . Optimally, the power analysis is performed prior to the study so that the researcher can plan to include an adequate number of participants. Otherwise, the researcher risks conducting a study with an inadequate number of participants and putting the study at risk for Type II error ( Aberson, 2019 ; Taylor & Spurlock, 2018 ). The four factors involved in a power analysis are as follows:

1.
Level of significance (α, or alpha level), usually 0.05.

2.
Probability of obtaining a significant result (power desired, or 1 − β), usually 0.80.

3.
The hypothesized or actual effect (association among variables or difference between your groups).

4.
Sample size.

Knowing any of the three factors listed above allows researchers to compute the fourth ( Cohen, 1988 ; Hayat, 2013 ). Significance (α) level and sample size are fairly straightforward. Effect size is “the degree to which the phenomenon is present in the population, or the degree to which the null hypothesis is false” ( Cohen, 1988 , pp. 9-10). For example, suppose you were measuring changes in anxiety levels, measured first when the patient is at home and then just before surgery. The effect size would be large if you expected a great change in anxiety. If you expected only a small change in the level of anxiety, the effect size would be small.

Small effect sizes require larger samples to detect these small differences. If the power is too low, it may not be worthwhile conducting the study unless a sample large enough to detect an effect can be obtained. Deciding to conduct a study in these circumstances is costly in terms of time and money, minimally adds to the body of nursing knowledge, and can actually lead to false conclusions ( Taylor & Spurlock, 2018 ). Power analysis can be conducted via hand calculations, computer software, or online calculators and should be performed to determine the sample size necessary for a particular study ( Aberson, 2019 ). For example, a power analysis can be calculated by using the free power analysis software G*Power ( Faul et al., 2009 ) or statistical software such as NCSS, SAS, and SPSS. Moreover, there are many free sample size calculators online that are easy to use and understand.

The notion of whether researchers should conduct a post hoc power analysis after a study fails to reject the null hypothesis has been greatly debated ( Hayat, 2013 ). This is because there is a strong association between the p value of the finding and the post hoc power; the lower the p value, the higher the power, and vice versa. Therefore any finding that fails to yield statistical significance will inevitably be associated with low power ( Levine & Ensom, 2001 ). Because of this phenomenon, reporting a post hoc power analysis may be considered redundant. On the other hand, if power was high, the post hoc power analysis may strengthen the meaning of the findings. Many researchers advocate the reporting of effect sizes and confidence intervals in the results of research articles in addition to or instead of post hoc power analyses ( Hayat, 2013 ; Levine & Ensom, 2001 ).

One appropriate context for a post hoc power analysis might be an exploratory pilot study, when a researcher analyzes the study data and reports the obtained effect size on which to base a future study ( Hayat, 2013 ). For any study that results in low statistical power, the researcher needs to address this issue in the discussion of limitations and implications of the study findings. Modifications in the research methodology that resulted from the use of power analysis also need to be reported. Therefore, the researcher must evaluate the elements of the methodology that affect the required sample size, which include the following:

1.
Statistical power corresponds to one type of statistical test at a time. If the researcher is planning to compute different categories of statistical tests, in order to adequately power the study one must perform a power analysis for each planned statistical procedure ( Hayat, 2013 ). For example, if the researcher is planning an analysis of variance (ANOVA) to address the first research question, and a chi-square test (χ 2 ) to address the second research question, the study will not be adequately powered unless both statistical tests are addressed with power analyses. In this example, the researcher would need to perform two power analyses, one for each research objective or hypothesis.

2.
The more stringent the α (e.g., 0.001 vs. 0.05), the greater the necessary sample size due to the reduced probability of a Type I error. With α = 0.001, the probability of Type I error is 1 chance in 1000; with α = 0.05, there are 5 chances for error in 100 analyses conducted.

3.
Two-tailed statistical tests require larger sample sizes than one-tailed tests because two-tailed tests require a larger critical statistical value to yield significance than a one-tailed test ( Kim et al., 2022 ; Zar, 2010 ).

4.
The smaller the effect size, the larger the necessary sample size because the effect size indicates how strong the relationship is between variables and the strength of the differences between groups ( Taylor & Spurlock, 2018 ).

5.
The larger the power required, the larger the necessary sample size. For example, a power set at 0.90 requires a larger sample size than the standard power set at 0.80.

6.
The smaller the sample size, the smaller the power of the study ( Cohen, 1988 ).

Effect size
Cohen (1988) defined effect size as “the degree to which the phenomenon is present in the population.” There are many different types of effect size measures, and each corresponds to the type of statistic computed. A decision tree developed by Cipher (2023) that can be helpful in selecting statistical procedures is presented in Fig. 23.1 of Exercise 23 in this text. The researcher needs to have identified the statistic(s) required to address the research question or hypothesis prior to conducting the power analysis. For example, if we were planning to compute an independent samples t -test, then the effect size in the power analysis would be a Cohen’s d ( Cohen, 1988 ). If we were planning to compute one-way ANOVA, then the effect size in the power analysis would be a Cohen’s f . A Pearson correlation coefficient ( r ) serves as its own effect size, as does the odds ratio ( OR ). Table 24.1 is a compilation of seven of the most common effect sizes used in power analyses. This table was created by extracting the information presented in the seminal text on power analysis by Cohen (1988) and provides three magnitudes of effects: small, moderate, and large.

View full size
TABLE 24.1

MAGNITUDE RANGES OF SEVEN COMMON EFFECT SIZES

Effect Size	Cohen’s d	Cohen’s d z	Cohen’s f	r	R 2	OR	d
Small	0.20	0.20	0.10	0.10	0.02	1.5	0.05
Moderate	0.50	0.50	0.25	0.30	0.13	2.5	0.15
Large	0.80	0.80	0.40	0.50	0.26	4.3	0.25
Cohen’s d = difference between two groups in standard deviation units

Cohen’s d z = difference between two paired assessments when the correlation between the pairs is r = 0.50

Cohen’s f = difference between more than two groups

r = Pearson r

R 2 = variance explained in linear regression model

OR = odds ratio

d = difference between proportions when one of the two groups’ rates = 50%

Cohen’s d
The most common effect size measure for a two-sample design (that is, a two-group comparison) is Cohen’s d . Cohen’s d is calculated as follows:

d
=
X
¯
1
−
X
¯
2
SD
where 
X
¯
1
 and 
X
¯
2
 are the means for Groups 1 and 2, respectively, and the SD would be the standard deviation of either group, considering that both groups are assumed to have approximately equal SD s.

The resulting d value represents the difference between the means of Groups 1 and 2, in SD units. Thus a value of 1.0 means that the two groups differed exactly 1 SD unit from one another. One can still compute the Cohen’s d even if the design has more than two groups, but the Cohen’s d is calculated one pair at a time. However, the more appropriate effect size for comparing three or more groups, such as a one-way ANOVA, is the f.

Cohen’s d z
Cohen’s d z is almost identical to Cohen’s d above, except the d z applies to paired samples instead of independent samples. Like Cohen’s d , Cohen’s d z also represents the difference between two means in SD units. However, Cohen’s d z is computed with two means of paired values. These paired values are most often from one group of people, but they can also be composed of paired data from naturally occurring pairs, such as siblings or spouses.

When the correlation ( r ) between the paired values is approximately r = 0.50, then the ranges of the magnitude of effect in terms of small, moderate, and large are the same as that of Cohen’s d , where small = 0.20, moderate = 0.50, and large = 0.80 or greater. However, when the correlation between the paired values is smaller, then the resulting magnitude of effect is smaller. Likewise, when the correlation between the paired values is larger, the resulting magnitude of effect is larger. For example, if there is a 0.50 mean difference between two paired samples, with a high r of the paired values at r = 0.80, the d z = 0.79 (a large effect). On the other hand, if there is a 0.50 mean difference between two paired samples, with a low r of the paired values at r = 0.20, the d z = 0.40 (a small to moderate effect). Therefore the magnitude of the association between the pairs has a direct impact on the magnitude of the d z value ( Cohen, 1988 ).

Cohen’s f
Like Cohen’s d, Cohen’s f also expresses effect size in standard deviation units but does so for two or more groups. When planning a one-way ANOVA, Cohen’s f can be computed to determine the differences between the groups. Like the ANOVA, the Cohen’s f will identify the magnitude of the differences among all of the groups, but it will not explain differences between specific groups. For two groups, f = 1/2 d. Conversely, d = 2 f ( Cohen, 1988 ).

Pearson r
The Pearson product-moment correlation coefficient was the first of the correlation measures developed and is computed on two continuous, approximately normally distributed variables (see Exercises 13 and 29 ). This coefficient (statistic) is represented by the letter r , and the value of the r is always between −1.00 and +1.00. A value of zero indicates absolutely no relationship between the two variables; a positive correlation indicates that higher values of x are associated with higher values of y ; and a negative, or inverse, correlation indicates that higher values of x are associated with lower values of y and vice versa. The r value is indicative of the slope of the line (called a regression line) that can be drawn through a standard scatterplot of the two variables (see Exercise 11 ). The strengths of different relationships are identified in Table 24.1 .

R 2
The R 2 , also referred to as the coefficient of determination, is the effect size for linear regression. The R 2 represents the percentage of variance explained in y by the predictor (see Exercises 14 and 30 ). Simple linear regression provides a means to estimate the value of a dependent variable based on the value of an independent variable. Multiple regression analysis is an extension of simple linear regression in which more than one independent variable is entered into the analysis to predict a dependent variable (see Exercises 15 and 31 ).

Odds ratio
When both the predictor and the dependent variable are dichotomous, the odds ratio ( OR ) is a commonly used statistic to obtain an indication of association (see Exercise 38 ). The odds ratio is defined as the ratio of the odds of an event occurring in one group to the odds of it occurring in another group ( Celentano & Szklo, 2018 ). Put simply, the OR is a way of comparing whether the odds of a certain event is the same for two groups. The OR can also be computed when the dependent variable is dichotomous and the predictor is continuous, and would be computed by performing logistic regression analysis. Logistic regression analysis tests a predictor (or set of predictors) with a dichotomous dependent variable. The output yields an adjusted OR, meaning that each predictor’s OR represents the relationship between that predictor and y , after adjusting for the presence of the other predictors in the model ( Tabachnick & Fidell, 2019 ).

d
For a two-sample comparative design where the dependent variable is dichotomous, the d is the effect size used in the power analysis. The letter “d” represents the difference in percentages in Group 1 versus Group 2. One example might be to compare employment rates in an intervention and control groups. We have evidence that our control group will have a 50% employment rate, and the intervention will be 15% higher, at 65%. Thus, our anticipated d would be 65% − 50% = 15%. In Exercise 25 , we will present a power analysis using each of the effect sizes described in this exercise.

Study questions

1.
Define statistical power.

2.
List the four components of a power analysis.

3.
Define power and beta and discuss the importance of power and beta in a study.

4.
What is the difference between Cohen’s d and Cohen’s d z ?

5.
Using the values in Table 24.1 , what would be considered a small Pearson r ? How would this value affect sample size for a study?

6.
Prior to conducting a power analysis, a researcher reviewed the literature and discovered that a study similar to hers reported an OR value of 2.75. According to Table 24.1 , how would you characterize the magnitude of that effect?

7.
Prior to conducting a power analysis, a researcher reviewed the literature and discovered a similar study reported an R 2 value of 0.30, or 30%. According to Table 24.1 , how would you characterize the magnitude of that effect?

8.
Prior to performing the power analysis, a researcher debates whether to set the study α at 0.05 or 0.01. Which α level will require more study participants? Provide a rationale for your answer.

9.
Prior to performing the power analysis, a researcher debates whether to set the study beta (β) at 0.15 or 0.20. Which beta level will require more study participants? Provide a rationale for your answer.

10.
What is the difference between Cohen’s d and d?

Answers to study questions

1.
Power is the probability that a statistical test will detect an effect (that is, a difference between groups or a relationship between variables) when it actually exists.

2.
The four components of a power analysis are alpha, power, effect size, and sample size ( Aberson, 2019 ).

3.
Beta (β) is the probability of making a Type II error, and power is the inverse of beta, or 1 − β. Because of the inverse association between beta and power, lower values of beta allow for a larger likelihood of finding an effect when one is present (power).

4.
Cohen’s d is the effect size for a two-sample design for a continuous, normally distributed dependent variable, whereas Cohen’s d z is the effect size for a one-sample design for a continuous, normally distributed dependent variable. Both Cohen’s d and Cohen’s d z represent the difference between two means in SD units. However, Cohen’s d is computed with two independent means, and Cohen’s d z is computed with two means of paired values.

5.
A small Pearson r would be any value equal to or less than 0.10, and would result in a lower required sample size because a small effect size requires a higher critical statistical value to yield significance ( Cohen, 1988 ; Taylor & Spurlock, 2018 ).

6.
An OR value of 2.75 would be considered a moderate effect size.

7.
An R 2 value of 30% would be considered a large effect size.

8.
Setting the alpha at 0.01 will require more study participants. A smaller alpha requires a larger sample size because the statistical test will require a larger critical statistical value to yield significance ( Gray & Grove, 2021 ).

9.
Setting the beta at 0.15 will require more study participants because there is less potential for error than with beta set at 0.20. With beta set at 0.15, the power is stronger (85%) than with beta set at 0.20 (80%) ( Cohen, 1988 ).

10.
Cohen’s d is the effect size for a two-sample design for a continuous, normally distributed dependent variable, whereas d is the effect size for a two-sample design for a dichotomous dependent variable ( Aberson, 2019 ; Cohen, 1988 ).

EXERCISE 24
Questions for additional study

Name: _____________________________________________________ Class: _______________________

Date: ___________________________________________________________________________________

Follow your instructor’s directions to submit your answers to the following questions for additional study. Your instructor may ask you to write your answers below and submit them as a hard copy for evaluation. Alternatively, your instructor may ask you to submit your answers online.

1.
When is the optimal time to perform a power analysis—before the beginning of the study or after the study ends? Provide a rationale for your answer.

2.
Define effect size.

3.
A researcher is plaConducting power analysis EPUB version of this book
Susan K. Grove, PhD, RN, ANP-BC, GNP-BC; Daisha J. Cipher, PhD

Statistics for Nursing Research, EXERCISE 25, 290-307

Exercise 24 described the components of a power analysis: α, power (1 − β), hypothesized effect, and sample size ( N ). Seven common effect sizes were presented: r , R 2 , Cohen’s d , Cohen’s d z , Cohen’s f , d, and OR ( Table 25.1 ). For an a priori power analysis, the researcher has already stated the research problem and the corresponding research question or hypothesis. Because the size of the effect in a power analysis is directly linked to the required sample size, it is crucial that the hypothesized effect be accurate. Sometimes, prior reports of a similar study or studies exist in the literature to determine the magnitude of the hypothesized effect chosen for the power analysis. Other times, a paucity of published studies hinders the researcher’s ability to find effect size information. Effect size information includes any values in the study that allow the reader to directly or indirectly calculate an effect size. For example, reporting means and SD s would allow the reader to calculate a Cohen’s d . A table of percentages for different groups would allow the reader to compute a d value (difference between rates).

View full size
TABLE 25.1

MAGNITUDE RANGES OF SEVEN COMMON EFFECT SIZES

Effect Size	Cohen’s d	Cohen’s d z	Cohen’s f	r	R 2	OR	d
Small	0.20	0.20	0.10	0.10	0.02	1.5	0.05
Moderate	0.50	0.50	0.25	0.30	0.13	2.5	0.15
Large	0.80	0.80	0.40	0.50	0.26	4.3	0.25
Cohen’s d = difference between two groups in standard deviation units

Cohen’s d z = difference between two paired assessments when the correlation between the pairs is r = 0.50

Cohen’s f = difference between more than two groups

r = Pearson r

R 2 = variance explained in linear regression model

OR = Odds ratio

d = difference between proportions when one of the two groups’ rates = 50%

It is very important to conduct an extensive search of the literature to yield the most accurate effect size information possible ( Taylor & Spurlock, 2018 ). Sometimes, effect sizes found in the literature differ in magnitude. For example, a researcher may be investigating effects for an association between two variables of interest, and finds studies reporting Pearson r values of varying sizes. The process of deciding which effect size to use in one’s own power analysis can be very difficult. The researcher must take into account the sample sizes of each study, the quality of the methodology, the quality of the measurement, and the similarity of the population to which the researcher plans to investigate. A study with a larger sample size using a sample with characteristics similar to the researcher’s own target population is likely to yield the highest generalizability.

If the literature review does not produce any helpful effect size information, then the researcher may consider contacting other investigators in the field to obtain guidance ( Hulley et al., 2013 ). A small pilot study could be conducted to obtain effect size information, although the typically smaller sample sizes used in pilot studies yield less stable or reliable effect size estimates because sample size affects power. If these options are not available, then the planned study should be considered a pilot study, because it has been established that it is the first of its kind to address the research question. Pilot studies, by and large, are by definition underpowered studies. Therefore, although a pilot study can provide useful information about the presence of an effect, the researcher should take caution in relying solely on this information when conducting a power analysis ( Hayat, 2013 ). Ultimately, effects from prior published empirical studies are the preferred method to obtaining effect sizes for a priori power analyses.

G*Power 3.1 is a free power analysis software available for download ( Faul et al., 2009 ). The download is available at http://www.gpower.hhu.de/en.html . Exercise 25 presents seven power analyses using G*Power 3.1, one for each of the effect sizes presented in Exercise 24 . Each of the seven power analyses present hypothetical effect sizes in the small, moderate, or large ranges, in order to provide the reader with the opportunity to perform power analyses using G*Power.

Power analysis 1: Cohen’s d
Cohen’s d is an effect that represents the magnitude of the difference between two groups expressed in standard deviation units. The following instructions outline the steps required to perform a hypothetical power analysis with a moderate anticipated effect size of Cohen’s d = 0.50 (see Table 25.1 ), α = 0.05, and power = 0.80.

Step 1: Open G*Power 3.1.

Step 2: Select “t-tests” from the pull-down menu labeled “Test family.”

Step 3: Select “Means: Differences between two independent means (two groups)” from the pull-down menu labeled “Statistical test.”

Step 4: Make sure that the type of power analysis listed is “A priori: Compute required sample size—given α, power, and effect size.” This is the default setting.

Step 5: In the “Input parameters” section, select a two-tailed test.

Step 6: Enter the hypothesized effect next to “Effect size d .” For our example, it will be 0.50.

Step 7: Enter the α next to “α err prob.” For our example, it will be 0.05.

Step 8: Enter the desired power next to “Power (1 − β err prob).” For our example, it will be 0.80.

Step 9: Leave “Allocation ratio N2/N1” at 1 unless there is a specific reason to anticipate unequal sample sizes.

Step 10: Click Calculate. The window should look like the screen shot in Fig. 25.1 .

A statistical power analysis interface with overlapping normal distribution curves and computed output values for two group mean comparison. The statistical power analysis interface shows two tailed test compares means between two independent groups. The plot contains two overlapping normal distribution curves labeled alpha equals 0.05 and power equals 0.80. The horizontal axis represents the effect magnitude, and the vertical axis represents the probability density. A shaded region indicates the rejection area. Below the plot, dropdown fields include Test Family set to Means, Statistical Test set to Difference between two independent means, two groups, and Type of Power Analysis set to A priori. Input parameters are Effect size d equals 0.5, alpha error probability equals 0.05, and power equals 0.8. Output parameters include Noncentrality parameter as 2.8284271, Critical t as 1.9789706, D f as 126, Small size group 1 as 64, Small size group 2 as 64, Total sample size as 128, and Actual power as 0.8014596.
FIG. 25.1 ■
POWER ANALYSIS RESULTS OF A MODERATE HYPOTHESIZED COHEN’S d , α = 0.05, AND POWER = 0.80.

As can be observed in Fig. 25.1 , 128 total participants are required (64 in each group) to test a study hypothesis using an independent samples t -test, based on a moderate Cohen’s d of 0.50, α = 0.05, and power = 0.80.

Power analysis 2: Cohen’s d z
Cohen’s d z is an effect that represents the magnitude of the difference between two sets of paired data expressed in standard deviation units. The following instructions outline the steps required to perform a hypothetical power analysis with a small anticipated effect size of Cohen’s d z = 0.20 (see Table 25.1 ), α = 0.05, and power = 0.80.

Step 1: Open G*Power 3.1.

Step 2: Select “t-tests” from the pull-down menu labeled “Test family.”

Step 3: Select “Means: Differences between two dependent means (matched pairs)” from the pull-down menu labeled “Statistical test.”

Step 4: Make sure that the type of power analysis listed is “A priori: Compute required sample size—given α, power, and effect size.” This is the default setting.

Step 5: In the “Input parameters” section, select a two-tailed test.

Step 6: Enter the hypothesized effect next to “Effect size d z .” For our example, it will be 0.20.

Step 7: Enter the α next to “α err prob.” For our example, it will be 0.05.

Step 8: Enter the desired power next to “Power (1– β err prob).” For our example, it will be 0.80.

Step 9: Click Calculate. The window should look like the screen shot in Fig. 25.2 .

A statistical power analysis diagram with two overlapping distribution curves for a small hypothesized effect size and power equals 0.80. The statistical diagram shows a power analysis for a two tailed test comparing two independent means. It includes two overlapping normal distribution curves labeled alpha equals 0.05 and power equals 0.80. The horizontal axis represents effect magnitude and the vertical axis represents probability density. A shaded region under the curve indicates the rejection area. Dropdown fields show test family set to Means, statistical test set to difference between two independent means, two groups, and type of power analysis set to A priori. Input values are effect size d equals 0.2, alpha error probability equals 0.05, and power equals 0.8. Output values include Noncentrality parameter as 2.8213472, Critical t as 1.9720175, D f as 198, Total sample size as 199, and Actual power as 0.8016910.
FIG. 25.2 ■
POWER ANALYSIS RESULTS OF A SMALL HYPOTHESIZED COHEN’S dz , α = 0.05, AND POWER = 0.80.

As can be observed in Fig. 25.2 , 199 total participants are required to test a study hypothesis using a paired samples t -test, based on a small Cohen’s d z of 0.20, α = 0.05, and power = 0.80.

Power analysis 3: Cohen’s f
When planning a one-way analysis of variance (ANOVA), Cohen’s f can be computed to determine the differences between the groups. Like the ANOVA, Cohen’s f will identify the magnitude of the differences among the groups, but it will not explain differences between specific groups. The following instructions outline the steps required to perform a hypothetical power analysis for a three-group design with a small anticipated effect size of f = 0.10 (see Table 25.1 ), α = 0.05, and power = 0.80.

Step 1: Open G*Power 3.1.

Step 2: Select “F-tests” from the pull-down menu labeled “Test family.”

Step 3: Select “ANOVA: Fixed effects, omnibus, one-way” from the pull-down menu labeled “Statistical test.”

Step 4: Make sure that the type of power analysis listed is “A priori: Compute required sample size—given α, power, and effect size.” This is the default setting.

Step 5: In the “Input parameters” section, select a two-tailed test.

Step 6: Enter the hypothesized effect next to “Effect size f .” For our example, it will be 0.10.

Step 7: Enter the α next to “α err prob.” For our example, it will be 0.05.

Step 8: Enter the desired power next to “Power (1 − β err prob).” For our example, it will be 0.80.

Step 9: Enter 3 next to “Number of groups.”

Step 10: Click Calculate. The window should look like the screen shot in Fig. 25.3 .

A power analysis diagram with a curve for a small hypothesized effect size Cohen's f using three groups. The diagram shows a power analysis for a fixed effects analysis of variance test using three groups. It displays a central and non-centrally distribution curve where the horizontal axis represents the effect size and the vertical axis represents the probability density. The test family is set to F tests. The statistical test is analysis fixed effects omnibus one way. The type of power analysis is A priori compute required sample size given alpha power and effect size. Input parameters include effect size f equals 0.1, alpha error probability equals 0.05, power equals 0.8, and number of groups equals 3. Output parameters include no centrality parameter lambda equals 9.6900000, critical F equals 3.0000000, numerator degrees of freedom equals 2, denominator degrees of freedom equals 966, total sample size equals 969, and actual power equals 0.8011010. A button labeled Calculate appears at the bottom right of the interface.
FIG. 25.3 ■
POWER ANALYSIS RESULTS OF A SMALL HYPOTHESIZED COHEN’S f , α = 0.05, AND POWER = 0.80, WITH THREE GROUPS.

As can be observed in Fig. 25.3 , 969 total participants are required (323 in each group) to test a study hypothesis using a three-group one-way ANOVA based on a Cohen’s f of 0.10, α = 0.05, and power = 0.80.

Power analysis 4: Pearson r
The Pearson product-moment correlation is always between −1.00 and +1.00, where a value of zero indicates absolutely no relationship between the two variables (see Exercises 13 and 29 ). The following instructions outline the steps required to perform a power analysis with a large anticipated effect size of r = 0.50 (see Table 25.1 ), α = 0.05, and power = 0.80.

Step 1: Open G*Power 3.1.

Step 2: Select “Exact” from the pull-down menu labeled “Test family.”

Step 3: Select “Correlation: Bivariate normal model” from the pull-down menu labeled “Statistical test.”

Step 4: Make sure that the type of power analysis listed is “A priori: Compute required sample size—given α, power, and effect size.” This is the default setting.

Step 5: In the “Input parameters” section, choose a two-tailed test.

Step 6: Enter the hypothesized effect next to “Correlation ρ H1.” For our example, it will be 0.50.

Step 7: Enter the α next to “α err prob.” For our example, it will be 0.05.

Step 8: Enter the desired power next to “Power (1 − β err prob).” For our example, it will be 0.80.

Step 9: Enter 0 next to “Correlation ρ H0.” This means that the null hypothesis states that there is no correlation between the two variables ( r = 0.0).

Step 10: Click Calculate. The window should look like the screen shot in Fig. 25.4 .

A statistical diagram of power analysis for a large hypothesized Pearson r using alpha equals 0.05 and power equals 0.80. The diagram presents a statistical power analysis for a large hypothesized Pearson correlation using a two-tailed test. It includes two overlapping normal distribution curves labeled critical and power. The horizontal axis shows effect size values, and the vertical axis shows probability density. A shaded region indicates the critical area. The test family is set to correlation, and the statistical test is set to a bivariate normal model. The type of power analysis is A priori computation of the required sample size given alpha, power, and effect size. Input parameters include effect size r equals 0.5, alpha error probability equals 0.05, and power equals 0.8. Output parameters include Lower critical r as negative 0.3672777, Upper critical r as 0.3672777, Total sample size is 29, and Actual power is 0.8139420.
FIG. 25.4 ■
POWER ANALYSIS RESULTS OF A LARGE HYPOTHESIZED PEARSON r , α = 0.05, AND POWER = 0.80.

As can be observed in Fig. 25.4 , 29 total participants are required to test a study hypothesis using a Pearson correlation coefficient, based on a Pearson r of 0.50, α = 0.05, and power = 0.80.

Power analysis 5: R 2
The R 2 is the effect size for linear regression. The R 2 represents the percentage of variance explained in y by the predictor (see Exercises 15 and 30 ). The following instructions outline the steps required to perform a hypothetical power analysis with a moderate anticipated effect size of R 2 = 0.15 (see Table 25.1 ), α = 0.05, and power = 0.80, with a three-predictor model.

Step 1: Open G*Power 3.1.

Step 2: Select “F-Tests” from the pull-down menu labeled “Test family.”

Step 3: Select “Linear multiple regression: Fixed model, R 2 deviation from zero” from the pull-down menu labeled “Statistical test.”

Step 4: Make sure that the type of power analysis listed is “A priori: Compute required sample size—given α, power, and effect size.” This is the default setting.

Step 5: Underneath the phrase “Input parameters,” click “Determine.” A window will slide out to the right of your screen. This is so you can convert your hypothesized R 2 value to an f 2 value, which is what G*Power uses to perform a power analysis for multiple regression.

Step 6: Enter the hypothesized effect next to “Squared multiple correlation ρ 2 .” For our example, it will be 0.15.

Step 7: Click “Calculate and transfer to main window.”

Step 8: Enter the α next to “α err prob.” For our example, it will be 0.05.

Step 9: Enter the desired power next to “Power (1 − β err prob).” For our example, it will be 0.80.

Step 10: Enter 3 next to “Number of predictors.”

Step 11: Click Calculate. The window should look like the screen shot in Fig. 25.5 .

A statistical diagram of power analysis for a moderate hypothesized R squared with alpha equals 0.05 and power equals 0.80. The diagram presents a statistical power analysis for a moderate hypothesized R-squared using a fixed model with a single regression coefficient. It contains two overlapping normal distribution curves labeled critical and power. The horizontal axis represents effect size values, and the vertical axis shows probability density. A shaded region indicates the critical area. The test family is set to F tests, and the statistical test is set to fixed model regression with a single regression coefficient. The type of power analysis is A priori computation of the required sample size given alpha, power, and effect size. Input parameters include the Effect size f-squared as 0.1764706, alpha error probability as 0.05, Power (1 minus beta error probability as 0.80), and Number of Predictors as 3. Output parameters include Noncentrality parameters lambda as 11.6470596, Critical F as 2.7529698, Numeration d f is 3, Denominator d f is 62, Total sample size is 66, and Actual power is 0.8012536.
FIG. 25.5 ■
POWER ANALYSIS RESULTS OF A MODERATE HYPOTHESIZED R 2 , α = 0.05, AND POWER = 0.80.

As can be observed in Fig. 25.5 , 66 total participants are required to test a study hypothesis using a three-predictor multiple regression model, based on an R 2 of 0.15, α = 0.05, and power = 0.80.

Power analysis 6: Odds ratio
An OR is computed when the dependent variable is dichotomous and the predictor is either continuous or dichotomous. With multiple predictors, OR s are computed by performing logistic regression analysis. Logistic regression analysis tests a predictor (or set of predictors) with a dichotomous dependent variable ( Tabachnick & Fidell, 2019 ). Because an OR in a power analysis is often being planned within the context of logistic regression, the following example uses the logistic regression feature of G*Power. The following instructions outline the steps required to perform a hypothetical power analysis with a small anticipated effect size of OR = 1.5 (see Table 25.1 ), α = 0.05, and power = 0.80.

Step 1: Open G*Power 3.1.

Step 2: Select “z-tests” from the pull-down menu labeled “Test family.”

Step 3: Select “Logistic regression” from the pull-down menu labeled “Statistical test.”

Step 4: Make sure that the type of power analysis listed is “A priori: Compute required sample size—given α, power, and effect size.” This is the default setting.

Step 5: In the “Input parameters” section, choose a two-tailed test.

Step 6: Enter the hypothesized effect next to “Odds ratio.” For our example, it will be 1.5.

Step 7: Enter 0.30 next to “Pr(Y=1|X=1) H0.” This represents the probability that y is 1 when x is 1, and 30% would represent a small to moderate association between x and y .

Step 8: Enter the α next to “α err prob.” For our example, it will be 0.05.

Step 9: Enter the desired power next to “Power (1 − β err prob).” For our example, it will be 0.80.

Step 10: Leave the default value of 0 next to “ R 2 other predictors.”

Step 11: Select “Binomial” from the pull-down menu next to “X distribution.”

Step 12: Click Calculate. The window should look like the screen shot in Fig. 25.6 .

A graph presents power analysis results with sample size and power level. The graph titled Power Analysis Results of a Small Hypothesized Or Alpha equals 0 point 05 and Power equals 0 point 80 presents a statistical output. The visual contains a curved line that represents the relationship between power and sample size. The power level is marked at 0 point 80 along the vertical axis, and the corresponding sample size is aligned with the horizontal axis. Labels on the graph identify key values, including sample size and power level. A horizontal reference line intersects the curve at a power equals 0 point 80. The curve illustrates that a higher sample size is needed to achieve the desired power of 0 point 80 when alpha is set at 0 point 05. The graph helps determine how many observations are required for adequate statistical power in hypothesis testing. The output parameters include Critical z as 1.9599640, Total sample size as 853, and Actual power as 0.8001429.
FIG. 25.6 ■
POWER ANALYSIS RESULTS OF A SMALL HYPOTHESIZED OR , α = 0.05, AND POWER = 0.80.

As can be observed in Fig. 25.6 , 853 total participants are required to test a study hypothesis using an unadjusted odds ratio, based on an OR of 1.5, α = 0.05, and power = 0.80.

Power analysis 7: d
When both the predictor and the dependent variable are dichotomous, you may use either the OR or the d as the effect size in a power analysis. However, the d is the preferred effect size in a power analysis for a two-sample comparative design where the dependent variable is dichotomous. Recall that the letter “d” represents the difference in percentages in Group 1 versus Group 2. A power analysis based on the effect size d can involve any two pairs of proportions. However, in this exercise, for ease of understanding one proportion will always be 0.50, or 50%. This is because the ranges of effect size magnitudes in Table 25.1 for d only apply when one group’s proportion is 50% ( Cohen, 1988 ). The following instructions outline the steps required to perform a hypothetical power analysis with a large anticipated effect size of d = 0.25, α = 0.05, and power = 0.80.

Step 1: Open G*Power 3.1.

Step 2: Select “Exact” from the pull-down menu labeled “Test family.”

Step 3: Select “Proportions: Inequality, two independent groups (Fisher’s exact test)” from the pull-down menu labeled “Statistical test.”

Step 4: Make sure that the type of power analysis listed is “A priori: Compute required sample size—given α, power, and effect size.” This is the default setting.

Step 5: In the “Input parameters” section, choose a two-tailed test.

Step 6: Enter the hypothesized proportions next to “Proportion p1 and Proportion p2.” For our example, it will be 0.50 and 0.25 to represent a 25% difference. It does not matter which proportion, p1 or p2, is 0.25 and 0.50. Thus, 0.25 and 0.50 can be entered in p1 and p2, or vice versa.

Step 7: Enter the α next to “α err prob.” For our example, it will be 0.05.

Step 8: Enter the desired power next to “Power (1 − β err prob).” For our example, it will be 0.80.

Step 9: Leave “Allocation ratio N2/N1” at 1 unless there is a specific reason to anticipate unequal sample sizes.

Step 10: Click Calculate. The window should look like the screen shot in Fig. 25.7 .

A software interface presents power analysis results for a large hypothesized d. The software interface titled Power Analysis Results of a Large Hypothesized d Alpha equals 0 point 05 and Power equals 0 point 80 displays output from G Power version 3 point 1 point 9 for a power analysis in the test family of Z tests using logistic regression. The type of power analysis is A priori, which computes the required sample size based on alpha power and effect size. Input parameters include an effect size of 0 point 8, alpha error probability of 0 point 05, and power of 0 point 80. The output parameters include the Sample size group 1 and group 2 as 64, the Total sample size as 128, the Actual power as 0.8017145, and the Actual alpha as 0.0298286.
FIG. 25.7 ■
POWER ANALYSIS RESULTS OF A LARGE HYPOTHESIZED d, α = 0.05, AND POWER = 0.80.

As can be observed in Fig. 25.7 , 128 total participants are required (64 in each group) to test a study hypothesis using a Fisher’s exact test, based on a large d of 0.25, α = 0.05, and power = 0.80.

Study questions

1.
Perform a power analysis based on a moderate hypothesized Cohen’s d z , α = 0.05 and power = 0.80, two-tailed test, using G*Power. What is the required N ?

2.
Perform a power analysis based on a large hypothesized R 2 with four predictors in the model, α = 0.05, and power = 0.80 using G*Power. What is the required N ?

3.
Perform a power analysis based on a large hypothesized three-group Cohen’s f , α= 0.05, and power = 0.80 using G*Power. What is the required N ?

4.
Redo your power analysis from Question 3 using a moderate hypothesized Cohen’s f . How many more participants are required? Provide a rationale for the difference in the sample size.

5.
Perform a power analysis based on a moderate hypothesized d where Group 1 = 50% and Group 2 = 65%, α = 0.05, and power = 0.80, two-tailed test, using G*Power. What is the required N ?

6.
Redo your power analysis from Question 5, using an α of 0.01. How many more participants are required? Provide a rationale for your difference in sample size.

7.
Prior to conducting a power analysis, a researcher reviewed the literature and discovered that a study similar to hers reported a Cohen’s d of 0.22. According to Table 25.1 , how would you characterize the magnitude of that effect?

8.
Perform a power analysis based on a moderate Pearson r , α = 0.05, and power = 0.80, two-tailed test, using G*Power. What is the required N ?

9.
Redo your power analysis from Question 8, using a power of 85% instead of 80%. How many more participants are required? Provide a rationale for the change in sample size.

10.
Prior to conducting a power analysis, a researcher reviewed the literature and discovered a similar study reported a Pearson r of 0.34. According to Table 25.1 , how would you characterize the magnitude of that effect?

Answers to study questions

1.
The required N would be 34.

A software interface presents power analysis results for proportions in two independent groups using Fishers exact test. The software interface presents input and output values used for a power analysis. Input values are tails as two, effect size d subscript Z as zero point five zero, alpha error probability as zero point zero five, and power one minus beta error probability as zero point eight zero. Output values are no centrality parameter delta as two point nine one five four seven five nine, critical t as two point zero three four five one five three, degrees of freedom as thirty three, total sample size as thirty four, and actual power as zero point eight zero seven seven seven five.
2.
The required N would be 40.

A software interface presents input and output values used for a power analysis. The software interface shows input and output values used for power analysis in regression. Input values include effect size F squared as zero point three five one three five one four, alpha error probability as zero point zero five, power one minus beta error probability as zero point eight, and number of predictors as four. Output values include no centrality parameter lambda as fourteen point zero five four zero five six zero, critical F as two point six four one four six five two, numerator degrees of freedom as four, denominator degrees of freedom as thirty five, total sample size as forty, and actual power as zero point eight one two seven one one seven.
3.
The required N would be 66.

A software interface shows input and output values used for power analysis in regression. The software interface displays input and output parameters for a power analysis. Input parameters include Effect size f as 0.4, alpha error probability as 0.05, Power 1 minus beta error probability as 0.8, and Number of groups as 3. Output parameters include No centrality parameter lambda as 10.5600000, Critical F as 3.1428985, Numerator degrees of freedom as 2, Denominator degrees of freedom as 63, Total sample size as 66, and Actual power as 0.8080744.
4.
The required N would be 159, which would be 93 more participants than would be needed in Question 3. This example demonstrates that the smaller the anticipated effect size, the larger the sample size required to conduct the study ( Gray & Grove, 2021 ).

A software interface displays input and output parameters for a power analysis. The software interface presents input and output parameters used in a power analysis. Input parameters include effect size f as 0.25, alpha error probability as 0.05, power 1 minus beta error probability as 0.8, and number of groups as 3. Output parameters include no centrality parameter lambda as 9.9375000, critical F as 3.0540042, numerator degrees of freedom as 2, denominator degrees of freedom as 156, total sample size as 159, and actual power as 0.8048873.
5.
The required N would be 366.

A software interface displays input and output parameters related to a power analysis test. The software interface presents power analysis results for proportions in two independent groups using Fisher's exact test. The test family is a statistical test. The statistical test is the proportion inequality between two independent groups, Fishers exact test. The type of power analysis is A priori compute required sample size given alpha power and effect size. The input parameters include tails as two proportions p 1 as 0 point 55, proportion p 2 as 0 point 65, alpha error probability as 0 point 05 and power one minus beta error probability as 0 point 8. The allocation ratio N 2 divided by N 1 is 1. The output parameters display sample size group 1 as 183, sample size group 2 as 183, total sample size as 366, actual power as 0. 8028427 and actual alpha as 0.0390516.
6.
The required N would be 534, which would be 168 more participants than would be needed in Question 5. This example demonstrates that the smaller the alpha, the larger the sample size required to conduct the study ( Kim et al., 2022 ).

A software interface displays input and output parameters for a power analysis using correlation values and probability levels. The software interface presents input parameters for a power analysis. Tails is set to two. Proportion p one is zero point five. Proportion p two is zero point six five. Alpha error probability is zero point zero one. Power one minus beta error probability is zero point eight. Allocation ratio N two divided by N one is one. The output parameters display sample size group one as two hundred sixty seven, sample size group two as two hundred sixty seven, total sample size as five hundred thirty four, actual power as zero point eight zero two seven eight one six, and actual alpha as zero point zero zero seven three nine five one six seven.
7.
A Cohen’s d of 0.22 would be considered a small effect according to Table 25.1 .

8.
The required N would be 84.

A software interface shows input values for correlation analysis and output values including sample size and actual power. The software interface displays input parameters for tails as two, correlation rho H 1 as zero point three, alpha error probability as zero point zero five, power one minus beta error probability as zero point eight, and correlation rho H 0 as zero. Output parameters include lower critical r as negative zero point two one four five six six nine, upper critical r as zero point two one four five six six nine, total sample size as eighty four, and actual power as zero point eight zero zero three three nine zero.
9.
The required N would be 96, which would be 12 more participants than would be needed in Question 8. This example demonstrates that the larger the desired statistical power, the larger the sample size required to conduct the study ( Terrell, 2021 ).

A software interface shows input and output parameters used in a power analysis. The software interface shows input values for Tails as Two, Correlation rho H 1 as 0.3, alpha error probability as 0.05, Power 1 minus beta error probability as 0.85, and Correlation rho H 0 as 0. The output values are Lower critical r as negative 0.2006272, Upper critical r as 0.2006272, Total sample size as 96, and Actual power as 0.8510607.
10.
A Pearson r of 0.34 would be considered a moderate effect, because it is so close to 0.30 (a moderate effect according to Table 25.1 ).

EXERCISE 25
Questions for additional study
